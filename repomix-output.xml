This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: **/*.mp4, **/*.png, **/*.jpg, **/*.zip, **/venv/**, **/.venv/**, **/__pycache__/**, **/.git/**, all_code.txt, repomix-output.xml
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
core/
  __init__.py
  agent_engine.py
  changes.py
  runner.py
  workflow_io.py
  workflow_manager.py
.gitignore
agent_demo.py
analyze_video.py
app.py
apply_changes.py
build_workflow.py
extract_frames.py
index.html
merge_workflow.py
run_workflow.py
smoke_test_core.py
stylize_frames.py
test_gemini.py
test_v3.py
vibe_check.py
video_generator.py
workflow_cli.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="merge_workflow.py">
# merge_workflow.py
import argparse
import sys
from pathlib import Path
from core.workflow_manager import WorkflowManager

def main():
    # 1. è®¾ç½®å‘½ä»¤è¡Œå‚æ•°ï¼Œæ–¹ä¾¿ä½ æŒ‡å®šè¦åˆå¹¶å“ªä¸ª Job
    parser = argparse.ArgumentParser(description="ä¸€é”®åˆå¹¶åˆ†é•œè§†é¢‘ä¸ºæœ€ç»ˆæˆç‰‡")
    parser.add_argument("--job_id", required=True, help="è¯·è¾“å…¥ Job ID (ä¾‹å¦‚: job_6db68d0c)")
    args = parser.parse_args()

    print(f"ğŸš€ æ­£åœ¨å¯åŠ¨åˆå¹¶ç¨‹åºï¼Œç›®æ ‡ Job: {args.job_id}")

    try:
        # 2. åˆå§‹åŒ–ç®¡ç†å™¨å¹¶å®šä½åˆ°è¯¥ Job
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¼ å…¥äº† project_rootï¼Œç¡®ä¿è·¯å¾„ç»å¯¹æ­£ç¡®
        project_root = Path(__file__).parent
        manager = WorkflowManager(args.job_id, project_root=project_root)
        
        if not manager.workflow:
            print(f"âŒ æ‰¾ä¸åˆ°è¯¥ Job çš„æ•°æ®ï¼Œè¯·æ£€æŸ¥ jobs/{args.job_id} æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ã€‚")
            return

        # 3. è°ƒç”¨åˆšæ‰åœ¨ core é‡Œå†™å¥½çš„åˆå¹¶é€»è¾‘
        result_file = manager.merge_videos()
        
        print("\n" + "="*30)
        print(f"âœ… åˆå¹¶æˆåŠŸï¼")
        print(f"ğŸ“ æˆç‰‡è·¯å¾„: jobs/{args.job_id}/{result_file}")
        print("="*30)

    except Exception as e:
        print(f"\nâŒ åˆå¹¶è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        # æ‰“å°è¯¦ç»†æŠ¥é”™æ–¹ä¾¿æˆ‘ä»¬æ’é›·
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
</file>

<file path="core/__init__.py">

</file>

<file path="core/changes.py">
from typing import Optional

def apply_global_style(wf: dict, new_style_prompt: str, cascade: bool = True) -> int:
    wf.setdefault("global", {})["style_prompt"] = new_style_prompt

    affected = 0
    if cascade:
        for shot in wf.get("shots", []):
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected

def replace_entity_reference(wf: dict, entity_id: str, new_ref_image: str) -> int:
    entities = wf.setdefault("entities", {})
    if entity_id not in entities:
        raise KeyError(f"entity ä¸å­˜åœ¨ï¼š{entity_id}")

    entities[entity_id]["reference_image"] = new_ref_image

    affected = 0
    for shot in wf.get("shots", []):
        shot_entities = shot.get("entities", [])
        if entity_id in shot_entities:
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected
</file>

<file path="core/workflow_io.py">
import json
from pathlib import Path

def load_workflow(job_dir: Path) -> dict:
    wf_path = job_dir / "workflow.json"
    return json.loads(wf_path.read_text(encoding="utf-8"))

def save_workflow(job_dir: Path, wf: dict) -> None:
    wf_path = job_dir / "workflow.json"
    wf_path.write_text(
        json.dumps(wf, ensure_ascii=False, indent=2),
        encoding="utf-8"
    )
</file>

<file path=".gitignore">
# å¿½ç•¥ Python è™šæ‹Ÿç¯å¢ƒ
venv/
.venv/
__pycache__/
*.pyc

# å¿½ç•¥æ•æ„Ÿä¿¡æ¯
.env

# å¿½ç•¥ç”Ÿæˆçš„å¤§å‹èµ„æºæ–‡ä»¶ï¼ˆåªä¼ ä»£ç ï¼Œä¸ä¼ ç´ æï¼‰
jobs/
downloads/
outputs/
frames/
stylized_frames/
all_code.txt
repomix-output.xml
</file>

<file path="agent_demo.py">
# agent_demo.py
import os
from core.workflow_manager import WorkflowManager
from core.agent_engine import AgentEngine

def main():
    # 1. åˆå§‹åŒ–
    manager = WorkflowManager("demo_job_001")
    agent = AgentEngine()
    
    print("--- AI çˆ†æ¬¾äºŒåˆ› Agent é©±åŠ¨æ¨¡å¼ ---")
    print("å½“å‰é£æ ¼:", manager.workflow.get("global", {}).get("style_prompt"))
    print("å½“å‰å®ä½“:", list(manager.workflow.get("entities", {}).keys()))
    print("-" * 30)
    
    while True:
        user_text = input("\nğŸ¤– æ‚¨æƒ³å¯¹è§†é¢‘åšä½•ä¿®æ”¹ï¼Ÿ(è¾“å…¥ 'exit' é€€å‡º): ")
        if user_text.lower() == 'exit':
            break
            
        # å‡†å¤‡å·¥ä½œæµæ‘˜è¦ï¼ˆå‘Šè¯‰ Gemini å½“å‰æœ‰ä»€ä¹ˆï¼Œå®ƒæ‰èƒ½æ”¹ï¼‰
        summary = f"Style: {manager.workflow.get('global', {}).get('style_prompt')}\n"
        summary += f"Entities: {json.dumps(manager.workflow.get('entities', {}), indent=2)}"
        
        print("ğŸ” Agent æ­£åœ¨æ€è€ƒ...")
        action = agent.get_action_from_text(user_text, summary)
        
        print(f"ğŸ¯ è§£ææŒ‡ä»¤: {action}")
        
        if action.get("op") != "none" and action.get("op") != "error":
            # æ‰§è¡Œä¿®æ”¹
            res = manager.apply_agent_action(action)
            print(f"âœ… æ‰§è¡ŒæˆåŠŸï¼å—å½±å“åˆ†é•œæ•°: {res['affected_shots']}")
            print(f"ğŸ”„ æ‰€æœ‰å—å½±å“çš„åˆ†é•œçŠ¶æ€å·²é‡ç½®ï¼Œå‡†å¤‡é‡æ–°ç”Ÿæˆã€‚")
        else:
            print(f"âš ï¸ æ— æ³•æ‰§è¡Œ: {action.get('reason')}")

if __name__ == "__main__":
    import json
    main()
</file>

<file path="analyze_video.py">
import os
import json
import time
from pathlib import Path
from google import genai

PROJECT_DIR = Path(__file__).parent
VIDEO_PATH = PROJECT_DIR / "downloads" / "input.mp4"
OUT_PATH = PROJECT_DIR / "outputs" / "storyboard.json"

DIRECTOR_METAPROMPT = r"""
è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„å½±è§†åˆ†é•œåˆ†æå¸ˆï¼Œä¸“æ³¨ä»¥ã€Œç”»é¢å˜åŒ–ã€ä¸ºæ ¸å¿ƒï¼Œ
å°†åˆšæ‰çš„è§†é¢‘æ‹†è§£ä¸ºè¯¦ç»†çš„åˆ†é•œè¡¨ã€‚
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºã€‚
æ ¹å…ƒç´ ä¸ºåŒ…å«å¤šä¸ªåˆ†é•œå¯¹è±¡çš„JSONæ•°ç»„ã€‚
æ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
shot_number, frame_description, content_analysis,
start_time, end_time, duration_seconds,
shot_type, camera_angle, camera_movement,
focus_and_depth, lighting, music_and_sound, voiceoverã€‚
æ— ä¿¡æ¯è¯·å¡« nullã€‚
ä»…è¾“å‡ºçº¯ JSONã€‚
""".strip()


def ensure_api_key() -> str:
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError(
            "æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡ã€‚\n"
            "è¯·åœ¨å½“å‰ç»ˆç«¯æ‰§è¡Œï¼š\n"
            '  export GEMINI_API_KEY="ä½ çš„key"\n'
            "ç„¶åå†è¿è¡Œæœ¬è„šæœ¬ã€‚"
        )
    return api_key


def extract_json_array(text: str):
    if not text:
        raise ValueError("æ¨¡å‹æ²¡æœ‰è¿”å›æ–‡æœ¬ï¼ˆresponse.text ä¸ºç©ºï¼‰ã€‚")

    s = text.strip()
    if s.startswith("[") and s.endswith("]"):
        return json.loads(s)

    l = s.find("[")
    r = s.rfind("]")
    if l != -1 and r != -1 and r > l:
        return json.loads(s[l : r + 1])

    raise ValueError(
        "æœªèƒ½ä»æ¨¡å‹è¾“å‡ºä¸­æå– JSON æ•°ç»„ã€‚\n"
        "è¯·æŠŠæ¨¡å‹åŸå§‹è¾“å‡ºå¤åˆ¶å‡ºæ¥æ£€æŸ¥ï¼ˆå®ƒå¯èƒ½æ²¡æœ‰æŒ‰è¦æ±‚è¾“å‡º JSONï¼‰ã€‚"
    )


def wait_until_file_active(client: genai.Client, file_obj, timeout_s: int = 120, poll_s: int = 2):
    """
    Files API ä¸Šä¼ åï¼Œæ–‡ä»¶å¯èƒ½å¤„äº PROCESSING çŠ¶æ€ï¼Œå¿…é¡»ç­‰åˆ° ACTIVE æ‰èƒ½ä½¿ç”¨ã€‚
    """
    file_name = getattr(file_obj, "name", None)
    if not file_name:
        # æå°‘æ•°æƒ…å†µä¸‹å¯¹è±¡ç»“æ„ä¸åŒï¼Œç›´æ¥è¿”å›è¯•è¯•
        return file_obj

    start = time.time()
    last_state = None

    while True:
        f = client.files.get(name=file_name)
        state = getattr(f, "state", None)

        if state != last_state:
            print(f"æ–‡ä»¶çŠ¶æ€ï¼š{state}")
            last_state = state

        if state == "ACTIVE":
            return f

        if time.time() - start > timeout_s:
            raise TimeoutError(
                f"ç­‰å¾…æ–‡ä»¶å˜ä¸º ACTIVE è¶…æ—¶ï¼ˆ>{timeout_s}sï¼‰ã€‚"
                "ä½ å¯ä»¥é‡è¯•ä¸€æ¬¡ï¼Œæˆ–è€…æ¢æ›´å°/æ›´å¸¸è§ç¼–ç çš„ mp4ã€‚"
            )

        time.sleep(poll_s)


def main():
    api_key = ensure_api_key()

    if not VIDEO_PATH.exists():
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ°è§†é¢‘æ–‡ä»¶ï¼š{VIDEO_PATH}\n"
            "è¯·ç¡®è®¤ä½ å·²æŠŠè§†é¢‘æ”¾åˆ° downloads/ é‡Œï¼Œå¹¶å‘½åä¸º input.mp4"
        )

    size_mb = VIDEO_PATH.stat().st_size / (1024 * 1024)
    print(f"å‡†å¤‡å¤„ç†è§†é¢‘ï¼š{VIDEO_PATH.name} ({size_mb:.1f} MB)")

    client = genai.Client(api_key=api_key)

    print("å¼€å§‹ä¸Šä¼ è§†é¢‘åˆ° Files APIâ€¦")
    uploaded = client.files.upload(file=str(VIDEO_PATH))
    print(f"âœ… ä¸Šä¼ å®Œæˆï¼š{uploaded.name}")

    print("ç­‰å¾…æ–‡ä»¶å˜ä¸º ACTIVEâ€¦")
    video_file = wait_until_file_active(client, uploaded, timeout_s=180, poll_s=2)
    print("âœ… æ–‡ä»¶å·² ACTIVEï¼Œå¯ä»¥å¼€å§‹åˆ†æ")

    print("å¼€å§‹åˆ†æè§†é¢‘ï¼ˆç”Ÿæˆåˆ†é•œ JSONï¼‰â€¦")
    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[DIRECTOR_METAPROMPT, video_file],
    )

    raw_text = getattr(response, "text", None) or ""
    storyboard = extract_json_array(raw_text)

    OUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUT_PATH.write_text(
        json.dumps(storyboard, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )

    print(f"\nâœ… å·²ç”Ÿæˆåˆ†é•œ JSONï¼š{OUT_PATH}")
    print(f"åˆ†é•œæ•°é‡ï¼š{len(storyboard)}")


if __name__ == "__main__":
    main()
</file>

<file path="apply_changes.py">
import json
import argparse
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
DEFAULT_JOB_ID = "demo_job_001"

def load_workflow(job_dir: Path) -> dict:
    return json.loads((job_dir / "workflow.json").read_text(encoding="utf-8"))

def save_workflow(job_dir: Path, wf: dict) -> None:
    (job_dir / "workflow.json").write_text(json.dumps(wf, ensure_ascii=False, indent=2), encoding="utf-8")

def apply_global_style(wf: dict, new_style_prompt: str, cascade: bool = True) -> int:
    """
    ä¿®æ”¹å…¨å±€é£æ ¼ï¼Œå¹¶çº§è”ä½¿ç›¸å…³èŠ‚ç‚¹éœ€è¦é‡è·‘ã€‚
    cascade=Trueï¼šæŠŠæ‰€æœ‰ shots çš„ stylize & video_generate é‡ç½®ä¸º NOT_STARTED
    è¿”å›ï¼šå—å½±å“ shots æ•°é‡
    """
    wf.setdefault("global", {})["style_prompt"] = new_style_prompt

    affected = 0
    if cascade:
        for shot in wf.get("shots", []):
            # é£æ ¼æ”¹äº†ï¼Œé£æ ¼åŒ–å›¾å°±åº”è¯¥é‡æ–°ç”Ÿæˆï¼ˆçœŸå®äº§å“é‡Œå¯èƒ½æœ‰ç¼“å­˜ç­–ç•¥ï¼Œdemo å…ˆå…¨é‡è·‘ï¼‰
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected

def replace_entity_reference(wf: dict, entity_id: str, new_ref_image: str) -> int:
    """
    æ›¿æ¢æŸä¸ª entity çš„ reference_imageï¼Œå¹¶åªå½±å“å¼•ç”¨å®ƒçš„ shotsï¼š
    - æ ‡è®° stylize / video_generate ä¸º NOT_STARTED
    è¿”å›ï¼šå—å½±å“ shots æ•°é‡
    """
    entities = wf.setdefault("entities", {})
    if entity_id not in entities:
        raise KeyError(f"entity ä¸å­˜åœ¨ï¼š{entity_id}")

    entities[entity_id]["reference_image"] = new_ref_image

    affected = 0
    for shot in wf.get("shots", []):
        shot_entities = shot.get("entities", [])
        if entity_id in shot_entities:
            shot.setdefault("status", {})["stylize"] = "NOT_STARTED"
            shot.setdefault("status", {})["video_generate"] = "NOT_STARTED"
            affected += 1
    return affected


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job_id", default=DEFAULT_JOB_ID)
    parser.add_argument("--set_global_style", default=None, help="è®¾ç½®æ–°çš„ global.style_prompt")
    parser.add_argument("--no_cascade", action="store_true", help="ä¸è§¦å‘çº§è”é‡è·‘ï¼ˆé»˜è®¤ä¼šè§¦å‘ï¼‰")
    parser.add_argument("--replace_entity", default=None, help="è¦æ›¿æ¢çš„ entity_idï¼Œä¾‹å¦‚ entity_1")
    parser.add_argument("--new_ref", default=None, help="æ–°çš„ reference_image è·¯å¾„ï¼Œä¾‹å¦‚ stylized_frames/shot_02.png")

    args = parser.parse_args()

    job_dir = PROJECT_DIR / "jobs" / args.job_id
    wf = load_workflow(job_dir)

    if args.set_global_style is not None:
        affected = apply_global_style(wf, args.set_global_style, cascade=(not args.no_cascade))
        save_workflow(job_dir, wf)
        print(f"âœ… å·²æ›´æ–° global.style_prompt")
        print(f"âœ… å—å½±å“ shotsï¼š{affected}ï¼ˆstylize/video_generate å·²æ ‡è®°ä¸º NOT_STARTEDï¼‰")
    else:
        print("æ²¡æœ‰æŒ‡å®šä»»ä½•ä¿®æ”¹å‚æ•°ã€‚ç¤ºä¾‹ï¼š")
        print('  python apply_changes.py --set_global_style "cinematic noir, high contrast"')
    
    if args.replace_entity and args.new_ref:
        affected = replace_entity_reference(wf, args.replace_entity, args.new_ref)
        save_workflow(job_dir, wf)
        print(f"âœ… å·²æ›¿æ¢ {args.replace_entity} çš„ reference_image -> {args.new_ref}")
        print(f"âœ… å—å½±å“ shotsï¼š{affected}ï¼ˆstylize/video_generate å·²æ ‡è®°ä¸º NOT_STARTEDï¼‰")
        return

if __name__ == "__main__":
    main()
</file>

<file path="build_workflow.py">
import json
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
JOB_DIR = PROJECT_DIR / "jobs" / "demo_job_001"

STORYBOARD_PATH = JOB_DIR / "storyboard.json"
FRAMES_DIR = JOB_DIR / "frames"
STYLIZED_DIR = JOB_DIR / "stylized_frames"
WORKFLOW_PATH = JOB_DIR / "workflow.json"

def to_seconds(t):
    if t is None:
        return None
    if isinstance(t, (int, float)):
        return float(t)
    s = str(t).strip()
    if not s:
        return None
    try:
        return float(s)
    except ValueError:
        pass
    parts = s.split(":")
    try:
        parts = [float(p) for p in parts]
    except ValueError:
        return None
    if len(parts) == 3:
        hh, mm, ss = parts
        return hh * 3600 + mm * 60 + ss
    if len(parts) == 2:
        mm, ss = parts
        return mm * 60 + ss
    if len(parts) == 1:
        return parts[0]
    return None

def main():
    storyboard = json.loads(STORYBOARD_PATH.read_text(encoding="utf-8"))

    shots = []
    for s in storyboard:
        shot_number = s.get("shot_number")
        if shot_number is None:
            continue
        sid = f"shot_{int(shot_number):02d}"

        start = to_seconds(s.get("start_time"))
        end = to_seconds(s.get("end_time"))
        desc = s.get("frame_description") or s.get("content_analysis") or ""

        frame_path = f"frames/{sid}.png"
        stylized_path = f"stylized_frames/{sid}.png"

        shots.append({
            "shot_id": sid,
            "start_time": start,
            "end_time": end,
            "description": desc,
            "voiceover": s.get("voiceover"),
            "assets": {
                "first_frame": frame_path if (JOB_DIR / frame_path).exists() else None,
                "stylized_frame": stylized_path if (JOB_DIR / stylized_path).exists() else None,
                "video": None
            },
            "status": {
                "analyze": "SUCCESS",
                "extract_frames": "SUCCESS",
                "stylize": "SUCCESS",
                "video_generate": "NOT_STARTED"
            }
        })

    workflow = {
        "job_id": "demo_job_001",
        "source_video": "input.mp4",
        "global": {
            "aspect_ratio": "16:9",
            "style_prompt": "de-replication stylization"
        },
        "entities": {},  # å…ˆç•™ç©ºï¼Œåç»­æˆ‘ä»¬åŠ â€œäººç‰©/èµ„äº§å…¨å±€æ›¿æ¢â€
        "shots": shots
    }

    WORKFLOW_PATH.write_text(json.dumps(workflow, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"âœ… workflow.json å·²ç”Ÿæˆï¼š{WORKFLOW_PATH}")
    print(f"shots æ•°é‡ï¼š{len(shots)}")

if __name__ == "__main__":
    main()
</file>

<file path="extract_frames.py">
import json
import subprocess
from pathlib import Path

PROJECT_DIR = Path(__file__).parent
VIDEO_PATH = PROJECT_DIR / "downloads" / "input.mp4"
STORYBOARD_PATH = PROJECT_DIR / "outputs" / "storyboard.json"
FRAMES_DIR = PROJECT_DIR / "frames"

def to_seconds(t):
    if t is None:
        return None
    if isinstance(t, (int, float)):
        return float(t)

    s = str(t).strip()
    if not s:
        return None

    try:
        return float(s)
    except ValueError:
        pass

    parts = s.split(":")
    try:
        parts = [float(p) for p in parts]
    except ValueError:
        return None

    if len(parts) == 3:
        hh, mm, ss = parts
        return hh * 3600 + mm * 60 + ss
    if len(parts) == 2:
        mm, ss = parts
        return mm * 60 + ss
    if len(parts) == 1:
        return parts[0]
    return None

def main():
    if not VIDEO_PATH.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è§†é¢‘ï¼š{VIDEO_PATH}")
    if not STORYBOARD_PATH.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° storyboardï¼š{STORYBOARD_PATH}")

    FRAMES_DIR.mkdir(parents=True, exist_ok=True)

    storyboard = json.loads(STORYBOARD_PATH.read_text(encoding="utf-8"))
    saved = 0

    for shot in storyboard:
        shot_num = shot.get("shot_number", saved + 1)
        start_time = shot.get("start_time", None)
        ts = to_seconds(start_time)

        if ts is None:
            continue

        out_path = FRAMES_DIR / f"shot_{int(shot_num):02d}.png"

        cmd = [
            "/opt/homebrew/bin/ffmpeg",
            "-y",
            "-ss", str(ts),
            "-i", str(VIDEO_PATH),
            "-frames:v", "1",
            "-q:v", "2",
            str(out_path)
        ]

        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        if out_path.exists():
            saved += 1

    print(f"âœ… æˆªå¸§å®Œæˆï¼š{saved} å¼ ï¼Œä¿å­˜åœ¨ {FRAMES_DIR}")

if __name__ == "__main__":
    main()
</file>

<file path="run_workflow.py">
import json
import argparse
from pathlib import Path
import shutil

PROJECT_DIR = Path(__file__).parent
DEFAULT_JOB_ID = "demo_job_001"

def load_workflow(job_dir: Path) -> dict:
    wf_path = job_dir / "workflow.json"
    return json.loads(wf_path.read_text(encoding="utf-8"))

def save_workflow(job_dir: Path, wf: dict) -> None:
    wf_path = job_dir / "workflow.json"
    wf_path.write_text(json.dumps(wf, ensure_ascii=False, indent=2), encoding="utf-8")

def find_shot(wf: dict, shot_id: str) -> dict | None:
    for s in wf.get("shots", []):
        if s.get("shot_id") == shot_id:
            return s
    return None

def ensure_videos_dir(job_dir: Path) -> Path:
    videos_dir = job_dir / "videos"
    videos_dir.mkdir(parents=True, exist_ok=True)
    return videos_dir

def mock_generate_video(job_dir: Path, shot: dict) -> str:
    """
    Demo ç‰ˆæœ¬ï¼šç”Ÿæˆä¸€ä¸ªâ€œå ä½è§†é¢‘æ–‡ä»¶â€ï¼Œç”¨æ¥éªŒè¯ runner çš„å·¥ä½œæ–¹å¼ã€‚
    åç»­æ¥ Seedance/Veo æ—¶ï¼Œåªéœ€æ›¿æ¢è¿™ä¸ªå‡½æ•°ã€‚
    """
    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    # ç”¨ input.mp4 çš„å‰ 1 ç§’å¤åˆ¶æˆä¸€ä¸ªå°æ–‡ä»¶ï¼ˆç¡®ä¿æ˜¯å¯æ’­æ”¾ mp4ï¼‰
    src_video = job_dir / "input.mp4"
    if not src_video.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æºè§†é¢‘ï¼š{src_video}")

    # ç›´æ¥å¤åˆ¶ä¼šå¾ˆå¤§ï¼›ä¸ºäº†å¿«ï¼Œæˆ‘ä»¬å¤åˆ¶ä¸€ä¸ªå°ç‰‡æ®µï¼ˆç”¨ ffmpegï¼‰
    # ä½ å·²ç»å®‰è£…äº† ffmpegï¼Œä½† PATH å¯èƒ½ä¸ç¨³å®šï¼Œç”¨ç»å¯¹è·¯å¾„æœ€ç¨³
    ffmpeg = "/opt/homebrew/bin/ffmpeg"

    import subprocess
    cmd = [
        ffmpeg, "-y",
        "-i", str(src_video),
        "-t", "1.0",
        "-c", "copy",
        str(out_path)
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    return f"videos/{out_path.name}"

def run_video_generate(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    """
    æ‰§è¡Œ video_generate èŠ‚ç‚¹ï¼š
    - target_shot=Noneï¼šè·‘æ‰€æœ‰ NOT_STARTED æˆ– FAILED çš„ shot
    - target_shot=shot_03ï¼šåªè·‘æŒ‡å®š shotï¼ˆå•èŠ‚ç‚¹é‡è·‘ï¼‰
    """
    shots = wf.get("shots", [])
    for shot in shots:
        sid = shot.get("shot_id")

        if target_shot and sid != target_shot:
            continue

        status = shot.get("status", {}).get("video_generate", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"):
            continue

        # æ ‡è®°è¿è¡Œä¸­
        shot.setdefault("status", {})["video_generate"] = "RUNNING"
        shot.setdefault("errors", {})["video_generate"] = None
        save_workflow(job_dir, wf)

        try:
            rel_video_path = mock_generate_video(job_dir, shot)
            shot.setdefault("assets", {})["video"] = rel_video_path
            shot["status"]["video_generate"] = "SUCCESS"
            print(f"âœ… video_generate SUCCESS: {sid} -> {rel_video_path}")
        except Exception as e:
            shot["status"]["video_generate"] = "FAILED"
            shot.setdefault("errors", {})["video_generate"] = str(e)
            print(f"âŒ video_generate FAILED: {sid} -> {e}")

        save_workflow(job_dir, wf)

def mock_stylize_frame(job_dir: Path, shot: dict) -> str:
    """
    Demo ç‰ˆé£æ ¼åŒ–ï¼šæŠŠ first_frame å¤åˆ¶æˆæ–°çš„ stylized_frameï¼ˆè¦†ç›–å†™ï¼‰ã€‚
    åç»­æ¥ Nano Banana æ—¶ï¼Œåªæ›¿æ¢è¿™é‡Œã€‚
    """
    src = job_dir / shot["assets"]["first_frame"]
    if not src.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° first_frameï¼š{src}")

    dst = job_dir / "stylized_frames" / f"{shot['shot_id']}.png"
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.copyfile(src, dst)
    return f"stylized_frames/{dst.name}"

def run_stylize(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    shots = wf.get("shots", [])
    for shot in shots:
        sid = shot.get("shot_id")

        if target_shot and sid != target_shot:
            continue

        status = shot.get("status", {}).get("stylize", "NOT_STARTED")
        if not target_shot and status not in ("NOT_STARTED", "FAILED"):
            continue

        shot.setdefault("status", {})["stylize"] = "RUNNING"
        shot.setdefault("errors", {})["stylize"] = None
        save_workflow(job_dir, wf)

        try:
            rel_path = mock_stylize_frame(job_dir, shot)
            shot.setdefault("assets", {})["stylized_frame"] = rel_path
            shot["status"]["stylize"] = "SUCCESS"
            print(f"âœ… stylize SUCCESS: {sid} -> {rel_path}")
        except Exception as e:
            shot["status"]["stylize"] = "FAILED"
            shot.setdefault("errors", {})["stylize"] = str(e)
            print(f"âŒ stylize FAILED: {sid} -> {e}")

        save_workflow(job_dir, wf)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job_id", default=DEFAULT_JOB_ID)
    parser.add_argument("--node", choices=["video_generate"], default="video_generate")
    parser.add_argument("--shot", default=None, help="åªè¿è¡ŒæŸä¸ª shotï¼Œä¾‹å¦‚ shot_03")
    args = parser.parse_args()

    job_dir = PROJECT_DIR / "jobs" / args.job_id
    if not job_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° job ç›®å½•ï¼š{job_dir}")

    wf = load_workflow(job_dir)

    if args.node == "video_generate":
        # â‘  å…ˆè·‘ stylize èŠ‚ç‚¹
        run_stylize(job_dir, wf, target_shot=args.shot)

        # â‘¡ é‡æ–°åŠ è½½ workflowï¼ˆç¡®ä¿çŠ¶æ€æœ€æ–°ï¼‰
        wf = load_workflow(job_dir)

        # â‘¢ å†è·‘ video_generate èŠ‚ç‚¹
        run_video_generate(job_dir, wf, target_shot=args.shot)


    print("âœ… runner æ‰§è¡Œå®Œæˆ")

if __name__ == "__main__":
    main()
</file>

<file path="smoke_test_core.py">
from pathlib import Path
from core.workflow_io import load_workflow, save_workflow
from core.changes import replace_entity_reference
from core.runner import run_pipeline

JOB_DIR = Path("jobs/demo_job_001")

def main():
    wf = load_workflow(JOB_DIR)
    print("âœ… load_workflow ok, shots =", len(wf.get("shots", [])))

    # åšä¸€æ¬¡æ— å®³çš„ entity reference æ›¿æ¢ï¼ˆæ¢æˆè‡ªå·±å·²æœ‰çš„æ–‡ä»¶ï¼‰
    if "entity_1" in wf.get("entities", {}):
        replace_entity_reference(wf, "entity_1", "stylized_frames/shot_03.png")
        save_workflow(JOB_DIR, wf)
        print("âœ… replace_entity_reference ok")

    # è·‘ pipelineï¼ˆä¼šæŒ‰ NOT_STARTED æ‰§è¡Œï¼‰
    run_pipeline(JOB_DIR)
    print("âœ… run_pipeline ok")

if __name__ == "__main__":
    main()
</file>

<file path="stylize_frames.py">
import os
from pathlib import Path

from google import genai
from google.genai import types

PROJECT_DIR = Path(__file__).parent
FRAMES_DIR = PROJECT_DIR / "frames"
OUT_DIR = PROJECT_DIR / "stylized_frames"
OUT_DIR.mkdir(exist_ok=True)

MODEL = "gemini-2.5-flash-image"  # Nano Bananaï¼ˆæ›´å¿«ã€æ›´é€‚åˆéªŒè¯æ‰¹é‡ç¨³å®šæ€§ï¼‰
# å¦‚æœä½ ä¹‹åæƒ³ç”¨ Proï¼ˆæ›´å¼ºã€æ›´è´µï¼‰ï¼šMODEL = "gemini-3-pro-image-preview"

PROMPT = """
You are given a storyboard reference frame from a viral short video.

Goal: "De-replication stylization" (same structure, new details).
- Preserve: composition, camera angle, subject placement, overall color palette, lighting mood, and emotional tone.
- Must change: all fine details must be newly designed (faces, clothing details, textures, materials, patterns, background objects, any text/logos).
- Avoid pixel-level similarity. Do NOT copy any identifiable characters, logos, or exact text.
- Keep it cinematic and coherent.

Output:
- 16:9 image
- high clarity, rich details
"""

def save_first_image_from_response(response, out_path: Path) -> bool:
    """
    Nano Banana responses can include text parts and image parts.
    We scan parts and save the first image we find.
    """
    for part in response.parts:
        if part.inline_data is not None:
            img = part.as_image()   # requires pillow
            img.save(out_path)
            return True
    return False

def main():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡ï¼ˆè¯·å…ˆ export GEMINI_API_KEY=ä½ çš„keyï¼‰")

    if not FRAMES_DIR.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° frames æ–‡ä»¶å¤¹ï¼š{FRAMES_DIR}")

    frame_paths = sorted(FRAMES_DIR.glob("shot_*.png"))
    if not frame_paths:
        raise FileNotFoundError(f"frames é‡Œæ²¡æœ‰ shot_*.pngï¼š{FRAMES_DIR}")

    client = genai.Client(api_key=api_key)

    print(f"å°†å¤„ç† {len(frame_paths)} å¼ åˆ†é•œå›¾ï¼Œè¾“å‡ºåˆ°ï¼š{OUT_DIR}")

    for img_path in frame_paths:
        out_path = OUT_DIR / img_path.name

        # ä¼ å…¥å›¾ç‰‡ï¼ˆå®˜æ–¹æ¨èï¼štypes.Part.from_bytesï¼‰
        image_part = types.Part.from_bytes(
            data=img_path.read_bytes(),
            mime_type="image/png",
        )

        print(f"ğŸ–¼ï¸  Stylize {img_path.name} ...")

        response = client.models.generate_content(
            model=MODEL,
            contents=[
                image_part,
                PROMPT
            ],
            # å¯é€‰ï¼šå¦‚æœä½ ç”¨ gemini-3-pro-image-preview æƒ³æŒ‡å®šè¾“å‡ºå‚æ•°ï¼Œå¯ä»¥æ‰“å¼€ä¸‹é¢ config
            # config=types.GenerateContentConfig(
            #     response_modalities=["TEXT", "IMAGE"],
            #     image_config=types.ImageConfig(aspect_ratio="16:9", image_size="2K"),
            # )
        )

        ok = save_first_image_from_response(response, out_path)
        if ok:
            print(f"âœ… saved -> {out_path}")
        else:
            # æœ‰æ—¶æ¨¡å‹åªå›æ–‡å­—ï¼ˆè¡¨ç¤ºæ²¡å‡ºå›¾æˆ–è¢«æ‹’ç»/é™çº§ï¼‰ï¼ŒæŠŠæ–‡å­—æ‰“å°å‡ºæ¥ä¾¿äºä½ åšå¯è¡Œæ€§åˆ¤æ–­
            print("âš ï¸ æ²¡æ‹¿åˆ°å›¾ç‰‡è¾“å‡ºï¼Œæ¨¡å‹è¿”å›æ–‡æœ¬å¦‚ä¸‹ï¼š")
            print(response.text)

    print("âœ… å…¨éƒ¨å®Œæˆ")

if __name__ == "__main__":
    main()
</file>

<file path="test_gemini.py">
import os
from google import genai

def main():
    # ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– API Key
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡")

    client = genai.Client(api_key=api_key)

    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents="ç”¨ä¸€å¥è¯å‘Šè¯‰æˆ‘ï¼Œä½ æ˜¯è°ï¼Ÿ"
    )

    print("Gemini å›å¤ï¼š")
    print(response.text)

if __name__ == "__main__":
    main()
</file>

<file path="test_v3.py">
# test_v3.py
from core.workflow_manager import WorkflowManager

manager = WorkflowManager("demo_job_001")

# æµ‹è¯•å½¢æ€ 3ï¼šæ‰‹åŠ¨å¾®è°ƒç¬¬ 2 ä¸ªé•œå¤´çš„æè¿°
print("æµ‹è¯•å½¢æ€ 3ï¼šæ‰‹åŠ¨å¾®è°ƒåˆ†é•œ...")
manager.apply_agent_action({
    "op": "update_shot_params",
    "shot_id": "shot_02",
    "description": "ä¸€åªæ­£åœ¨æˆ´ç€å¢¨é•œè·³èˆçš„é…·ç‹—"
})

manager.load()
shot2 = [s for s in manager.workflow["shots"] if s["shot_id"] == "shot_02"][0]
print(f"åˆ†é•œ 2 æ–°æè¿°: {shot2['description']}")
print(f"åˆ†é•œ 2 çŠ¶æ€å·²é‡ç½®: {shot2['status']['video_generate']}") # åº”è¯¥æ˜¯ NOT_STARTED
print(f"å…¨å±€ Video Gen é˜¶æ®µçŠ¶æ€: {manager.workflow['global_stages']['video_gen']}")
</file>

<file path="vibe_check.py">
# vibe_check.py
from core.workflow_manager import WorkflowManager

# 1. åˆå§‹åŒ–ï¼ˆä½¿ç”¨ä½ å·²æœ‰çš„ demo_job_001ï¼‰
manager = WorkflowManager("demo_job_001")

# 2. æ¨¡æ‹Ÿå½¢æ€ 3ï¼šç›´æ¥æ”¹å…¨å±€é£æ ¼
print("æ­£åœ¨å°è¯•ä¿®æ”¹å…¨å±€é£æ ¼...")
res = manager.apply_agent_action({"op": "set_global_style", "value": "Cyberpunk Neon"})
print(f"å—å½±å“åˆ†é•œæ•°: {res['affected_shots']}")

# 3. éªŒè¯çŠ¶æ€æ˜¯å¦å˜å›äº† NOT_STARTED (è¿™æ˜¯æˆ‘ä»¬ changes.py é‡Œçš„çº§è”é€»è¾‘)
manager.load() # é‡æ–°åŠ è½½çœ‹ç£ç›˜ä¸Šçš„ç»“æœ
first_shot_status = manager.workflow["shots"][0]["status"]["video_generate"]
print(f"ä¿®æ”¹é£æ ¼åï¼ŒShot 01 çš„ç”ŸæˆçŠ¶æ€æ˜¯: {first_shot_status}")

if first_shot_status == "NOT_STARTED":
    print("âœ… åº•åº§é€»è¾‘éªŒè¯æˆåŠŸï¼")
else:
    print("âŒ çŠ¶æ€æ²¡æœ‰æ­£ç¡®é‡ç½®ï¼Œè¯·æ£€æŸ¥ core/changes.py")
</file>

<file path="video_generator.py">
import os
import time
from google import genai
from google.genai import types

# ç¡®ä¿ç¯å¢ƒå˜é‡å·²åŠ è½½
api_key = os.environ.get("GEMINI_API_KEY")
client = genai.Client(api_key=api_key)

def run_veo_generation(shot_id, prompt, image_path, output_dir="output_videos"):
    """
    é’ˆå¯¹ 2026 å¹´ Gemini 3 / Veo ç”Ÿæ€ä¼˜åŒ–çš„è§†é¢‘ç”Ÿæˆå‡½æ•°
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # 1. ä»¥äºŒè¿›åˆ¶è¯»å–é£æ ¼åŒ–åçš„å‚è€ƒå›¾
    try:
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°å›¾ç‰‡æ–‡ä»¶: {image_path}")
        return None

    print(f"ğŸš€ å¯åŠ¨ Veo 3.1 ä»»åŠ¡ | åˆ†é•œ: {shot_id}")
    
    try:
        # 2. è°ƒç”¨ä¸“é—¨çš„ generate_videos æ¥å£
        # ä¿®å¤ç‚¹ï¼šå¿…é¡»ä½¿ç”¨ generate_videos è€Œé generate_content
        operation = client.models.generate_videos(
            model="veo-3.1-generate-preview",
            prompt=prompt,
            config=types.GenerateVideosConfig(
                # ä¿®å¤ç‚¹ï¼šå‚è€ƒå›¾å¿…é¡»æ”¾åœ¨è¿™ä¸ª image å­—æ®µé‡Œ
                image=types.Part.from_bytes(
                    data=image_bytes,
                    mime_type="image/png"
                ),
                aspect_ratio="16:9"
            )
        )

        # 3. å¼‚æ­¥è½®è¯¢ (Veo è§†é¢‘ç”Ÿæˆä¸æ˜¯å³æ—¶çš„)
        print(f"â³ è§†é¢‘æ­£åœ¨äº‘ç«¯æ¸²æŸ“ (Operation ID: {operation.name})")
        while not operation.done:
            print(".", end="", flush=True)
            time.sleep(10)  # æ¯ 10 ç§’æŸ¥è¯¢ä¸€æ¬¡è¿›åº¦
            operation = client.operations.get(operation.name)

        # 4. æ£€æŸ¥ç»“æœå¹¶ä¿å­˜
        if operation.result and operation.result.generated_videos:
            generated_video = operation.result.generated_videos[0]
            output_path = os.path.join(output_dir, f"{shot_id}.mp4")
            
            # ä½¿ç”¨ SDK åŸç”Ÿ save æ–¹æ³•
            generated_video.video.save(output_path)
            print(f"\nâœ… è§†é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
            return output_path
        else:
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥ï¼ŒåŸå› : {operation.error}")
            return None

    except Exception as e:
        print(f"\nâŒ è°ƒç”¨ Veo API å‡ºç°ä¸¥é‡å¼‚å¸¸: {str(e)}")
        return None

if __name__ == "__main__":
    # æµ‹è¯•ä»£ç  (ä½ å¯ä»¥ç›´æ¥è¿è¡Œ python video_generator.py éªŒè¯)
    test_prompt = "A cinematic drone shot of a neon cyberpunk city in the rain."
    test_image = "stylized_frames/shot_01.png"
    run_veo_generation("shot_01", test_prompt, test_image)
</file>

<file path="workflow_cli.py">
import argparse
from pathlib import Path

from core.workflow_io import load_workflow, save_workflow
from core.changes import apply_global_style, replace_entity_reference
from core.runner import run_pipeline

DEFAULT_JOB_ID = "demo_job_001"
PROJECT_DIR = Path(__file__).parent

def job_dir_from_id(job_id: str) -> Path:
    return PROJECT_DIR / "jobs" / job_id

def cmd_list(job_dir: Path) -> None:
    wf = load_workflow(job_dir)
    print(f"job_id: {wf.get('job_id')}")
    print(f"global.style_prompt: {wf.get('global', {}).get('style_prompt')}")
    print("-" * 60)
    for s in wf.get("shots", []):
        sid = s.get("shot_id")
        st = s.get("status", {})
        print(f"{sid:7}  stylize={st.get('stylize')}  video={st.get('video_generate')}")

def cmd_set_style(job_dir: Path, style: str, cascade: bool) -> None:
    wf = load_workflow(job_dir)
    affected = apply_global_style(wf, style, cascade=cascade)
    save_workflow(job_dir, wf)
    print(f"âœ… style å·²æ›´æ–°ï¼š{style}")
    print(f"âœ… å—å½±å“ shotsï¼š{affected}ï¼ˆcascade={cascade}ï¼‰")

def cmd_replace_entity(job_dir: Path, entity_id: str, new_ref: str) -> None:
    wf = load_workflow(job_dir)
    affected = replace_entity_reference(wf, entity_id, new_ref)
    save_workflow(job_dir, wf)
    print(f"âœ… å·²æ›¿æ¢ {entity_id}.reference_image -> {new_ref}")
    print(f"âœ… å—å½±å“ shotsï¼š{affected}")

def cmd_run(job_dir: Path, shot: str | None) -> None:
    run_pipeline(job_dir, target_shot=shot)
    print("âœ… runner æ‰§è¡Œå®Œæˆ")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--job_id", default=DEFAULT_JOB_ID)

    sub = parser.add_subparsers(dest="cmd", required=True)

    p_list = sub.add_parser("list", help="åˆ—å‡º shots çŠ¶æ€")
    p_list.set_defaults(func="list")

    p_style = sub.add_parser("set-style", help="è®¾ç½®å…¨å±€ style_prompt")
    p_style.add_argument("style")
    p_style.add_argument("--no-cascade", action="store_true", help="ä¸çº§è”é‡è·‘ï¼ˆé»˜è®¤ä¼šçº§è”ï¼‰")
    p_style.set_defaults(func="set-style")

    p_ent = sub.add_parser("replace-entity", help="æ›¿æ¢ entity çš„ reference_imageï¼Œå¹¶æ ‡è®°å—å½±å“ shots")
    p_ent.add_argument("entity_id")
    p_ent.add_argument("new_ref")
    p_ent.set_defaults(func="replace-entity")

    p_run = sub.add_parser("run", help="è¿è¡Œ runnerï¼ˆæŒ‰ NOT_STARTED æ‰§è¡Œï¼‰")
    p_run.add_argument("--shot", default=None, help="åªè·‘æŸä¸ª shotï¼Œä¾‹å¦‚ shot_03")
    p_run.set_defaults(func="run")

    args = parser.parse_args()
    job_dir = job_dir_from_id(args.job_id)
    if not job_dir.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° job ç›®å½•ï¼š{job_dir}")

    if args.func == "list":
        cmd_list(job_dir)
    elif args.func == "set-style":
        cmd_set_style(job_dir, args.style, cascade=(not args.no_cascade))
    elif args.func == "replace-entity":
        cmd_replace_entity(job_dir, args.entity_id, args.new_ref)
    elif args.func == "run":
        cmd_run(job_dir, args.shot)

if __name__ == "__main__":
    main()
</file>

<file path="core/agent_engine.py">
# core/agent_engine.py
import os
import json
import re
from google import genai
from google.genai import types # ğŸ’¡ å¼•å…¥ç±»å‹å®šä¹‰
from typing import Dict, Any, List, Union

class AgentEngine:
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError("æœªæ£€æµ‹åˆ° GEMINI_API_KEY")
        self.client = genai.Client(api_key=api_key)
        self.model_id = "gemini-2.0-flash" 

    def get_action_from_text(self, user_input: str, workflow_summary: str) -> Union[Dict, List]:
        system_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å¯¼æ¼”åŠ©ç†ã€‚ä½ å¿…é¡»æ ¹æ®ç”¨æˆ·éœ€æ±‚ç”Ÿæˆå·¥ä½œæµä¿®æ”¹æŒ‡ä»¤ã€‚

[å½“å‰å·¥ä½œæµçŠ¶æ€æ‘˜è¦]
{workflow_summary}

[æŒ‡ä»¤é€»è¾‘è§„èŒƒ - æå…¶é‡è¦]
1. ä¿®æ”¹å…¨å±€é£æ ¼: {{"op": "set_global_style", "value": "è‹±æ–‡é£æ ¼æè¿°è¯"}}
2. å…¨å±€ä¸»ä½“æ›¿æ¢: {{"op": "global_subject_swap", "old_subject": "è‹±æ–‡åŸè¯", "new_subject": "è‹±æ–‡æ–°è¯"}}
   - æ–¹å‘é€»è¾‘ï¼šâ€œæŠŠ A æ¢æˆ Bâ€æ„å‘³ç€ A æ˜¯æ—§çš„(old)ï¼ŒB æ˜¯æ–°çš„(new)ã€‚
   - åŒ¹é…è¦æ±‚ï¼šä½ å¿…é¡»è§‚å¯Ÿ [æ‘˜è¦] ä¸­çš„ "Example Shot Description"ï¼Œæ‰¾å‡ºå…¶ä¸­çœŸæ­£å­˜åœ¨çš„è‹±æ–‡å•è¯ä½œä¸º "old_subject"ã€‚
   - ç¿»è¯‘è¦æ±‚ï¼šå¦‚æœç”¨æˆ·è¯´â€œç”·äººâ€ï¼Œè€Œæ‘˜è¦é‡Œæ˜¯ "man"ï¼Œè¯·ä½¿ç”¨ "man"ï¼›å¦‚æœç”¨æˆ·è¯´â€œå°å­©â€ï¼Œè¯·ç¿»è¯‘ä¸º "child"ã€‚

[è¾“å‡ºè¦æ±‚]
- å¿…é¡»è¯†åˆ«ç”¨æˆ·çš„æ‰€æœ‰æ„å›¾ã€‚
- å¿…é¡»è¿”å›ä¸€ä¸ªåŒ…å«æŒ‡ä»¤å¯¹è±¡çš„ JSON åˆ—è¡¨ []ï¼Œå³ä½¿åªæœ‰ä¸€æ¡æŒ‡ä»¤ä¹Ÿè¦æ”¾åœ¨åˆ—è¡¨é‡Œã€‚
- ä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ï¼Œåªè¾“å‡ºçº¯ JSON å­—ç¬¦ä¸²ã€‚
"""
        try:
            # ğŸ’¡ å¼ºåˆ¶ JSON æ¨¡å¼ï¼Œç¡®ä¿è¾“å‡ºç»“æ„ç¨³å®š
            response = self.client.models.generate_content(
                model=self.model_id,
                contents=[system_prompt, f"ç”¨æˆ·æŒ‡ä»¤: {user_input}"],
                config=types.GenerateContentConfig(
                    response_mime_type='application/json',
                )
            )
            
            # è‡ªåŠ¨è§£æ JSON å­—ç¬¦ä¸²
            res_json = json.loads(response.text)
            
            # è°ƒè¯•æ—¥å¿—ï¼šåœ¨ç»ˆç«¯æ‰“å° Agent çš„å†³ç­–é€»è¾‘
            print(f"ğŸ¤– Agent å†³ç­–æŒ‡ä»¤é›†: {res_json}")
            
            return res_json
            
        except Exception as e:
            print(f"âŒ Agent å†³ç­–è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            if 'response' in locals() and hasattr(response, 'candidates'):
                print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - åœæ­¢åŸå› : {response.candidates[0].finish_reason}")
            return {"op": "error", "reason": str(e)}
</file>

<file path="app.py">
# app.py
import os
import uuid
import shutil
from pathlib import Path
from fastapi import FastAPI, HTTPException, BackgroundTasks, UploadFile, File
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import Optional, Dict, Any, List, Union

from core.workflow_manager import WorkflowManager
from core.agent_engine import AgentEngine

app = FastAPI(title="AI å¯¼æ¼”å·¥ä½œå° API")

# 1. è·¨åŸŸé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. åˆå§‹åŒ–æ ¸å¿ƒå¼•æ“
manager = WorkflowManager() 
agent = AgentEngine()

# --- æ•°æ®æ¨¡å‹ ---
class ChatRequest(BaseModel):
    message: str
    job_id: Optional[str] = None 

class ShotUpdateRequest(BaseModel):
    shot_id: str
    description: Optional[str] = None
    video_model: Optional[str] = None
    job_id: Optional[str] = None

# --- è·¯ç”±æ¥å£ ---

@app.get("/")
async def read_index():
    return FileResponse('index.html')

@app.post("/api/upload")
async def upload_video(file: UploadFile = File(...)):
    print(f"ğŸ“¥ [æ”¶åˆ°æ–‡ä»¶] æ­£åœ¨æ¥æ”¶ä¸Šä¼ : {file.filename}") 
    try:
        temp_dir = Path("temp_uploads")
        temp_dir.mkdir(exist_ok=True)
        temp_file_path = temp_dir / f"{uuid.uuid4()}_{file.filename}"
        
        with open(temp_file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        print(f"ğŸ§  [AI å¯åŠ¨] æ­£åœ¨è°ƒç”¨ Gemini 1.5 Pro æ‹†è§£åˆ†é•œï¼Œè¯·è€å¿ƒç­‰å¾…...")
        new_job_id = manager.initialize_from_file(temp_file_path)
        
        if temp_file_path.exists():
            os.remove(temp_file_path)
            
        print(f"âœ… [å…¨éƒ¨å®Œæˆ] æ–°é¡¹ç›®å·²å°±ç»ª: {new_job_id}")
        return {"status": "success", "job_id": new_job_id}
    except Exception as e:
        print(f"âŒ [æŠ¥é”™] ä¸Šä¼ æ‹†è§£ç¯èŠ‚å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/workflow")
async def get_workflow(job_id: Optional[str] = None):
    target_id = job_id or manager.job_id
    if not target_id:
        jobs_dir = Path("jobs")
        if jobs_dir.exists():
            existing_jobs = sorted([d.name for d in jobs_dir.iterdir() if d.is_dir()], reverse=True)
            if existing_jobs: target_id = existing_jobs[0]
    
    if not target_id:
        return {"error": "No jobs found"}
        
    manager.job_id = target_id
    manager.job_dir = Path(__file__).parent / "jobs" / target_id
    return manager.load()

@app.post("/api/agent/chat")
async def agent_chat(req: ChatRequest):
    if req.job_id: 
        manager.job_id = req.job_id
        manager.job_dir = Path(__file__).parent / "jobs" / req.job_id
        
    wf = manager.load()
    example_desc = wf.get("shots")[0].get("description", "") if wf.get("shots") else ""
    summary = f"Job ID: {manager.job_id}\nGlobal Style: {wf.get('global', {}).get('style_prompt')}\nSample Desc: {example_desc}"
    
    action = agent.get_action_from_text(req.message, summary)
    if isinstance(action, list) or (isinstance(action, dict) and action.get("op") != "error"):
        res = manager.apply_agent_action(action)
        return {"action": action, "result": res}
    return {"action": action, "result": {"status": "error"}}

@app.post("/api/shot/update")
async def update_shot_params(req: ShotUpdateRequest):
    if req.job_id:
        manager.job_id = req.job_id
        manager.job_dir = Path(__file__).parent / "jobs" / req.job_id
    manager.load()
    action = {
        "op": "update_shot_params",
        "shot_id": req.shot_id,
        "description": req.description
    }
    res = manager.apply_agent_action(action)
    return res

@app.post("/api/run/{node_type}")
async def run_task(node_type: str, background_tasks: BackgroundTasks, shot_id: Optional[str] = None, job_id: Optional[str] = None):
    # ğŸ’¡ ç»Ÿä¸€åŒæ­¥ manager çš„ Job æŒ‡å‘
    if job_id:
        manager.job_id = job_id
        manager.job_dir = Path(__file__).parent / "jobs" / job_id

    # ğŸ’¡ æ ¸å¿ƒæ–°å¢ï¼šå¤„ç†åˆå¹¶å¯¼å‡ºé€»è¾‘
    if node_type == "merge":
        print(f"ğŸ¬ æ”¶åˆ°åˆå¹¶è¯·æ±‚ï¼Œç›®æ ‡ Job: {manager.job_id}")
        manager.load() # ç¡®ä¿çŠ¶æ€æœ€æ–°
        try:
            result_file = manager.merge_videos()
            return {"status": "success", "file": result_file, "job_id": manager.job_id}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    if node_type not in ["stylize", "video_generate"]:
        raise HTTPException(status_code=400, detail="Invalid node type")
    
    background_tasks.add_task(manager.run_node, node_type, shot_id)
    return {"status": "started", "job_id": manager.job_id}

# --- æ ¸å¿ƒï¼šé˜²ç¼“å­˜ä¸èµ„æºæ˜ å°„ ---
@app.middleware("http")
async def add_no_cache_header(request, call_next):
    response = await call_next(request)
    if request.url.path.startswith("/assets"):
        response.headers["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
    return response

app.mount("/assets", StaticFiles(directory="jobs"), name="assets")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
</file>

<file path="core/runner.py">
# core/runner.py
from pathlib import Path
import shutil
import subprocess
import time
import os
import requests 
import io
from PIL import Image

from .workflow_io import save_workflow, load_workflow


def ensure_videos_dir(job_dir: Path) -> Path:
    videos_dir = job_dir / "videos"
    videos_dir.mkdir(parents=True, exist_ok=True)
    return videos_dir


def ai_stylize_frame(job_dir: Path, wf: dict, shot: dict) -> str:
    """
    ğŸ’¡ æ ¸å¿ƒå‡çº§ï¼šè°ƒç”¨çœŸæ­£çš„ AI æ¨¡å‹ç”Ÿæˆé£æ ¼åŒ–å‚è€ƒå›¾ (å®šå¦†å›¾)
    """
    from google import genai
    from google.genai import types

    api_key = os.getenv("GEMINI_API_KEY")
    client = genai.Client(api_key=api_key)
    
    src = job_dir / shot["assets"]["first_frame"]
    if not src.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°åŸå§‹åˆ†é•œå¸§ï¼š{src}")

    dst = job_dir / "stylized_frames" / f"{shot['shot_id']}.png"
    dst.parent.mkdir(parents=True, exist_ok=True)

    # å‡†å¤‡ Promptï¼šç»“åˆå…¨å±€é£æ ¼å’Œåˆ†é•œæè¿°
    global_style = wf.get("global", {}).get("style_prompt", "Realistic")
    description = shot.get("description", "")
    
    prompt = f"""
    You are an expert storyboard artist. 
    Goal: Generate a high-quality stylized reference frame.
    Subject and Action: {description}
    Style: {global_style}
    Requirement: Maintain the composition of the provided source image but transform the subjects and art style according to the prompt.
    Output: 16:9 cinematic image.
    """

    print(f"ğŸ–¼ï¸  AI æ­£åœ¨æ‰§è¡Œé£æ ¼åŒ–é‡ç»˜: {shot['shot_id']} (Prompt: {description})")
    
    # å°†æœ¬åœ°å›¾ç‰‡è½¬ä¸º API å¯ç”¨çš„ Part
    image_part = types.Part.from_bytes(
        data=src.read_bytes(),
        mime_type="image/png",
    )

    try:
        # è°ƒç”¨ Gemini 2.0 Flash ç”Ÿæˆå›¾åƒ
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ generate_content é…åˆ response_modalities=["IMAGE"]
        response = client.models.generate_content(
            model="gemini-2.0-flash", # ä½¿ç”¨ 2.0 æ¨¡å‹
            contents=[image_part, prompt],
            config=types.GenerateContentConfig(
                response_modalities=["IMAGE"],
            )
        )

        # å¯»æ‰¾å¹¶ä¿å­˜è¿”å›çš„å›¾ç‰‡
        for part in response.parts:
            if part.inline_data is not None:
                img = Image.open(io.BytesIO(part.inline_data.data))
                img.save(dst)
                return f"stylized_frames/{dst.name}"
        
        # å¦‚æœæ¨¡å‹æ²¡æœ‰è¿”å›å›¾ç‰‡ï¼ˆå¯èƒ½ç”±äºå®‰å…¨å®¡æ ¸æˆ–æ¨¡å‹é™åˆ¶ï¼‰
        print(f"âš ï¸ æ¨¡å‹æœªç›´æ¥ç”Ÿæˆå›¾ç‰‡ï¼Œå°è¯•æ‰§è¡Œå…œåº•å¤åˆ¶é€»è¾‘")
        shutil.copyfile(src, dst)
        return f"stylized_frames/{dst.name}"

    except Exception as e:
        print(f"âŒ AI ç”Ÿå›¾å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå›¾å ä½")
        shutil.copyfile(src, dst)
        return f"stylized_frames/{dst.name}"


def mock_generate_video(job_dir: Path, shot: dict) -> str:
    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"
    
    if out_path.exists():
        os.remove(out_path)

    src_video = job_dir / "input.mp4"
    if not src_video.exists():
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æºè§†é¢‘ï¼š{src_video}")
    ffmpeg = "/opt/homebrew/bin/ffmpeg"
    cmd = [
        ffmpeg, "-y",
        "-i", str(src_video),
        "-t", "1.0",
        "-c", "copy",
        str(out_path)
    ]
    subprocess.run(cmd, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return f"videos/{out_path.name}"


def veo_generate_video(job_dir: Path, wf: dict, shot: dict) -> str:
    from google import genai
    from google.genai import types

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("æ²¡æœ‰æ£€æµ‹åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡")

    videos_dir = ensure_videos_dir(job_dir)
    out_path = videos_dir / f"{shot['shot_id']}.mp4"

    if out_path.exists():
        print(f"ğŸ—‘ï¸ å‡†å¤‡ç”Ÿæˆæ–°è§†é¢‘ï¼Œæ¸…ç†æ—§æ–‡ä»¶: {out_path}")
        os.remove(out_path)

    img_rel = shot.get("assets", {}).get("stylized_frame")
    if not img_rel:
        img_rel = f"stylized_frames/{shot['shot_id']}.png"
    
    img_path = job_dir / img_rel

    if not img_path.exists():
        print(f"ğŸ•µï¸ æ£€æŸ¥ï¼šåˆ†é•œ {shot['shot_id']} ç¼ºå¤±å‚è€ƒå›¾ï¼Œæ­£åœ¨å¯åŠ¨ AI è¡¥å…¨...")
        try:
            # ğŸ’¡ å†…éƒ¨ä¿®å¤ï¼šè°ƒç”¨çœŸæ­£çš„ AI é£æ ¼åŒ–
            recovered_rel_path = ai_stylize_frame(job_dir, wf, shot)
            shot.setdefault("assets", {})["stylized_frame"] = recovered_rel_path
            shot.setdefault("status", {})["stylize"] = "SUCCESS"
            save_workflow(job_dir, wf)
            img_path = job_dir / recovered_rel_path
        except Exception as recovery_error:
            raise RuntimeError(f"å‚è€ƒå›¾è¡¥å…¨å¤±è´¥ï¼Œæ— æ³•å¯åŠ¨ Veo: {recovery_error}")

    client = genai.Client(api_key=api_key, http_options={'api_version': 'v1alpha'})

    print(f"ğŸš€ å‘èµ· Veo çœŸå®æ¸²æŸ“ (Shot: {shot['shot_id']})")
    operation = client.models.generate_videos(
        model="veo-3.1-generate-preview", 
        prompt=f"Cinematic video, {shot.get('description', '')}. Style: {wf.get('global', {}).get('style_prompt', '')}.",
        image=types.Image(
            image_bytes=img_path.read_bytes(),
            mime_type="image/png"
        ),
        config=types.GenerateVideosConfig(
            number_of_videos=1,
            duration_seconds=6.0
        ),
    )

    while not operation.done:
        time.sleep(20)
        operation = client.operations.get(operation)
        print(f"â³ Veo æ­£åœ¨æ¸²æŸ“ä¸­...")

    if operation.error:
        raise RuntimeError(f"Veo åç«¯æŠ¥é”™: {operation.error}")

    resp = operation.response
    if not resp or not hasattr(resp, 'generated_videos') or not resp.generated_videos:
        raise RuntimeError("Veo æœªè¿”å›è§†é¢‘å†…å®¹ã€‚è¯·æ£€æŸ¥å®‰å…¨è¿‡æ»¤æˆ–é…é¢ã€‚")

    video_obj = resp.generated_videos[0].video
    file_id = getattr(video_obj, 'name', None) or f"files/{video_obj.uri.split('/')[-1]}"

    download_url = f"https://generativelanguage.googleapis.com/v1beta/{file_id}"
    query_params = {'alt': 'media', 'key': api_key}

    try:
        response = requests.get(download_url, params=query_params, stream=True)
        if response.status_code != 200:
            alpha_url = f"https://generativelanguage.googleapis.com/v1alpha/{file_id}"
            response = requests.get(alpha_url, params=query_params, stream=True)

        if response.status_code == 200:
            with open(out_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=1024*1024): 
                    if chunk: f.write(chunk)
            print(f"ğŸ’¾ è§†é¢‘ä¸‹è½½æˆåŠŸ: {out_path}")
        else:
            raise RuntimeError(f"ä¸‹è½½å¤±è´¥ã€‚çŠ¶æ€ç : {response.status_code}")
            
    except Exception as e:
        raise e

    return f"videos/{out_path.name}"


def run_stylize(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot: continue
        status = shot.get("status", {}).get("stylize", "NOT_STARTED")
        # ğŸ’¡ æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœæŒ‡å®šäº†åˆ†é•œï¼Œå³ä½¿æ˜¯ RUNNING ä¹Ÿå¼ºåˆ¶æ‰§è¡Œï¼Œé¿å…æ­»é”
        if not target_shot and status not in ("NOT_STARTED", "FAILED"): continue
        
        shot.setdefault("status", {})["stylize"] = "RUNNING"
        save_workflow(job_dir, wf)
        try:
            rel_path = ai_stylize_frame(job_dir, wf, shot)
            shot.setdefault("assets", {})["stylized_frame"] = rel_path
            shot["status"]["stylize"] = "SUCCESS"
            print(f"âœ… stylize SUCCESS: {sid}")
        except Exception as e:
            shot["status"]["stylize"] = "FAILED"
            shot.setdefault("errors", {})["stylize"] = str(e)
            print(f"âŒ stylize FAILED: {sid} -> {e}")
        save_workflow(job_dir, wf)


def run_video_generate(job_dir: Path, wf: dict, target_shot: str | None = None) -> None:
    for shot in wf.get("shots", []):
        sid = shot.get("shot_id")
        if target_shot and sid != target_shot: continue
        status = shot.get("status", {}).get("video_generate", "NOT_STARTED")
        # ğŸ’¡ æ ¸å¿ƒä¿®å¤ï¼šå¦‚æœæŒ‡å®šäº†åˆ†é•œï¼Œå³ä½¿æ˜¯ RUNNING ä¹Ÿå¼ºåˆ¶æ‰§è¡Œï¼Œé¿å…æ­»é”
        if not target_shot and status not in ("NOT_STARTED", "FAILED"): continue
        
        shot.setdefault("status", {})["video_generate"] = "RUNNING"
        save_workflow(job_dir, wf)
        try:
            video_model = wf.get("global", {}).get("video_model", "mock")
            if video_model == "veo":
                rel_video_path = veo_generate_video(job_dir, wf, shot)
            else:
                rel_video_path = mock_generate_video(job_dir, shot)
            shot.setdefault("assets", {})["video"] = rel_video_path
            shot["status"]["video_generate"] = "SUCCESS"
            print(f"âœ… video_generate SUCCESS: {sid}")
        except Exception as e:
            shot["status"]["video_generate"] = "FAILED"
            shot.setdefault("errors", {})["video_generate"] = str(e)
            print(f"âŒ video_generate FAILED: {sid}")
        save_workflow(job_dir, wf)


def run_pipeline(job_dir: Path, target_shot: str | None = None) -> None:
    wf = load_workflow(job_dir)
    run_stylize(job_dir, wf, target_shot=target_shot)
    wf = load_workflow(job_dir)
    run_video_generate(job_dir, wf, target_shot=target_shot)
</file>

<file path="core/workflow_manager.py">
# core/workflow_manager.py
import json
import time
import os
import re
import uuid
import subprocess
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional, Union

from core.workflow_io import load_workflow, save_workflow
from core.changes import apply_global_style, replace_entity_reference
from core.runner import run_pipeline, run_stylize, run_video_generate

# å¼•å…¥æ‹†è§£æ‰€éœ€çš„åº“å’Œé€»è¾‘
from google import genai
from analyze_video import DIRECTOR_METAPROMPT, wait_until_file_active, extract_json_array
from extract_frames import to_seconds

class WorkflowManager:
    def __init__(self, job_id: Optional[str] = None, project_root: Optional[Path] = None):
        self.project_dir = project_root or Path(__file__).parent.parent
        self.job_id = job_id
        self.workflow: Dict[str, Any] = {}
        
        if job_id:
            self.job_dir = self.project_dir / "jobs" / job_id
            if (self.job_dir / "workflow.json").exists():
                self.load()

    def initialize_from_file(self, temp_video_path: Path) -> str:
        """å…¨è‡ªåŠ¨åˆå§‹åŒ–ç®¡çº¿ï¼šå®Œæˆæ‹†è§£ä¸åŸå§‹ç´ ææå–"""
        new_id = f"job_{uuid.uuid4().hex[:8]}"
        self.job_id = new_id
        self.job_dir = self.project_dir / "jobs" / new_id
        
        self.job_dir.mkdir(parents=True, exist_ok=True)
        (self.job_dir / "frames").mkdir(exist_ok=True)
        (self.job_dir / "videos").mkdir(exist_ok=True)
        (self.job_dir / "source_segments").mkdir(exist_ok=True)
        (self.job_dir / "stylized_frames").mkdir(exist_ok=True)
        
        final_video_path = self.job_dir / "input.mp4"
        shutil.move(str(temp_video_path), str(final_video_path))
        
        print(f"ğŸš€ [Phase 1] æ­£åœ¨é€šè¿‡ Gemini æ‹†è§£è§†é¢‘: {new_id}...")
        storyboard = self._run_gemini_analysis(final_video_path)
        
        print(f"ğŸš€ [Phase 2] æ­£åœ¨æå–å…³é”®å¸§ä¸åŸå§‹åˆ†é•œçŸ­ç‰‡...")
        self._run_ffmpeg_extraction(final_video_path, storyboard)
        
        shots = []
        for s in storyboard:
            shot_num = int(s.get("shot_number", 1))
            sid = f"shot_{shot_num:02d}"
            shots.append({
                "shot_id": sid,
                "start_time": s.get("start_time"),
                "end_time": s.get("end_time"),
                "description": s.get("frame_description") or s.get("content_analysis"),
                "entities": [],
                "assets": {
                    "first_frame": f"frames/{sid}.png",
                    "source_video_segment": f"source_segments/{sid}.mp4",
                    "stylized_frame": None, # ğŸ’¡ PMé€»è¾‘ï¼šåˆå§‹åŒ–ä¸ºç©ºï¼Œå¿…é¡»å…ˆç»è¿‡ç”Ÿå›¾ç¯èŠ‚
                    "video": None
                },
                "status": {
                    "stylize": "NOT_STARTED",
                    "video_generate": "NOT_STARTED"
                }
            })
            
        self.workflow = {
            "job_id": new_id,
            "source_video": "input.mp4",
            "global": {"style_prompt": "Cinematic Realistic", "video_model": "veo"},
            "global_stages": {
                "analyze": "SUCCESS", "extract": "SUCCESS", 
                "stylize": "NOT_STARTED", "video_gen": "NOT_STARTED", "merge": "NOT_STARTED"
            },
            "shots": shots,
            "meta": {"attempts": 0, "updated_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())}
        }
        
        self.save()
        print(f"âœ… [Done] è§†é¢‘æ‹†è§£ä¸åˆ‡ç‰‡å®Œæˆï¼ŒJob ID: {new_id}")
        return new_id

    def _run_gemini_analysis(self, video_path: Path):
        api_key = os.getenv("GEMINI_API_KEY")
        client = genai.Client(api_key=api_key)
        uploaded = client.files.upload(file=str(video_path))
        video_file = wait_until_file_active(client, uploaded)
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[DIRECTOR_METAPROMPT, video_file],
        )
        return extract_json_array(response.text)

    def _run_ffmpeg_extraction(self, video_path: Path, storyboard: List):
        ffmpeg_path = "/opt/homebrew/bin/ffmpeg"
        for s in storyboard:
            ts = to_seconds(s.get("start_time"))
            duration = to_seconds(s.get("end_time")) - ts
            sid = f"shot_{int(s['shot_number']):02d}"
            img_out = self.job_dir / "frames" / f"{sid}.png"
            subprocess.run([ffmpeg_path, "-y", "-ss", str(ts), "-i", str(video_path), "-frames:v", "1", "-q:v", "2", str(img_out)], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            video_segment_out = self.job_dir / "source_segments" / f"{sid}.mp4"
            subprocess.run([ffmpeg_path, "-y", "-ss", str(ts), "-t", str(duration), "-i", str(video_path), "-c", "copy", str(video_segment_out)], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

    def load(self):
        """åŠ è½½çŠ¶æ€å¹¶å¯¹é½ç‰©ç†æ–‡ä»¶çŠ¶æ€"""
        self.workflow = load_workflow(self.job_dir)
        if "global_stages" not in self.workflow:
            self.workflow["global_stages"] = {"analyze": "SUCCESS", "extract": "SUCCESS", "stylize": "NOT_STARTED", "video_gen": "NOT_STARTED", "merge": "NOT_STARTED"}

        updated = False
        for shot in self.workflow.get("shots", []):
            sid = shot.get("shot_id")
            status_node = shot.get("status", {})
            
            # 1. é£æ ¼åŒ–å‚è€ƒå›¾ç‰©ç†å¯¹é½
            stylized_path = self.job_dir / "stylized_frames" / f"{sid}.png"
            if stylized_path.exists() and status_node.get("stylize") != "SUCCESS":
                status_node["stylize"] = "SUCCESS"
                shot["assets"]["stylized_frame"] = f"stylized_frames/{sid}.png"
                updated = True

            # 2. è§†é¢‘äº§ç‰©ç‰©ç†å¯¹é½
            video_output_path = self.job_dir / "videos" / f"{sid}.mp4"
            if video_output_path.exists() and status_node.get("video_generate") != "SUCCESS":
                status_node["video_generate"] = "SUCCESS"
                shot.setdefault("assets", {})["video"] = f"videos/{sid}.mp4"
                updated = True
            elif status_node.get("video_generate") == "SUCCESS" and not video_output_path.exists():
                status_node["video_generate"] = "NOT_STARTED"
                shot.setdefault("assets", {})["video"] = None
                updated = True
        
        if updated: self.save()
        return self.workflow

    def save(self):
        self.workflow.setdefault("meta", {})["updated_at"] = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
        save_workflow(self.job_dir, self.workflow)

    def apply_agent_action(self, action: Union[Dict, List]) -> Dict[str, Any]:
        """å¤„ç†ä¿®æ”¹æ„å›¾ï¼šå¼ºåˆ¶é‡ç½®åç»­æ‰€æœ‰ä¾èµ–èŠ‚ç‚¹"""
        actions = action if isinstance(action, list) else [action]
        total_affected = 0
        for act in actions:
            op = act.get("op")
            
            if op == "set_global_style":
                affected = apply_global_style(self.workflow, act.get("value"), cascade=True)
                if affected > 0:
                    for s in self.workflow.get("shots", []):
                        v_path = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                        if v_path.exists(): os.remove(v_path)
                        i_path = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                        if i_path.exists(): os.remove(i_path)
                        s["status"]["stylize"] = "NOT_STARTED"
                        s["status"]["video_generate"] = "NOT_STARTED"
                        s["assets"]["video"] = None
                        s["assets"]["stylized_frame"] = None
                total_affected += affected
                
            elif op == "global_subject_swap":
                old_s = act.get("old_subject", "").lower()
                new_s = act.get("new_subject", "").lower()
                if old_s and new_s:
                    for s in self.workflow.get("shots", []):
                        if old_s in s["description"].lower():
                            s["description"] = re.sub(old_s, new_s, s["description"], flags=re.IGNORECASE)
                            s["status"]["stylize"] = "NOT_STARTED"
                            s["status"]["video_generate"] = "NOT_STARTED"
                            v_path = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                            if v_path.exists(): os.remove(v_path)
                            i_path = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                            if i_path.exists(): os.remove(i_path)
                            s["assets"]["video"] = None
                            s["assets"]["stylized_frame"] = None
                            total_affected += 1
                            
            elif op == "update_shot_params":
                sid = act.get("shot_id")
                for s in self.workflow.get("shots", []):
                    if s["shot_id"] == sid:
                        if "description" in act: s["description"] = act["description"]
                        s["status"]["stylize"] = "NOT_STARTED"
                        s["status"]["video_generate"] = "NOT_STARTED"
                        v_path = self.job_dir / "videos" / f"{sid}.mp4"
                        if v_path.exists(): os.remove(v_path)
                        i_path = self.job_dir / "stylized_frames" / f"{sid}.png"
                        if i_path.exists(): os.remove(i_path)
                        s["assets"]["video"] = None
                        s["assets"]["stylized_frame"] = None
                        total_affected += 1
                        break
                        
        if total_affected > 0: self.save()
        return {"status": "success", "affected_shots": total_affected}

    def run_node(self, node_type: str, shot_id: Optional[str] = None):
        """ğŸ’¡ æ ¸å¿ƒé‡ç»„ï¼šé€»è¾‘ç¼–æ’å¼•æ“ã€‚ç¡®ä¿â€˜å…ˆæœ‰å›¾ï¼Œåæœ‰è§†é¢‘â€™ä¸”æ— æ­»é”"""
        self.workflow.setdefault("meta", {}).setdefault("attempts", 0)
        self.workflow["meta"]["attempts"] += 1
        
        # 1. ç¡®å®šæœ¬æ¬¡æ“ä½œå½±å“çš„èŒƒå›´
        target_shots = [s for s in self.workflow.get("shots", []) if not shot_id or s["shot_id"] == shot_id]

        # 2. ä¾èµ–é¡¹æ£€æŸ¥ï¼šå¦‚æœè¦ç”Ÿè§†é¢‘ï¼Œå¿…é¡»ç¡®ä¿é£æ ¼åŒ–å›¾å·²å­˜åœ¨ä¸”æˆåŠŸ
        if node_type == "video_generate":
            for s in target_shots:
                if s["status"].get("stylize") != "SUCCESS":
                    print(f"ğŸ”— [Dependency] åˆ†é•œ {s['shot_id']} ç¼ºå°‘å®šå¦†å›¾ï¼Œæ­£åœ¨å‰ç½®ç”Ÿæˆ...")
                    # ğŸ’¡ æ³¨æ„ï¼šæ­¤å¤„ç›´æ¥è°ƒç”¨ runnerï¼Œä¸è¦åœ¨ Manager é‡Œé¢„è®¾ RUNNING çŠ¶æ€ï¼Œé˜²æ­¢å“è·‘ runner
                    run_stylize(self.job_dir, self.workflow, target_shot=s["shot_id"])
                    # æ‰§è¡Œå®Œåç‰©ç†æ£€æŸ¥ä¸€æ¬¡
                    i_file = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                    if i_file.exists(): 
                        s["status"]["stylize"] = "SUCCESS"
                        s["assets"]["stylized_frame"] = f"stylized_frames/{s['shot_id']}.png"

        # 3. å‡†å¤‡æ‰§è¡Œï¼šæ›´æ–°å…¨å±€è¿›åº¦ï¼Œå¹¶ç‰©ç†æ¸…åœº
        # ğŸ’¡ æ ¸å¿ƒä¿®å¤ï¼šManager ä¸å†é¢„è®¾ RUNNINGï¼Œåªè´Ÿè´£ç‰©ç†æ¸…åœºå’Œæ ‡è®° NOT_STARTED
        stage_key = "video_gen" if node_type == "video_generate" else "stylize"
        self.workflow["global_stages"][stage_key] = "RUNNING"

        for s in target_shots:
            if node_type == "video_generate":
                v_file = self.job_dir / "videos" / f"{s['shot_id']}.mp4"
                if v_file.exists(): os.remove(v_file)
                s["status"]["video_generate"] = "NOT_STARTED" # ğŸ‘ˆ äº¤ç»™ runner å»å˜ RUNNING
                s["assets"]["video"] = None
            elif node_type == "stylize":
                i_file = self.job_dir / "stylized_frames" / f"{s['shot_id']}.png"
                if i_file.exists(): os.remove(i_file)
                s["status"]["stylize"] = "NOT_STARTED" # ğŸ‘ˆ äº¤ç»™ runner å»å˜ RUNNING
                s["assets"]["stylized_frame"] = None

        self.save() # å¿…é¡»å…ˆå­˜ç›˜ï¼Œè®© runner è¯»åˆ° NOT_STARTED

        # 4. æ­£å¼è°ƒç”¨ Runner
        if node_type == "stylize": 
            run_stylize(self.job_dir, self.workflow, target_shot=shot_id)
        elif node_type == "video_generate": 
            run_video_generate(self.job_dir, self.workflow, target_shot=shot_id)
        
        self.load() # æœ€ç»ˆåŒæ­¥çŠ¶æ€

    def _get_shot_by_id(self, shot_id: str) -> Optional[Dict]:
        for s in self.workflow.get("shots", []):
            if s.get("shot_id") == shot_id: return s
        return None

    def merge_videos(self) -> str:
        """æ‰§è¡Œæ— æŸåˆå¹¶"""
        ffmpeg_path = "/opt/homebrew/bin/ffmpeg"
        success_shots = [s for s in self.workflow.get("shots", []) if s["status"].get("video_generate") == "SUCCESS"]
        if not success_shots: raise RuntimeError("æ²¡æœ‰å¯åˆå¹¶çš„åˆ†é•œè§†é¢‘ã€‚")
        success_shots.sort(key=lambda x: x["shot_id"])
        concat_list_path = self.job_dir / "concat_list.txt"
        output_video_path = self.job_dir / "final_output.mp4"
        with open(concat_list_path, "w", encoding="utf-8") as f:
            for s in success_shots:
                v_rel_path = s["assets"].get("video")
                if v_rel_path:
                    abs_v_path = (self.job_dir / v_rel_path).absolute()
                    f.write(f"file '{abs_v_path}'\n")
        cmd = [ffmpeg_path, "-y", "-f", "concat", "-safe", "0", "-i", str(concat_list_path), "-c", "copy", str(output_video_path)]
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0: raise RuntimeError(f"åˆå¹¶å¤±è´¥: {result.stderr}")
        if "global_stages" in self.workflow:
            self.workflow["global_stages"]["merge"] = "SUCCESS"
        self.save()
        return "final_output.mp4"
</file>

<file path="index.html">
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI å¯¼æ¼”å·¥ä½œå° - æœ€ç»ˆäº¤ä»˜ç‰ˆæœ¬</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;700&family=Inter:wght@400;600;900&display=swap');
        body { font-family: 'Inter', sans-serif; background-color: #020617; color: #f8fafc; overflow: hidden; }
        .glass { background: rgba(15, 23, 42, 0.85); backdrop-filter: blur(16px); border: 1px solid rgba(255,255,255,0.08); }
        .node-line { stroke: #3b82f6; stroke-width: 2; fill: none; stroke-opacity: 0.2; transition: stroke-opacity 0.3s; }
        .node-line-active { stroke: #3b82f6; stroke-width: 3; stroke-dasharray: 8; animation: flow 1s linear infinite; stroke-opacity: 1; }
        @keyframes flow { from { stroke-dashoffset: 16; } to { stroke-dashoffset: 0; } }
        .custom-scrollbar::-webkit-scrollbar { width: 4px; }
        .custom-scrollbar::-webkit-scrollbar-thumb { background: #1e293b; border-radius: 10px; }
        .canvas-bg { background-image: radial-gradient(circle, #1e293b 1.5px, transparent 1.5px); background-size: 30px 30px; }
        .no-select { user-select: none; }
        .sidebar-transition { transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1); }
    </style>
</head>
<body>
    <div id="root"></div>

    <script type="text/babel">
        const { useState, useEffect, useRef } = React;

        const App = () => {
            const [workflow, setWorkflow] = useState(null);
            const [currentJobId, setCurrentJobId] = useState(null);
            const [viewMode, setViewMode] = useState('grid'); 
            const [messages, setMessages] = useState([{ role: 'ai', text: 'æˆ‘æ˜¯æ‚¨çš„ AI æŒ‡æŒ¥å®˜ã€‚ä¸Šä¼ è§†é¢‘åæˆ‘å°†å¼€å§‹å…¨è‡ªåŠ¨æ‹†è§£ã€‚' }]);
            const [inputText, setInputText] = useState('');
            const [loading, setLoading] = useState(false);
            const [uploading, setUploading] = useState(false);
            const [isAgentVisible, setIsAgentVisible] = useState(true);

            // ç”»å¸ƒç¼©æ”¾å’Œæ‹–æ‹½çŠ¶æ€
            const [transform, setTransform] = useState({ x: 80, y: 50, scale: 0.5 });
            const isDragging = useRef(false);
            const lastMousePos = useRef({ x: 0, y: 0 });

            // 1. è·å–æ•°æ®
            const fetchWorkflow = async (jobId) => {
                try {
                    const targetId = jobId || currentJobId;
                    const url = targetId ? `/api/workflow?job_id=${targetId}` : '/api/workflow';
                    const res = await fetch(url);
                    const data = await res.json();
                    if (data && data.job_id) {
                        setWorkflow(data);
                        setCurrentJobId(data.job_id);
                    }
                } catch (e) { console.error("Update failed", e); }
            };

            useEffect(() => { fetchWorkflow(); }, []);
            useEffect(() => {
                const timer = setInterval(() => { if (currentJobId && !uploading) fetchWorkflow(currentJobId); }, 3000);
                return () => clearInterval(timer);
            }, [currentJobId, uploading]);

            // 2. ç”»å¸ƒäº¤äº’é€»è¾‘ (Zoom & Pan)
            const handleWheel = (e) => {
                if (viewMode !== 'graph') return;
                const delta = e.deltaY > 0 ? -0.05 : 0.05;
                setTransform(prev => ({ ...prev, scale: Math.min(Math.max(prev.scale + delta, 0.1), 1.5) }));
            };
            const handleMouseDown = (e) => {
                if (viewMode === 'graph') { isDragging.current = true; lastMousePos.current = { x: e.clientX, y: e.clientY }; }
            };
            const handleMouseMove = (e) => {
                if (!isDragging.current || viewMode !== 'graph') return;
                const dx = e.clientX - lastMousePos.current.x;
                const dy = e.clientY - lastMousePos.current.y;
                setTransform(prev => ({ ...prev, x: prev.x + dx, y: prev.y + dy }));
                lastMousePos.current = { x: e.clientX, y: e.clientY };
            };
            const handleMouseUp = () => { isDragging.current = false; };

            // 3. ä¸Šä¼ ä¸é€»è¾‘
            const handleFileUpload = async (e) => {
                const file = e.target.files[0];
                if (!file) return;
                setUploading(true);
                const formData = new FormData();
                formData.append('file', file);
                try {
                    const res = await fetch('/api/upload', { method: 'POST', body: formData });
                    const data = await res.json();
                    if (data.status === 'success') {
                        setCurrentJobId(data.job_id);
                        await fetchWorkflow(data.job_id);
                    }
                } catch (e) { alert("ä¸Šä¼ å¤±è´¥"); }
                setUploading(false);
            };

            const sendAgentMsg = async () => {
                if (!inputText.trim()) return;
                const msg = inputText; setInputText('');
                setMessages(prev => [...prev, { role: 'user', text: msg }]);
                setLoading(true);
                await fetch('/api/agent/chat', { 
                    method: 'POST', 
                    headers: {'Content-Type': 'application/json'}, 
                    body: JSON.stringify({ message: msg, job_id: currentJobId }) 
                });
                setLoading(false);
                fetchWorkflow(currentJobId);
            };

            const updateShot = async (shotId, desc) => {
                await fetch('/api/shot/update', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ shot_id: shotId, description: desc, job_id: currentJobId })
                });
            };

            const runTask = async (type, shotId = null) => {
                await fetch(`/api/run/${type}${shotId ? `?shot_id=${shotId}&job_id=${currentJobId}` : `?job_id=${currentJobId}`}`, { method: 'POST' });
            };

            const getAssetUrl = (path) => path ? `/assets/${currentJobId}/${path}` : "";

            // ğŸ’¡ è¿çº¿å‡ ä½•è®¡ç®—ï¼šMaster Source ä½äºæ‰€æœ‰åˆ†é•œæ€»é«˜åº¦çš„ä¸­ç‚¹
            const SHOT_BLOCK_HEIGHT = 600; 
            const totalShotsCount = workflow?.shots?.length || 0;
            const masterSourceY = (totalShotsCount * SHOT_BLOCK_HEIGHT) / 2 - 250;

            if (!workflow && !uploading) {
                return (
                    <div className="h-screen flex items-center justify-center p-4 bg-slate-950">
                        <div className="max-w-xl w-full glass rounded-[3rem] p-12 text-center space-y-8 border-blue-500/20 border-2 shadow-2xl">
                            <h1 className="text-3xl font-black tracking-tighter uppercase italic">AI Director Workflow</h1>
                            <label className="block bg-slate-900 border-2 border-dashed border-slate-700 hover:border-blue-500 p-12 rounded-[2rem] transition-all cursor-pointer">
                                <span className="text-blue-500 font-black uppercase text-sm tracking-widest">Upload Video to Start</span>
                                <input type="file" onChange={handleFileUpload} className="hidden" accept="video/*" />
                            </label>
                        </div>
                    </div>
                );
            }

            if (uploading) return <div className="h-screen flex items-center justify-center bg-slate-950 text-2xl font-black animate-pulse uppercase tracking-tighter text-blue-400">AI Deconstructing...</div>;

            return (
                <div className="h-screen flex flex-col p-4 gap-4 overflow-hidden">
                    {/* Header */}
                    <div className="glass rounded-2xl p-4 flex items-center justify-between border border-white/5 z-50">
                        <div className="flex items-center gap-6">
                            <h1 className="text-xl font-bold tracking-tight bg-gradient-to-r from-blue-400 to-emerald-400 bg-clip-text text-transparent italic uppercase pr-4">AI DIRECTOR WORKSTATION</h1>
                            <div className="flex bg-slate-900 rounded-xl p-1 border border-white/10 shadow-inner">
                                <button onClick={() => setViewMode('grid')} className={`px-5 py-1.5 rounded-lg text-xs font-bold transition ${viewMode === 'grid' ? 'bg-blue-600 text-white shadow-lg' : 'text-slate-500'}`}>STORYBOARD (ç²¾ä¿®)</button>
                                <button onClick={() => setViewMode('graph')} className={`px-5 py-1.5 rounded-lg text-xs font-bold transition ${viewMode === 'graph' ? 'bg-blue-600 text-white shadow-lg' : 'text-slate-500'}`}>WORKFLOW CANVAS</button>
                            </div>
                        </div>
                        <div className="flex gap-4">
                            <button onClick={() => { setWorkflow(null); setCurrentJobId(null); }} className="text-[10px] font-black border border-white/10 px-4 py-2 rounded-xl text-slate-500 hover:text-white uppercase">+ New Project</button>
                            <button onClick={() => runTask('video_generate')} className="bg-emerald-600 hover:bg-emerald-500 px-6 py-2 rounded-xl text-sm font-black shadow-lg uppercase active:scale-95 transition-all">Execute All</button>
                        </div>
                    </div>

                    <div className="flex flex-1 gap-4 overflow-hidden relative">
                        <div 
                            className={`flex-1 glass rounded-[3rem] overflow-hidden relative border border-white/10 no-select ${viewMode === 'graph' ? 'canvas-bg' : ''}`}
                            onWheel={handleWheel} onMouseDown={handleMouseDown} onMouseMove={handleMouseMove} onMouseUp={handleMouseUp} onMouseLeave={handleMouseUp}
                        >
                            {viewMode === 'grid' ? (
                                <div className="h-full overflow-y-auto p-10 custom-scrollbar">
                                    <div className="flex flex-col gap-10">
                                        {workflow.shots?.map(shot => {
                                            const hasStylized = !!shot.assets.stylized_frame;
                                            const isSuccess = shot.status?.video_generate === 'SUCCESS';
                                            return (
                                                <div key={shot.shot_id} className="glass rounded-[2rem] border border-white/5 p-8 bg-slate-950/20 relative">
                                                    <div className="flex justify-between items-center mb-6 px-2">
                                                        <span className="font-mono text-xs text-blue-400 font-bold uppercase tracking-widest">{shot.shot_id}</span>
                                                        <span className="text-[10px] text-slate-600 font-mono tracking-tighter">TS: {shot.start_time}s</span>
                                                    </div>
                                                    {/* ğŸ’¡ ä¿®å¤é‡ç‚¹ï¼šä¸‰åˆ—å¯¹æ¯”å¸ƒå±€ (Source Img -> Stylized Img -> AI Video) */}
                                                    <div className="grid grid-cols-3 gap-6">
                                                        {/* 1. åŸå§‹åˆ†é•œå›¾ */}
                                                        <div className="space-y-3">
                                                            <div className="relative aspect-video rounded-2xl overflow-hidden border border-white/10 bg-black">
                                                                <img src={getAssetUrl(shot.assets.first_frame)} className="w-full h-full object-cover" />
                                                                <div className="absolute top-3 left-3 bg-red-500 text-[8px] px-2 py-0.5 font-black rounded uppercase">SOURCE IMAGE</div>
                                                            </div>
                                                            <p className="text-[10px] text-center text-slate-500 uppercase tracking-widest">åŸå§‹åˆ†é•œå›¾</p>
                                                        </div>
                                                        {/* 2. é£æ ¼åŒ–å‚è€ƒå›¾ */}
                                                        <div className="space-y-3">
                                                            <div className="relative aspect-video rounded-2xl overflow-hidden border border-purple-500/30 bg-slate-900 shadow-[0_0_20px_rgba(168,85,247,0.1)]">
                                                                {hasStylized ? (
                                                                    <img src={getAssetUrl(shot.assets.stylized_frame)} className="w-full h-full object-cover" />
                                                                ) : <div className="h-full flex items-center justify-center text-[10px] text-slate-700 italic">Pending DNA...</div>}
                                                                <div className="absolute top-3 left-3 bg-purple-600 text-[8px] px-2 py-0.5 font-black rounded uppercase text-white">STYLIZED DNA</div>
                                                                <button onClick={() => runTask('stylize', shot.shot_id)} className="absolute bottom-3 right-3 glass p-2 rounded-lg hover:bg-white/10"><svg className="w-3 h-3 text-purple-400" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15" strokeWidth="3"/></svg></button>
                                                            </div>
                                                            <p className="text-[10px] text-center text-purple-400 uppercase tracking-widest">åˆ†é•œå®šå¦†å›¾</p>
                                                        </div>
                                                        {/* 3. AI è¾“å‡ºè§†é¢‘ */}
                                                        <div className="space-y-3">
                                                            <div className={`relative aspect-video rounded-2xl overflow-hidden border ${isSuccess ? 'border-emerald-500/40 shadow-xl' : 'border-blue-500/20 bg-slate-900'}`}>
                                                                {isSuccess ? <video src={`${getAssetUrl(shot.assets.video)}?t=${Date.now()}`} className="w-full h-full object-cover" controls autoPlay muted loop /> : <div className="h-full flex items-center justify-center font-mono text-[9px] text-blue-400 animate-pulse uppercase">{shot.status?.video_generate}</div>}
                                                                <div className="absolute top-3 left-3 bg-blue-500 text-[8px] px-2 py-0.5 font-black rounded uppercase text-white">AI OUTPUT</div>
                                                            </div>
                                                            <p className="text-[10px] text-center text-blue-400 uppercase tracking-widest">æœ€ç»ˆç”Ÿæˆè§†é¢‘</p>
                                                        </div>
                                                    </div>
                                                    <div className="mt-8 p-5 bg-slate-900/50 rounded-2xl border border-white/5 relative">
                                                        <div className="mb-2 text-[9px] text-slate-500 italic">Style Reference: {workflow.global?.style_prompt}</div>
                                                        <textarea className="w-full bg-transparent border-none text-[13px] text-slate-300 outline-none h-20 resize-none italic leading-relaxed" defaultValue={shot.description} onBlur={(e) => updateShot(shot.shot_id, e.target.value)} />
                                                        <div className="flex justify-end mt-2"><button onClick={() => runTask('video_generate', shot.shot_id)} className="text-[10px] text-emerald-400 font-black uppercase tracking-widest hover:text-emerald-300 transition-all">Execute Re-Draw</button></div>
                                                    </div>
                                                </div>
                                            );
                                        })}
                                    </div>
                                </div>
                            ) : (
                                <div className="absolute inset-0 origin-top-left transition-transform duration-75" style={{ transform: `translate(${transform.x}px, ${transform.y}px) scale(${transform.scale})` }}>
                                    <svg className="absolute inset-0 w-[10000px] h-[10000px] pointer-events-none">
                                        {workflow.shots?.map((shot, i) => (
                                            <path key={i} d={`M 430 ${masterSourceY + 185} C 530 ${masterSourceY + 185}, 530 ${180 + i * SHOT_BLOCK_HEIGHT}, 630 ${180 + i * SHOT_BLOCK_HEIGHT}`} className={`node-line ${shot.status?.video_generate === 'RUNNING' ? 'node-line-active' : ''}`} />
                                        ))}
                                    </svg>
                                    
                                    {/* ğŸ’¡ Master Source (å¸¦å°é¢çš„è§†é¢‘) */}
                                    <div className="absolute left-20 w-[410px] glass p-10 rounded-[4rem] border-2 border-red-500/40 shadow-2xl" style={{ top: `${masterSourceY}px` }}>
                                        <div className="absolute -right-3 top-1/2 -translate-y-1/2 w-8 h-8 bg-red-500 rounded-full border-4 border-slate-950 shadow-[0_0_20px_#ef4444]"></div>
                                        <h3 className="text-[10px] font-black text-red-500 mb-6 uppercase tracking-widest italic">Root: Master Source</h3>
                                        <div className="aspect-video bg-black rounded-[2.5rem] overflow-hidden border border-white/10">
                                            <video src={getAssetUrl('input.mp4')} className="w-full h-full object-cover" controls muted poster={getAssetUrl(workflow.shots[0]?.assets?.first_frame)} />
                                        </div>
                                    </div>

                                    {/* ğŸ’¡ å·¥ä½œæµå¤§èŠ‚ç‚¹ (Input Img -> Style -> Output Video) */}
                                    <div className="absolute left-[630px] top-0 flex flex-col gap-40 py-20">
                                        {workflow.shots?.map((shot, i) => {
                                            const isSuccess = shot.status?.video_generate === 'SUCCESS';
                                            return (
                                                <div key={shot.shot_id} className="flex items-center gap-16">
                                                    <div className="w-[580px] glass p-10 rounded-[3.5rem] border border-white/10 relative shadow-2xl">
                                                        <div className="absolute -left-3 top-1/2 -translate-y-1/2 w-6 h-6 bg-blue-500 rounded-full border-4 border-slate-950 shadow-[0_0_15px_#3b82f6]"></div>
                                                        <h4 className="text-blue-400 font-black text-[10px] mb-6 uppercase tracking-widest">Input Node #{i+1}</h4>
                                                        <div className="flex gap-8">
                                                            <div className="w-48 h-32 rounded-2xl bg-black overflow-hidden border border-white/5">
                                                                {/* è¿™é‡Œå¿…é¡»æ˜¯å›¾ (PMè¦æ±‚) */}
                                                                <img src={getAssetUrl(shot.assets.first_frame)} className="w-full h-full object-cover opacity-80" />
                                                            </div>
                                                            <div className="flex-1 overflow-hidden">
                                                                <span className="text-[9px] text-slate-500 font-bold uppercase tracking-widest opacity-60">Source Description</span>
                                                                {/* ğŸ’¡ ä¿®å¤ (1): å·¥ä½œæµä¸­ Prompt ç•¥ç¼©æ˜¾ç¤ºä¸”ä¸å¯ä¿®æ”¹ */}
                                                                <div className="w-full bg-slate-950/30 border border-white/5 rounded-xl p-3 text-[11px] text-slate-400 h-24 mt-2 font-mono leading-relaxed overflow-hidden italic line-clamp-4 select-none">
                                                                    {shot.description}
                                                                </div>
                                                            </div>
                                                        </div>
                                                    </div>
                                                    <div className="text-4xl text-slate-800 font-black italic opacity-20">â†’</div>
                                                    {/* Style Node */}
                                                    <div className="w-32 flex flex-col items-center gap-1 opacity-60"><span className="text-[7px] text-slate-500 uppercase font-black">Style Node</span><div className="glass px-2 py-2 rounded-lg border border-purple-500/20 text-[8px] text-purple-400 font-mono text-center w-full truncate">{workflow.global?.style_prompt}</div></div>
                                                    <div className="text-4xl text-slate-800 font-black italic opacity-20">â†’</div>
                                                    {/* ğŸ’¡ ä¿®å¤ (2): æå¤§åŒ–çš„è¾“å‡ºè§†é¢‘ */}
                                                    <div className={`w-[700px] glass p-5 rounded-[4rem] border transition-all duration-700 shadow-2xl ${isSuccess ? 'border-emerald-500/40 bg-emerald-500/5' : 'border-white/5 opacity-20'}`}>
                                                        <div className="aspect-video bg-black rounded-[3rem] overflow-hidden">
                                                            {isSuccess ? <video src={`${getAssetUrl(shot.assets.video)}?t=${Date.now()}`} className="w-full h-full object-cover" autoPlay muted loop controls /> : <div className="h-full flex items-center justify-center font-mono text-xs text-slate-800 tracking-[0.8em] uppercase">Awaiting Asset</div>}
                                                        </div>
                                                    </div>
                                                </div>
                                            );
                                        })}
                                    </div>
                                </div>
                            )}
                        </div>

                        {/* ğŸ’¡ ä¿®å¤: é›†æˆç¼©æ”¾é”®çš„ Agent Sidebar */}
                        <div className={`sidebar-transition flex flex-col glass rounded-[3rem] overflow-hidden border border-white/10 shadow-2xl relative ${isAgentVisible ? 'w-96 ml-4' : 'w-0 border-none'}`}>
                            <button onClick={() => setIsAgentVisible(!isAgentVisible)} className={`absolute top-1/2 -left-5 -translate-y-1/2 w-10 h-10 glass rounded-full flex items-center justify-center text-blue-400 hover:text-white transition-all z-[100] border border-white/10 shadow-2xl ${!isAgentVisible ? 'translate-x-[-3rem] rotate-180' : ''}`}>
                                <svg className="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path strokeLinecap="round" strokeLinejoin="round" strokeWidth="2" d="M11 19l-7-7 7-7m8 14l-7-7 7-7" /></svg>
                            </button>
                            {isAgentVisible && (
                                <div className="flex flex-col h-full">
                                    <div className="p-6 border-b border-white/5 bg-white/5 font-black uppercase text-xs tracking-widest text-emerald-400">Director Agent</div>
                                    <div className="flex-1 overflow-y-auto p-6 space-y-6 custom-scrollbar text-xs leading-relaxed">
                                        {messages.map((m, i) => (
                                            <div key={i} className={`flex ${m.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                                                <div className={`max-w-[90%] p-4 rounded-3xl ${m.role === 'user' ? 'bg-blue-600 text-white rounded-tr-none shadow-lg' : 'bg-slate-800 text-slate-200 border border-white/5 shadow-xl'}`}>{m.text}</div>
                                            </div>
                                        ))}
                                    </div>
                                    <div className="p-6 bg-slate-900/80 border-t border-white/10">
                                        <div className="flex gap-3">
                                            <input value={inputText} onChange={e => setInputText(e.target.value)} onKeyDown={e => e.key === 'Enter' && sendAgentMsg()} placeholder="Command..." className="flex-1 bg-slate-950 border border-white/10 rounded-2xl px-5 py-3 text-xs outline-none focus:border-blue-500 text-white shadow-inner" />
                                            <button onClick={sendAgentMsg} className="bg-blue-600 hover:bg-blue-500 px-5 py-3 rounded-2xl font-black text-xs shadow-lg">Send</button>
                                        </div>
                                    </div>
                                </div>
                            )}
                        </div>
                    </div>
                </div>
            );
        };

        const root = ReactDOM.createRoot(document.getElementById('root'));
        root.render(<App />);
    </script>
</body>
</html>
</file>

</files>
