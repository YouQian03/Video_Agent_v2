# core/film_ir_manager.py
"""
Film IR Manager
===============
ç”µå½±é€»è¾‘ä¸­é—´å±‚ç®¡ç†å™¨ï¼Œè´Ÿè´£ï¼š
1. é˜¶æ®µæµè½¬æ§åˆ¶
2. æ”¯æŸ±æ•°æ®ç®¡ç†
3. æŠ½è±¡åŒ–ä¸æ„å›¾æ³¨å…¥è°ƒåº¦

ä¸‰é˜¶æ®µæµç¨‹:
- Stage 1: Specific Analysis (å…·ä½“åˆ†æ)
- Stage 2: Abstraction (é€»è¾‘æŠ½è±¡)
- Stage 3: Intent Injection (æ„å›¾æ³¨å…¥)
"""

import os
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime

from google import genai
from google.genai import types


def gemini_call_with_retry(client, model: str, contents: list, config=None, max_retries: int = 2, base_delay: float = 5.0):
    """
    å¸¦é‡è¯•å’Œè‡ªåŠ¨é™çº§çš„ Gemini API è°ƒç”¨

    ç­–ç•¥ï¼š
    1. ä½¿ç”¨æŒ‡å®šæ¨¡å‹é‡è¯• max_retries æ¬¡
    2. å¦‚æœä»ç„¶å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§åˆ° gemini-2.0-flash

    Args:
        client: Gemini å®¢æˆ·ç«¯
        model: æ¨¡å‹åç§°
        contents: è¯·æ±‚å†…å®¹
        config: ç”Ÿæˆé…ç½®
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤2æ¬¡ï¼‰
        base_delay: åŸºç¡€ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        Gemini å“åº”
    """
    # é™çº§æ¨¡å‹æ˜ å°„
    fallback_model = "gemini-2.0-flash" if "3" in model else None

    last_error = None
    current_model = model

    # ç¬¬ä¸€è½®ï¼šä½¿ç”¨åŸå§‹æ¨¡å‹é‡è¯•
    for attempt in range(max_retries + 1):
        try:
            if config:
                response = client.models.generate_content(
                    model=current_model,
                    contents=contents,
                    config=config
                )
            else:
                response = client.models.generate_content(
                    model=current_model,
                    contents=contents
                )
            return response
        except Exception as e:
            error_str = str(e)
            last_error = e

            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯ (503 è¿‡è½½, 429 é™æµ)
            if "503" in error_str or "overloaded" in error_str.lower() or "429" in error_str:
                if attempt < max_retries:
                    delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿: 5s, 10s
                    print(f"   â³ {current_model} overloaded, retrying in {delay:.0f}s... (attempt {attempt + 1}/{max_retries})")
                    time.sleep(delay)
                    continue
                else:
                    # é‡è¯•æ¬¡æ•°ç”¨å®Œï¼Œå°è¯•é™çº§
                    break
            else:
                # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
                raise

    # ç¬¬äºŒè½®ï¼šé™çº§åˆ°å¤‡ç”¨æ¨¡å‹
    if fallback_model and fallback_model != model:
        print(f"   ğŸ”„ Falling back to {fallback_model}...")
        try:
            if config:
                response = client.models.generate_content(
                    model=fallback_model,
                    contents=contents,
                    config=config
                )
            else:
                response = client.models.generate_content(
                    model=fallback_model,
                    contents=contents
                )
            print(f"   âœ… Fallback to {fallback_model} succeeded")
            return response
        except Exception as e:
            print(f"   âŒ Fallback also failed: {e}")
            # é™çº§ä¹Ÿå¤±è´¥ï¼ŒæŠ›å‡ºåŸå§‹é”™è¯¯
            raise last_error

    # æ— æ³•é™çº§ï¼ŒæŠ›å‡ºåŸå§‹é”™è¯¯
    raise last_error

from core.film_ir_schema import create_empty_film_ir, StageStatus
from core.film_ir_io import (
    load_film_ir, save_film_ir, film_ir_exists,
    update_film_ir_stage, update_film_ir_pillar,
    set_user_intent, get_hidden_template, get_active_layer,
    convert_to_frontend_story_theme,
    convert_to_frontend_script_analysis,
    convert_to_frontend_storyboard
)
from core.meta_prompts import (
    # Pillar I-III Analysis
    STORY_THEME_ANALYSIS_PROMPT,
    convert_story_theme_to_frontend,
    extract_story_theme_abstract,
    NARRATIVE_EXTRACTION_PROMPT,
    convert_narrative_to_frontend,
    extract_narrative_abstract,
    extract_narrative_hidden_assets,
    SHOT_DECOMPOSITION_PROMPT,
    SHOT_DETECTION_PROMPT,
    SHOT_DETAIL_BATCH_PROMPT,
    convert_shot_recipe_to_frontend,
    extract_shot_recipe_abstract,
    extract_shot_first_frames,
    extract_shot_dialogue_timeline,
    create_shot_boundaries_text,
    merge_batch_results,
    # Character Ledger (Pillar II extension) - 3-pass architecture
    CHARACTER_DISCOVERY_PROMPT,
    CHARACTER_PRESENCE_AUDIT_PROMPT,
    SURGICAL_RECHECK_PROMPT,
    ENVIRONMENT_EXTRACTION_PROMPT,
    build_shot_subjects_input,
    select_key_frames,
    check_character_continuity,
    process_ledger_result,
    get_ledger_display_summary,
    update_shots_with_entity_refs,
    # M4: Intent Injection
    INTENT_PARSER_PROMPT,
    parse_intent_result,
    extract_subject_mappings,
    get_intent_summary,
    check_compliance,
    INTENT_FUSION_PROMPT,
    convert_to_remixed_layer,
    extract_identity_anchors,
    extract_t2i_prompts,
    extract_i2v_prompts,
    validate_fusion_output,
    generate_fusion_summary,
    post_process_remixed_layer
)


class FilmIRManager:
    """
    Film IR ç®¡ç†å™¨

    Usage:
        manager = FilmIRManager(job_id, project_root)
        manager.run_stage("specificAnalysis")
        manager.run_stage("abstraction")
        manager.inject_intent("æŠŠçŒ«æ¢æˆéœ¸ç‹é¾™")
        manager.run_stage("assetGeneration")
    """

    def __init__(self, job_id: str, project_root: Optional[Path] = None):
        """
        åˆå§‹åŒ– Film IR Manager

        Args:
            job_id: ä½œä¸š ID
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        self.project_dir = project_root or Path(__file__).parent.parent
        self.job_id = job_id
        self.job_dir = self.project_dir / "jobs" / job_id

        # åŠ è½½æˆ–åˆ›å»º Film IR
        if film_ir_exists(self.job_dir):
            self.ir = load_film_ir(self.job_dir)
        else:
            self.ir = create_empty_film_ir(job_id)

    # ============================================================
    # å±æ€§è®¿é—®
    # ============================================================

    @property
    def stages(self) -> Dict[str, str]:
        """è·å–é˜¶æ®µçŠ¶æ€"""
        return self.ir.get("stages", {})

    @property
    def pillars(self) -> Dict[str, Any]:
        """è·å–å››å¤§æ”¯æŸ±"""
        return self.ir.get("pillars", {})

    @property
    def user_intent(self) -> Dict[str, Any]:
        """è·å–ç”¨æˆ·æ„å›¾"""
        return self.ir.get("userIntent", {})

    @property
    def source_video(self) -> str:
        """è·å–æºè§†é¢‘è·¯å¾„"""
        return self.ir.get("sourceVideo", "")

    # ============================================================
    # æŒä¹…åŒ–
    # ============================================================

    def save(self) -> None:
        """ä¿å­˜ Film IR"""
        save_film_ir(self.job_dir, self.ir)

    def reload(self) -> None:
        """é‡æ–°åŠ è½½ Film IR"""
        self.ir = load_film_ir(self.job_dir)

    # ============================================================
    # é˜¶æ®µæ§åˆ¶
    # ============================================================

    def update_stage(self, stage: str, status: str) -> None:
        """
        æ›´æ–°é˜¶æ®µçŠ¶æ€

        Args:
            stage: é˜¶æ®µå
            status: çŠ¶æ€ (NOT_STARTED/RUNNING/SUCCESS/FAILED)
        """
        if stage in self.ir["stages"]:
            self.ir["stages"][stage] = status
            self.save()
        else:
            raise ValueError(f"Unknown stage: {stage}")

    def can_run_stage(self, stage: str) -> tuple:
        """
        æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿è¡ŒæŒ‡å®šé˜¶æ®µ

        Returns:
            (can_run: bool, reason: str)
        """
        stages = self.stages

        dependencies = {
            "specificAnalysis": [],
            "abstraction": ["specificAnalysis"],
            # intentInjection ä¾èµ– specificAnalysis (å·²åŒ…å« abstract æå–)
            # è·³è¿‡ abstraction placeholderï¼Œç›´æ¥ä» specificAnalysis è·å– abstract æ•°æ®
            "intentInjection": ["specificAnalysis"],
            "assetGeneration": ["intentInjection"],
            "shotRefinement": ["assetGeneration"],
            "execution": ["shotRefinement"]
        }

        if stage not in dependencies:
            return False, f"Unknown stage: {stage}"

        # æ£€æŸ¥å‰ç½®ä¾èµ–
        for dep in dependencies[stage]:
            if stages.get(dep) != "SUCCESS":
                return False, f"Dependency not met: {dep} must be SUCCESS"

        # ç‰¹æ®Šæ£€æŸ¥ï¼šæ„å›¾æ³¨å…¥éœ€è¦ç”¨æˆ·è¾“å…¥
        if stage == "intentInjection":
            if not self.user_intent.get("rawPrompt"):
                return False, "User intent not provided"

        return True, "OK"

    def run_stage(self, stage: str) -> Dict[str, Any]:
        """
        è¿è¡ŒæŒ‡å®šé˜¶æ®µ

        Args:
            stage: é˜¶æ®µå

        Returns:
            è¿è¡Œç»“æœ
        """
        can_run, reason = self.can_run_stage(stage)
        if not can_run:
            return {"status": "error", "reason": reason}

        self.update_stage(stage, "RUNNING")

        try:
            if stage == "specificAnalysis":
                result = self._run_specific_analysis()
            elif stage == "abstraction":
                result = self._run_abstraction()
            elif stage == "intentInjection":
                result = self._run_intent_injection()
            elif stage == "assetGeneration":
                result = self._run_asset_generation()
            elif stage == "shotRefinement":
                result = self._run_shot_refinement()
            elif stage == "execution":
                result = self._run_execution()
            else:
                result = {"status": "error", "reason": f"Unknown stage: {stage}"}

            if result.get("status") == "success":
                self.update_stage(stage, "SUCCESS")
            else:
                self.update_stage(stage, "FAILED")

            return result

        except Exception as e:
            self.update_stage(stage, "FAILED")
            print(f"âŒ Stage {stage} failed: {e}")
            return {"status": "error", "reason": str(e)}

    # ============================================================
    # é˜¶æ®µå®ç° (é¢„ç•™æ¥å£ï¼Œç­‰å¾… Meta Prompts)
    # ============================================================

    def _run_specific_analysis(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 1: å…·ä½“åˆ†æ
        è°ƒç”¨ Meta Prompts æå–å››å¤§æ”¯æŸ±çš„ concrete æ•°æ®

        ä¼˜åŒ–: è§†é¢‘åªä¸Šä¼ ä¸€æ¬¡ï¼Œä¸‰ä¸ªåˆ†æå¤ç”¨åŒä¸€ä¸ªæ–‡ä»¶å¼•ç”¨
        """
        print(f"ğŸ” [Stage 1] Running specific analysis for {self.job_id}...")

        # è·å–è§†é¢‘è·¯å¾„
        video_path = self.job_dir / self.source_video
        if not video_path.exists():
            return {"status": "error", "reason": f"Video file not found: {video_path}"}

        # ============================================================
        # ğŸš€ ç»Ÿä¸€ä¸Šä¼ è§†é¢‘ (åªä¸Šä¼ ä¸€æ¬¡ï¼Œä¸‰ä¸ªåˆ†æå¤ç”¨)
        # ============================================================
        print(f"ğŸ“¤ [Stage 1.0] Uploading video to Gemini (once for all analyses)...")
        try:
            uploaded_file, client = self._upload_video_to_gemini(video_path)
            print(f"âœ… [Stage 1.0] Video uploaded and ready: {uploaded_file.name}")
        except Exception as e:
            print(f"âŒ [Stage 1.0] Video upload failed: {e}")
            return {"status": "error", "reason": f"Video upload failed: {e}"}

        # ============================================================
        # Step 1: Story Theme Analysis (æ”¯æŸ± I) - Concrete + Abstract èåˆè¾“å‡º
        # ============================================================
        print(f"ğŸ“Š [Stage 1.1] Analyzing Story Theme...")

        try:
            story_theme_result = self._analyze_story_theme(uploaded_file, client)
            if story_theme_result:
                # æå–åŒå±‚æ•°æ®
                concrete_data = convert_story_theme_to_frontend(story_theme_result)
                abstract_data = extract_story_theme_abstract(story_theme_result)

                # å­˜å‚¨åˆ°æ”¯æŸ± I
                self.ir["pillars"]["I_storyTheme"]["concrete"] = concrete_data
                self.ir["pillars"]["I_storyTheme"]["abstract"] = abstract_data
                self.save()
                print(f"âœ… [Stage 1.1] Story Theme analysis completed (concrete + abstract)")
            else:
                print(f"âš ï¸ [Stage 1.1] Story Theme analysis returned empty result")
        except Exception as e:
            print(f"âŒ [Stage 1.1] Story Theme analysis failed: {e}")
            return {"status": "error", "reason": f"Story Theme analysis failed: {e}"}

        # ============================================================
        # Step 2: Narrative Extraction (æ”¯æŸ± II) - Concrete + Abstract èåˆè¾“å‡º
        # ============================================================
        print(f"ğŸ“ [Stage 1.2] Extracting Narrative Template...")

        try:
            narrative_result = self._analyze_narrative(uploaded_file, client)
            if narrative_result:
                # æå–ä¸‰å±‚æ•°æ®
                concrete_data = convert_narrative_to_frontend(narrative_result)
                abstract_data = extract_narrative_abstract(narrative_result)
                hidden_assets = extract_narrative_hidden_assets(narrative_result)

                # å­˜å‚¨åˆ°æ”¯æŸ± II
                self.ir["pillars"]["II_narrativeTemplate"]["concrete"] = concrete_data
                self.ir["pillars"]["II_narrativeTemplate"]["abstract"] = abstract_data
                self.ir["pillars"]["II_narrativeTemplate"]["hiddenAssets"] = hidden_assets
                self.save()
                print(f"âœ… [Stage 1.2] Narrative extraction completed (concrete + abstract + hiddenAssets)")
            else:
                print(f"âš ï¸ [Stage 1.2] Narrative extraction returned empty result")
        except Exception as e:
            print(f"âŒ [Stage 1.2] Narrative extraction failed: {e}")
            # ä¸é˜»å¡æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ

        # ============================================================
        # Step 3: Shot Decomposition (æ”¯æŸ± III) - Concrete + Abstract èåˆè¾“å‡º
        # ============================================================
        print(f"ğŸ¬ [Stage 1.3] Decomposing Shot Recipe...")

        try:
            shot_recipe_result = self._analyze_shot_recipe(uploaded_file, client)
            if shot_recipe_result:
                # æå–å¤šå±‚æ•°æ®
                concrete_data = convert_shot_recipe_to_frontend(shot_recipe_result)
                abstract_data = extract_shot_recipe_abstract(shot_recipe_result)
                first_frames = extract_shot_first_frames(shot_recipe_result)
                dialogue_timeline = extract_shot_dialogue_timeline(shot_recipe_result)

                # æå–åˆ†æå…ƒæ•°æ® (åŒ…å«é™çº§ä¿¡æ¯)
                analysis_metadata = shot_recipe_result.get("shotRecipe", {}).get("_analysisMetadata", {})
                degraded_batches = analysis_metadata.get("degradedBatches", [])

                # å­˜å‚¨åˆ°æ”¯æŸ± III
                self.ir["pillars"]["III_shotRecipe"]["concrete"] = concrete_data
                self.ir["pillars"]["III_shotRecipe"]["abstract"] = abstract_data
                # é™„åŠ æ•°æ®å­˜å‚¨åˆ° metadata
                self.ir["pillars"]["III_shotRecipe"]["firstFrames"] = first_frames
                self.ir["pillars"]["III_shotRecipe"]["dialogueTimeline"] = dialogue_timeline
                # å­˜å‚¨é™çº§æ‰¹æ¬¡ä¿¡æ¯ (ç”¨äºé‡è¯•)
                self.ir["pillars"]["III_shotRecipe"]["_analysisMetadata"] = analysis_metadata

                self.save()

                # è¾“å‡ºåˆ†æç»“æœæ‘˜è¦
                total_shots = len(concrete_data.get('shots', []))
                degraded_count = analysis_metadata.get("degradedShots", 0)
                if degraded_count > 0:
                    print(f"âš ï¸ [Stage 1.3] Shot Recipe completed: {total_shots} shots ({degraded_count} degraded, can retry)")
                else:
                    print(f"âœ… [Stage 1.3] Shot Recipe completed ({total_shots} shots extracted)")
            else:
                print(f"âš ï¸ [Stage 1.3] Shot Recipe returned empty result")
        except Exception as e:
            print(f"âŒ [Stage 1.3] Shot Recipe analysis failed: {e}")
            import traceback
            traceback.print_exc()
            # ä¸é˜»å¡æµç¨‹

        # ============================================================
        # Step 4: Character Ledger Generation (æ”¯æŸ± II æ‰©å±•) - ä¸¤é˜¶æ®µè¯†åˆ«
        # ============================================================
        print(f"ğŸ‘¥ [Stage 1.4] Generating Character Ledger (two-phase clustering)...")

        try:
            # è·å–å·²åˆ†æçš„ shots æ•°æ®
            shots = self.ir["pillars"]["III_shotRecipe"]["concrete"].get("shots", [])
            if shots:
                ledger_result = self._generate_character_ledger(shots, client)
                if ledger_result:
                    # å­˜å‚¨ character ledger åˆ° Pillar II
                    self.ir["pillars"]["II_narrativeTemplate"]["characterLedger"] = ledger_result.get("characterLedger", [])
                    self.ir["pillars"]["II_narrativeTemplate"]["environmentLedger"] = ledger_result.get("environmentLedger", [])
                    self.ir["pillars"]["II_narrativeTemplate"]["ledgerSummary"] = ledger_result.get("clusteringSummary", {})

                    # æ›´æ–° Pillar III shotsï¼Œæ·»åŠ  entityRefs
                    updated_shots = update_shots_with_entity_refs(shots, ledger_result)
                    self.ir["pillars"]["III_shotRecipe"]["concrete"]["shots"] = updated_shots

                    # åˆå§‹åŒ– Pillar IV çš„ identityMapping (ç©ºæ˜ å°„ï¼Œå¾…ç”¨æˆ·ç»‘å®š)
                    self._init_identity_mapping(ledger_result)

                    self.save()
                    print(f"âœ… [Stage 1.4] Character Ledger completed:")
                    print(get_ledger_display_summary(ledger_result))
                else:
                    print(f"âš ï¸ [Stage 1.4] Character Ledger generation returned empty result")
            else:
                print(f"âš ï¸ [Stage 1.4] Skipped - no shots available for clustering")
        except Exception as e:
            print(f"âŒ [Stage 1.4] Character Ledger generation failed: {e}")
            import traceback
            traceback.print_exc()
            # ä¸é˜»å¡æµç¨‹

        return {"status": "success", "message": "Specific analysis completed"}

    def _upload_video_to_gemini(self, video_path: Path) -> tuple:
        """
        ç»Ÿä¸€ä¸Šä¼ è§†é¢‘åˆ° Gemini Files API

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            (uploaded_file, client) å…ƒç»„ï¼Œä¾›åç»­åˆ†æå¤ç”¨
        """
        import time

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError("GEMINI_API_KEY not set")
        # Sanitize API key to remove non-ASCII characters (fixes encoding errors in HTTP headers)
        api_key = api_key.strip()
        api_key = ''.join(c for c in api_key if c.isascii() and c.isprintable())

        client = genai.Client(api_key=api_key)

        # ä¸Šä¼ è§†é¢‘æ–‡ä»¶
        uploaded_file = client.files.upload(file=str(video_path))

        # ç­‰å¾…æ–‡ä»¶å¤„ç†å®Œæˆ
        while uploaded_file.state.name == "PROCESSING":
            print(f"â³ Waiting for video processing...")
            time.sleep(3)
            uploaded_file = client.files.get(name=uploaded_file.name)

        if uploaded_file.state.name != "ACTIVE":
            raise RuntimeError(f"Video processing failed: {uploaded_file.state.name}")

        return uploaded_file, client

    def _analyze_story_theme(self, uploaded_file, client) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ Gemini API åˆ†æè§†é¢‘ä¸»é¢˜

        Args:
            uploaded_file: å·²ä¸Šä¼ çš„ Gemini æ–‡ä»¶å¼•ç”¨
            client: Gemini å®¢æˆ·ç«¯å®ä¾‹

        Returns:
            AI åˆ†æç»“æœ (åŸå§‹æ ¼å¼)
        """
        # æ„å»º Prompt (æ›¿æ¢ {input_content} å ä½ç¬¦)
        prompt = STORY_THEME_ANALYSIS_PROMPT.replace(
            "{input_content}",
            "[Video file attached - analyze the visual and audio content]"
        )

        # è°ƒç”¨ Gemini API (å¸¦ 503 é‡è¯•)
        print(f"ğŸ¤– Calling Gemini API for Story Theme analysis...")
        response = gemini_call_with_retry(
            client=client,
            model="gemini-3-flash-preview",
            contents=[prompt, uploaded_file],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        # è§£æ JSON å“åº” - ä½¿ç”¨å¢å¼ºçš„è§£æå™¨å¤„ç†è½¬ä¹‰åºåˆ—ç­‰é—®é¢˜
        result = self._parse_json_response(response.text, "Story Theme")
        print(f"âœ… Story Theme analysis received")
        return result

    def _analyze_narrative(self, uploaded_file, client) -> Optional[Dict[str, Any]]:
        """
        è°ƒç”¨ Gemini API æå–å™äº‹æ¨¡æ¿ (Concrete + Abstract èåˆè¾“å‡º)

        Args:
            uploaded_file: å·²ä¸Šä¼ çš„ Gemini æ–‡ä»¶å¼•ç”¨
            client: Gemini å®¢æˆ·ç«¯å®ä¾‹

        Returns:
            AI åˆ†æç»“æœï¼ŒåŒ…å« narrativeTemplate.*.concrete å’Œ *.abstract
        """
        # æ„å»º Prompt
        prompt = NARRATIVE_EXTRACTION_PROMPT.replace(
            "{input_content}",
            "[Video file attached - analyze the narrative structure, characters, and story arc]"
        )

        # è°ƒç”¨ Gemini API (å¸¦ 503 é‡è¯•)
        print(f"ğŸ¤– Calling Gemini API for Narrative extraction...")
        response = gemini_call_with_retry(
            client=client,
            model="gemini-3-flash-preview",
            contents=[prompt, uploaded_file],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        # è§£æ JSON å“åº” - ä½¿ç”¨å¢å¼ºçš„è§£æå™¨å¤„ç†è½¬ä¹‰åºåˆ—ç­‰é—®é¢˜
        result = self._parse_json_response(response.text, "Narrative")
        print(f"âœ… Narrative extraction received")
        return result

    def _analyze_shot_recipe(self, uploaded_file, client, batch_size: int = 8) -> Optional[Dict[str, Any]]:
        """
        ä¸¤é˜¶æ®µåˆ†æ‰¹åˆ†æåˆ†é•œ (é¿å… JSON æˆªæ–­)

        Phase 1: è½»é‡çº§ shot æ£€æµ‹ (è·å–è¾¹ç•Œå’ŒåŸºç¡€ metadata)
        Phase 2: åˆ†æ‰¹æå–è¯¦ç»† concrete/abstract å­—æ®µ

        Args:
            uploaded_file: å·²ä¸Šä¼ çš„ Gemini æ–‡ä»¶å¼•ç”¨
            client: Gemini å®¢æˆ·ç«¯å®ä¾‹
            batch_size: æ¯æ‰¹å¤„ç†çš„ shot æ•°é‡ (é»˜è®¤ 8)

        Returns:
            åˆå¹¶åçš„ AI åˆ†æç»“æœï¼ŒåŒ…å« shotRecipe.globalSettings å’Œ shots[]
            å¤±è´¥çš„æ‰¹æ¬¡ä¼šä½¿ç”¨é™çº§æ•°æ®ï¼Œå¹¶è®°å½•åœ¨ _analysisMetadata.degradedBatches
        """
        import time

        # ============================================================
        # Phase 1: è½»é‡çº§ Shot æ£€æµ‹
        # ============================================================
        print(f"ğŸ” [Phase 1] Lightweight shot detection...")

        phase1_prompt = SHOT_DETECTION_PROMPT.replace(
            "{input_content}",
            "[Video file attached - detect shot boundaries and extract basic metadata]"
        )

        response = gemini_call_with_retry(
            client=client,
            model="gemini-3-flash-preview",
            contents=[phase1_prompt, uploaded_file],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        # ä½¿ç”¨å¢å¼ºçš„è§£æå™¨å¤„ç†è½¬ä¹‰åºåˆ—ç­‰é—®é¢˜
        phase1_result = self._parse_json_response(response.text, "Shot Phase 1")
        shots_basic = phase1_result.get("shotRecipe", {}).get("shots", [])
        total_shots = len(shots_basic)
        print(f"âœ… [Phase 1] Detected {total_shots} shots")

        if total_shots == 0:
            print(f"âš ï¸ No shots detected, returning Phase 1 result as-is")
            return phase1_result

        # ============================================================
        # Phase 2: åˆ†æ‰¹æå–è¯¦æƒ…
        # ============================================================
        batch_results = []
        degraded_batches = []
        num_batches = (total_shots + batch_size - 1) // batch_size

        for batch_idx in range(num_batches):
            start_idx = batch_idx * batch_size
            end_idx = min((batch_idx + 1) * batch_size, total_shots)

            print(f"ğŸ“¦ [Phase 2] Processing batch {batch_idx + 1}/{num_batches} (shots {start_idx + 1}-{end_idx})...")

            # æ„å»ºæ‰¹æ¬¡ prompt
            shot_boundaries = create_shot_boundaries_text(shots_basic, start_idx, end_idx)
            batch_prompt = SHOT_DETAIL_BATCH_PROMPT.replace(
                "{batch_start}", str(start_idx + 1)
            ).replace(
                "{batch_end}", str(end_idx)
            ).replace(
                "{total_shots}", str(total_shots)
            ).replace(
                "{shot_boundaries}", shot_boundaries
            ).replace(
                "{input_content}",
                "[Video file attached - extract detailed parameters for specified shots]"
            )

            # è°ƒç”¨ API (å¸¦ 503 é‡è¯• + JSON è§£æé‡è¯•)
            batch_success = False
            batch_result = self._process_batch_with_fallback(
                client=client,
                uploaded_file=uploaded_file,
                batch_prompt=batch_prompt,
                shots_basic=shots_basic,
                start_idx=start_idx,
                end_idx=end_idx,
                batch_idx=batch_idx,
                total_shots=total_shots
            )

            if batch_result is not None:
                batch_results.append(batch_result)
                batch_success = True
                print(f"âœ… [Phase 2] Batch {batch_idx + 1} completed")
            else:
                # è®°å½•é™çº§ä¿¡æ¯
                degraded_batch = {
                    "batchIndex": batch_idx,
                    "startIdx": start_idx,
                    "endIdx": end_idx,
                    "shotIds": [s.get("shotId") for s in shots_basic[start_idx:end_idx]],
                    "reason": "All retries and split attempts failed",
                    "timestamp": datetime.now().isoformat()
                }
                degraded_batches.append(degraded_batch)
                print(f"âš ï¸ [Phase 2] Batch {batch_idx + 1} DEGRADED - using Phase 1 data")

        # ============================================================
        # åˆå¹¶ç»“æœ
        # ============================================================
        merged_result = merge_batch_results(phase1_result, batch_results, degraded_batches)

        # æŠ¥å‘Šé™çº§æƒ…å†µ
        if degraded_batches:
            degraded_shot_count = sum(
                b["endIdx"] - b["startIdx"] for b in degraded_batches
            )
            print(f"âš ï¸ Shot Recipe completed with {len(degraded_batches)} degraded batch(es)")
            print(f"   {degraded_shot_count} shots using basic data (can be retried)")
        else:
            print(f"âœ… Shot Recipe fully completed (all batches successful)")

        return merged_result

    def _try_fix_json(self, broken_json: str) -> Optional[dict]:
        """
        å°è¯•ä¿®å¤æˆªæ–­çš„ JSON

        å¸¸è§é—®é¢˜ï¼š
        1. JSON åœ¨ä¸­é—´è¢«æˆªæ–­ï¼Œç¼ºå°‘é—­åˆæ‹¬å·
        2. æœ€åä¸€ä¸ªå…ƒç´ ä¸å®Œæ•´
        """
        import re

        text = broken_json.strip()

        # å¦‚æœå·²ç»æ˜¯æœ‰æ•ˆ JSONï¼Œç›´æ¥è¿”å›
        try:
            return json.loads(text)
        except:
            pass

        # å°è¯•ä¿®å¤ç­–ç•¥ 1: è¡¥å…¨ç¼ºå¤±çš„æ‹¬å·
        # ç»Ÿè®¡æœªé—­åˆçš„æ‹¬å·
        open_braces = text.count('{') - text.count('}')
        open_brackets = text.count('[') - text.count(']')

        if open_braces > 0 or open_brackets > 0:
            # åˆ é™¤æœ€åä¸€ä¸ªä¸å®Œæ•´çš„å…ƒç´ ï¼ˆé€šå¸¸åœ¨é€—å·åé¢ï¼‰
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ } æˆ– ]
            last_complete_idx = max(text.rfind('}'), text.rfind(']'))
            if last_complete_idx > 0:
                text = text[:last_complete_idx + 1]

            # é‡æ–°è®¡ç®—
            open_braces = text.count('{') - text.count('}')
            open_brackets = text.count('[') - text.count(']')

            # è¡¥å…¨æ‹¬å·
            text += ']' * open_brackets + '}' * open_braces

            try:
                return json.loads(text)
            except:
                pass

        # å°è¯•ä¿®å¤ç­–ç•¥ 2: æå– shots æ•°ç»„
        shots_match = re.search(r'"shots"\s*:\s*\[', text)
        if shots_match:
            start_idx = shots_match.end() - 1  # ä» [ å¼€å§‹
            # æ‰¾åˆ°æ‰€æœ‰å®Œæ•´çš„ shot å¯¹è±¡
            bracket_count = 0
            last_complete_shot_end = start_idx
            i = start_idx
            while i < len(text):
                if text[i] == '[':
                    bracket_count += 1
                elif text[i] == ']':
                    bracket_count -= 1
                    if bracket_count == 0:
                        last_complete_shot_end = i
                        break
                elif text[i] == '}' and bracket_count == 1:
                    # å¯èƒ½æ˜¯ä¸€ä¸ªå®Œæ•´çš„ shot å¯¹è±¡ç»“æŸ
                    last_complete_shot_end = i
                i += 1

            if last_complete_shot_end > start_idx:
                shots_text = text[start_idx:last_complete_shot_end + 1]
                # ç¡®ä¿é—­åˆ
                if not shots_text.endswith(']'):
                    shots_text += ']'
                try:
                    shots = json.loads(shots_text)
                    return {"shots": shots}
                except:
                    pass

        return None

    def _process_batch_with_fallback(
        self,
        client,
        uploaded_file,
        batch_prompt: str,
        shots_basic: List[dict],
        start_idx: int,
        end_idx: int,
        batch_idx: int,
        total_shots: int
    ) -> Optional[dict]:
        """
        å¤„ç†å•ä¸ªæ‰¹æ¬¡ï¼Œå¸¦å¤šå±‚é‡è¯•å’Œæ‹†åˆ†å›é€€

        ç­–ç•¥:
        1. ä¸»æ‰¹æ¬¡é‡è¯• 3 æ¬¡
        2. å°è¯• JSON ä¿®å¤
        3. å¦‚æœä»å¤±è´¥ä¸”æ‰¹æ¬¡ > 4 ä¸ª shotï¼Œæ‹†åˆ†æˆä¸¤åŠåˆ†åˆ«å¤„ç†
        """
        max_retries = 3
        last_response_text = ""

        for retry in range(max_retries):
            try:
                # Rate limiting
                if batch_idx > 0 or retry > 0:
                    time.sleep(2)

                response = gemini_call_with_retry(
                    client=client,
                    model="gemini-3-flash-preview",
                    contents=[batch_prompt, uploaded_file],
                    config=types.GenerateContentConfig(
                        response_mime_type="application/json"
                    )
                )

                last_response_text = response.text
                batch_result = self._parse_json_response(response.text, f"Shot Batch {batch_idx + 1}")

                # Debug: æ‰“å°è¿”å›çš„æ•°æ®ç»“æ„
                if isinstance(batch_result, dict):
                    shots_in_batch = batch_result.get("shots", [])
                    if shots_in_batch and len(shots_in_batch) > 0:
                        first_shot = shots_in_batch[0]
                        has_concrete = "concrete" in first_shot
                        shot_keys = list(first_shot.keys())[:5]  # åªæ˜¾ç¤ºå‰5ä¸ªé”®
                        print(f"   ğŸ“‹ Batch structure: {len(shots_in_batch)} shots, concrete_nested={has_concrete}, keys={shot_keys}")

                return batch_result

            except json.JSONDecodeError as e:
                print(f"âš ï¸ [Phase 2] Batch {batch_idx + 1} retry {retry + 1}/{max_retries}: JSON parse error")

                # å°è¯•ä¿®å¤ JSON
                if last_response_text:
                    fixed = self._try_fix_json(last_response_text)
                    if fixed:
                        print(f"   ğŸ”§ JSON repair successful")
                        return fixed

            except Exception as e:
                print(f"âš ï¸ [Phase 2] Batch {batch_idx + 1} retry {retry + 1}/{max_retries}: {e}")

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œå°è¯•æ‹†åˆ†æ‰¹æ¬¡
        batch_size = end_idx - start_idx
        if batch_size > 4:
            print(f"   ğŸ”€ Splitting batch {batch_idx + 1} into smaller chunks...")
            mid = start_idx + batch_size // 2

            # å¤„ç†å‰åŠéƒ¨åˆ†
            first_half = self._process_single_split(
                client, uploaded_file, shots_basic, start_idx, mid, total_shots, "A"
            )

            # å¤„ç†ååŠéƒ¨åˆ†
            second_half = self._process_single_split(
                client, uploaded_file, shots_basic, mid, end_idx, total_shots, "B"
            )

            # åˆå¹¶ç»“æœ
            if first_half or second_half:
                combined_shots = []
                if first_half:
                    combined_shots.extend(first_half.get("shots", []))
                if second_half:
                    combined_shots.extend(second_half.get("shots", []))

                if combined_shots:
                    print(f"   âœ… Split recovery: {len(combined_shots)} shots extracted")
                    return {"shots": combined_shots}

        return None

    def _process_single_split(
        self,
        client,
        uploaded_file,
        shots_basic: List[dict],
        start_idx: int,
        end_idx: int,
        total_shots: int,
        split_label: str
    ) -> Optional[dict]:
        """å¤„ç†æ‹†åˆ†åçš„å°æ‰¹æ¬¡"""
        shot_boundaries = create_shot_boundaries_text(shots_basic, start_idx, end_idx)
        split_prompt = SHOT_DETAIL_BATCH_PROMPT.replace(
            "{batch_start}", str(start_idx + 1)
        ).replace(
            "{batch_end}", str(end_idx)
        ).replace(
            "{total_shots}", str(total_shots)
        ).replace(
            "{shot_boundaries}", shot_boundaries
        ).replace(
            "{input_content}",
            "[Video file attached - extract detailed parameters for specified shots]"
        )

        try:
            time.sleep(2)
            response = gemini_call_with_retry(
                client=client,
                model="gemini-3-flash-preview",
                contents=[split_prompt, uploaded_file],
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )

            # ä½¿ç”¨å¢å¼ºçš„è§£æå™¨å¤„ç†è½¬ä¹‰åºåˆ—ç­‰é—®é¢˜
            result = self._parse_json_response(response.text, f"Shot Split {split_label}")
            print(f"      âœ… Split {split_label} completed ({start_idx + 1}-{end_idx})")
            return result

        except json.JSONDecodeError as e:
            print(f"      âŒ Split {split_label} JSON parse failed: {e}")
            return None

        except Exception as e:
            print(f"      âŒ Split {split_label} error: {e}")
            return None

    def _generate_character_ledger(
        self,
        shots: List[Dict[str, Any]],
        client
    ) -> Optional[Dict[str, Any]]:
        """
        ä¸‰é˜¶æ®µè§’è‰²/ç¯å¢ƒè¯†åˆ«æ¶æ„ (3-Pass Character Extraction)

        Pass 1 (Discovery): 2-3 å¼ å®½æ™¯å…³é”®å¸§ â†’ ç¡®å®šæ¼”å‘˜è¡¨ (who exists)
        Pass 2 (Presence Audit): é€è§’è‰²åˆ†æ‰¹å¸§å®¡è®¡ â†’ ç¡®å®šå‡ºåœºè¡¨ (where they appear)
        Pass 3 (Continuity Check): ç¡®å®šæ€§é—´éš™å¡«å…… + å¤–ç§‘å¼å•å›¾é‡æ£€

        ç‹¬ç«‹æ­¥éª¤: ç¯å¢ƒæå– (text-only, unchanged)

        Args:
            shots: Pillar III çš„ concrete shots åˆ—è¡¨
            client: Gemini å®¢æˆ·ç«¯å®ä¾‹

        Returns:
            å¤„ç†åçš„ character ledger æ•°æ®
        """
        print(f"ğŸ“Š [Character Ledger] Input: {len(shots)} shots to analyze")
        shot_subjects_text = build_shot_subjects_input(shots)
        all_shot_ids = [shot.get("shotId") for shot in shots if shot.get("shotId")]
        job_dir = Path("jobs") / self.job_id
        frames_dir = job_dir / "frames"

        # Helper: load frame bytes for a shot
        def load_frame(shot_id: str) -> bytes:
            frame_path = frames_dir / f"{shot_id}.png"
            if frame_path.exists():
                with open(frame_path, "rb") as f:
                    return f.read()
            return None

        # ============================================================
        # Pass 1: Character Discovery â€” 2-3 key frames
        # ============================================================
        key_frame_shots = select_key_frames(shots)
        key_frame_ids = [s.get("shotId") for s in key_frame_shots]
        print(f"ğŸ­ [Pass 1: Discovery] Selected {len(key_frame_shots)} key frames: {key_frame_ids}", flush=True)

        discovery_prompt = CHARACTER_DISCOVERY_PROMPT.replace("{shot_subjects}", shot_subjects_text)
        discovery_contents = [discovery_prompt]

        # Attach only key frame images
        for shot in key_frame_shots:
            shot_id = shot.get("shotId", "")
            frame_bytes = load_frame(shot_id)
            if frame_bytes:
                discovery_contents.append(f"[KEY FRAME â€” {shot_id}]:")
                discovery_contents.append(types.Part.from_bytes(data=frame_bytes, mime_type="image/png"))

        discovery_response = gemini_call_with_retry(
            client=client,
            model="gemini-3-flash-preview",
            contents=discovery_contents,
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                temperature=0.1
            )
        )

        try:
            discovery_result = json.loads(discovery_response.text)
            discovered_chars = discovery_result.get("characters", [])
            print(f"   âœ… Discovered {len(discovered_chars)} characters:")
            for c in discovered_chars:
                print(f"      - {c.get('entityId', '?')}: {c.get('displayName', '?')} [{c.get('importance', '?')}]")
        except json.JSONDecodeError as e:
            print(f"   âŒ Failed to parse Discovery JSON: {e}")
            print(f"   Raw response: {discovery_response.text[:300]}...")
            discovered_chars = []

        # ============================================================
        # Pass 2: Presence Audit â€” per PRIMARY character, batched frames
        # SECONDARY characters get a single-pass audit with all frames
        # ============================================================
        AUDIT_BATCH_SIZE = 6

        primary_chars = [c for c in discovered_chars if c.get("importance") == "PRIMARY"]
        secondary_chars = [c for c in discovered_chars if c.get("importance") != "PRIMARY"]

        print(f"ğŸ” [Pass 2: Presence Audit] Auditing {len(primary_chars)} PRIMARY characters (batched)...", flush=True)

        # Build character ledger entries
        character_ledger = []

        for char in primary_chars:
            char_name = char.get("displayName", "Unknown")
            char_desc = char.get("visualDescription", "")
            entity_id = char.get("entityId", f"orig_char_{len(character_ledger) + 1:02d}")

            print(f"   ğŸ¯ Auditing '{char_name}' ({entity_id})...", flush=True)

            appears_in = []

            # Split shots into batches
            for batch_start in range(0, len(shots), AUDIT_BATCH_SIZE):
                batch_shots = shots[batch_start:batch_start + AUDIT_BATCH_SIZE]
                batch_ids = [s.get("shotId", "") for s in batch_shots]

                audit_prompt = CHARACTER_PRESENCE_AUDIT_PROMPT.replace(
                    "{char_name}", char_name
                ).replace(
                    "{char_description}", char_desc
                )

                audit_contents = [audit_prompt]

                # Attach batch frame images
                for shot in batch_shots:
                    shot_id = shot.get("shotId", "")
                    frame_bytes = load_frame(shot_id)
                    if frame_bytes:
                        audit_contents.append(f"[{shot_id}]:")
                        audit_contents.append(types.Part.from_bytes(data=frame_bytes, mime_type="image/png"))

                audit_response = gemini_call_with_retry(
                    client=client,
                    model="gemini-3-flash-preview",
                    contents=audit_contents,
                    config=types.GenerateContentConfig(
                        response_mime_type="application/json",
                        temperature=0.1
                    )
                )

                try:
                    audit_result = json.loads(audit_response.text)
                    audit_entries = audit_result.get("audit", [])
                    for entry in audit_entries:
                        if entry.get("visible", False):
                            appears_in.append(entry.get("shotId", ""))
                except json.JSONDecodeError as e:
                    print(f"      âš ï¸ Failed to parse audit batch JSON: {e}")
                    # Fallback: assume visible in all batch shots
                    appears_in.extend(batch_ids)

            # Filter to valid shot IDs only
            appears_in = [sid for sid in appears_in if sid in all_shot_ids]
            print(f"      âœ… '{char_name}' visible in {len(appears_in)}/{len(all_shot_ids)} shots: {appears_in}")

            character_ledger.append({
                "entityId": entity_id,
                "entityType": "CHARACTER",
                "importance": "PRIMARY",
                "displayName": char_name,
                "visualSignature": char_desc[:100],
                "detailedDescription": char_desc,
                "appearsInShots": appears_in,
                "shotCount": len(appears_in),
                "trackingConfidence": "HIGH",
                "visualCues": []
            })

        # SECONDARY characters: single-pass audit (all frames at once, no batching)
        if secondary_chars:
            print(f"   ğŸ“‹ Auditing {len(secondary_chars)} SECONDARY characters (single-pass)...", flush=True)

            for char in secondary_chars:
                char_name = char.get("displayName", "Unknown")
                char_desc = char.get("visualDescription", "")
                entity_id = char.get("entityId", f"orig_char_{len(character_ledger) + 1:02d}")

                audit_prompt = CHARACTER_PRESENCE_AUDIT_PROMPT.replace(
                    "{char_name}", char_name
                ).replace(
                    "{char_description}", char_desc
                )

                audit_contents = [audit_prompt]
                for shot in shots:
                    shot_id = shot.get("shotId", "")
                    frame_bytes = load_frame(shot_id)
                    if frame_bytes:
                        audit_contents.append(f"[{shot_id}]:")
                        audit_contents.append(types.Part.from_bytes(data=frame_bytes, mime_type="image/png"))

                audit_response = gemini_call_with_retry(
                    client=client,
                    model="gemini-3-flash-preview",
                    contents=audit_contents,
                    config=types.GenerateContentConfig(
                        response_mime_type="application/json",
                        temperature=0.1
                    )
                )

                appears_in = []
                try:
                    audit_result = json.loads(audit_response.text)
                    for entry in audit_result.get("audit", []):
                        if entry.get("visible", False):
                            appears_in.append(entry.get("shotId", ""))
                except json.JSONDecodeError:
                    pass

                appears_in = [sid for sid in appears_in if sid in all_shot_ids]
                print(f"      âœ… '{char_name}' visible in {len(appears_in)}/{len(all_shot_ids)} shots")

                character_ledger.append({
                    "entityId": entity_id,
                    "entityType": "CHARACTER",
                    "importance": char.get("importance", "SECONDARY"),
                    "displayName": char_name,
                    "visualSignature": char_desc[:100],
                    "detailedDescription": char_desc,
                    "appearsInShots": appears_in,
                    "shotCount": len(appears_in),
                    "trackingConfidence": "MEDIUM",
                    "visualCues": []
                })

        # ============================================================
        # Environment Extraction (text-only, unchanged)
        # ============================================================
        env_prompt = ENVIRONMENT_EXTRACTION_PROMPT.replace("{shot_subjects}", shot_subjects_text)
        print(f"ğŸ  [Environment] Extracting environments...")

        env_response = gemini_call_with_retry(
            client=client,
            model="gemini-3-flash-preview",
            contents=[env_prompt],
            config=types.GenerateContentConfig(
                response_mime_type="application/json",
                temperature=0.1
            )
        )

        environment_ledger = []
        try:
            env_result = json.loads(env_response.text)
            raw_envs = env_result.get("environments", [])
            print(f"   âœ… Found {len(raw_envs)} environments")

            for i, env in enumerate(raw_envs):
                environment_ledger.append({
                    "entityId": env.get("entityId", f"orig_env_{i+1:02d}"),
                    "entityType": "ENVIRONMENT",
                    "importance": env.get("importance", "SECONDARY"),
                    "displayName": env.get("displayName", "Unknown"),
                    "visualSignature": env.get("visualDescription", "")[:100],
                    "detailedDescription": env.get("visualDescription", ""),
                    "appearsInShots": env.get("appearsInShots", []),
                    "shotCount": len(env.get("appearsInShots", []))
                })
        except json.JSONDecodeError as e:
            print(f"   âŒ Failed to parse environments JSON: {e}")
            raw_envs = []

        # ============================================================
        # Pass 3: Continuity Check â€” deterministic gap-fill + surgical re-check
        # ============================================================
        print(f"ğŸ”— [Pass 3: Continuity] Checking character continuity...", flush=True)

        character_ledger, recheck_requests = check_character_continuity(
            character_ledger, environment_ledger, all_shot_ids
        )

        # Execute surgical re-checks for 2-3 shot gaps
        if recheck_requests:
            print(f"   ğŸ”¬ Executing {len(recheck_requests)} surgical re-checks...", flush=True)

            for req in recheck_requests:
                shot_id = req["shotId"]
                frame_bytes = load_frame(shot_id)
                if not frame_bytes:
                    continue

                recheck_prompt = SURGICAL_RECHECK_PROMPT.replace(
                    "{char_name}", req["char_name"]
                ).replace(
                    "{char_description}", req["char_desc"]
                )

                recheck_contents = [
                    recheck_prompt,
                    f"[Frame: {shot_id}]:",
                    types.Part.from_bytes(data=frame_bytes, mime_type="image/png")
                ]

                recheck_response = gemini_call_with_retry(
                    client=client,
                    model="gemini-3-flash-preview",
                    contents=recheck_contents,
                    config=types.GenerateContentConfig(
                        response_mime_type="application/json",
                        temperature=0.1
                    )
                )

                try:
                    recheck_result = json.loads(recheck_response.text)
                    is_visible = recheck_result.get("visible", False)
                    print(f"      {req['entityId']} in {shot_id}: {'âœ… VISIBLE' if is_visible else 'âŒ NOT visible'}")

                    if is_visible:
                        # Add to character's appearsInShots
                        for char in character_ledger:
                            if char["entityId"] == req["entityId"]:
                                if shot_id not in char["appearsInShots"]:
                                    char["appearsInShots"].append(shot_id)
                                    char["appearsInShots"] = sorted(
                                        char["appearsInShots"],
                                        key=lambda s: all_shot_ids.index(s) if s in all_shot_ids else 999
                                    )
                                    char["shotCount"] = len(char["appearsInShots"])
                                break
                except json.JSONDecodeError:
                    print(f"      âš ï¸ Failed to parse re-check for {req['entityId']} in {shot_id}")

        # ============================================================
        # Combine results
        # ============================================================
        combined_result = {
            "clusteringSuccess": True,
            "characterLedger": character_ledger,
            "environmentLedger": environment_ledger,
            "clusteringSummary": {
                "totalCharacters": len(character_ledger),
                "primaryCharacters": len([c for c in character_ledger if c["importance"] == "PRIMARY"]),
                "secondaryCharacters": len([c for c in character_ledger if c["importance"] != "PRIMARY"]),
                "totalEnvironments": len(environment_ledger),
                "totalShots": len(all_shot_ids),
                "unclusteredShots": []
            }
        }

        # Final summary
        print(f"âœ… Character Ledger complete: {len(character_ledger)} characters, {len(environment_ledger)} environments")
        for char in character_ledger:
            print(f"   {char['entityId']}: {char['displayName']} â†’ {char['shotCount']}/{len(all_shot_ids)} shots {char['appearsInShots']}")

        return process_ledger_result(combined_result, all_shot_ids)

    def _init_identity_mapping(self, ledger_result: Dict[str, Any]) -> None:
        """
        åˆå§‹åŒ– Pillar IV çš„ identityMapping çŸ©é˜µ

        ä¸ºæ¯ä¸ªåŸç‰‡å®ä½“åˆ›å»ºç©ºçš„æ˜ å°„æ§½ä½ï¼Œå¾…ç”¨æˆ·åç»­ç»‘å®šæ›¿æ¢èµ„äº§

        Args:
            ledger_result: character ledger æ•°æ®
        """
        identity_mapping = {}

        # ä¸ºæ¯ä¸ªè§’è‰²åˆ›å»ºæ˜ å°„æ§½ä½
        for char in ledger_result.get("characterLedger", []):
            entity_id = char.get("entityId")
            identity_mapping[entity_id] = {
                "entityType": "CHARACTER",
                "originalEntity": {
                    "entityId": entity_id,
                    "displayName": char.get("displayName"),
                    "visualSignature": char.get("visualSignature"),
                    "importance": char.get("importance"),
                    "appearsInShots": char.get("appearsInShots", [])
                },
                "remixedEntity": None,  # Phase 3: ç”± Intent Injection å¡«å……
                "boundAsset": None,  # å¾…ç»‘å®š
                "bindingStatus": "UNBOUND",
                "bindingTimestamp": None,
                "isRemixed": False  # æ ‡è®°æ˜¯å¦å·²è¢« remix
            }

        # ä¸ºæ¯ä¸ªç¯å¢ƒåˆ›å»ºæ˜ å°„æ§½ä½
        for env in ledger_result.get("environmentLedger", []):
            entity_id = env.get("entityId")
            identity_mapping[entity_id] = {
                "entityType": "ENVIRONMENT",
                "originalEntity": {
                    "entityId": entity_id,
                    "displayName": env.get("displayName"),
                    "visualSignature": env.get("visualSignature"),
                    "importance": env.get("importance"),
                    "appearsInShots": env.get("appearsInShots", [])
                },
                "remixedEntity": None,  # Phase 3: ç”± Intent Injection å¡«å……
                "boundAsset": None,
                "bindingStatus": "UNBOUND",
                "bindingTimestamp": None,
                "isRemixed": False
            }

        # å­˜å‚¨åˆ° Pillar IV
        self.ir["pillars"]["IV_renderStrategy"]["identityMapping"] = identity_mapping

    def _update_identity_mapping_with_remix(self, parsed_intent: Dict[str, Any]) -> None:
        """
        Phase 3: æ ¹æ®è§£æåçš„æ„å›¾æ›´æ–° Identity Mapping

        ç”¨æˆ·é€‰æ‹©çš„å®ä½“æ›¿æ¢ï¼ˆsubjectMapping/environmentMappingï¼‰ä¼šå†™å…¥å¯¹åº”å®ä½“çš„ remixedEntity å­—æ®µ
        é‡‡ç”¨ Overwrite æ¨¡å¼ï¼šæ¯æ¬¡è°ƒç”¨ä¼šè¦†ç›– remixedEntityï¼Œä½†ä¿ç•™ originalEntity ä¸å˜

        Args:
            parsed_intent: è§£æåçš„ç”¨æˆ·æ„å›¾
        """
        identity_mapping = self.ir["pillars"]["IV_renderStrategy"].get("identityMapping", {})

        # å¤„ç†ä¸»ä½“æ›¿æ¢ (subjectMapping)
        for subject_map in parsed_intent.get("subjectMapping", []):
            entity_id = subject_map.get("originalEntityId")

            if not entity_id:
                continue

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°å®ä½“ (new_char_XX)
            if entity_id.startswith("new_"):
                # ä¸ºæ–°å®ä½“åˆ›å»ºæ˜ å°„æ¡ç›®
                identity_mapping[entity_id] = {
                    "entityType": "CHARACTER",
                    "originalEntity": None,  # æ–°å®ä½“æ²¡æœ‰åŸå§‹å®ä½“
                    "remixedEntity": {
                        "entityId": entity_id,
                        "toDescription": subject_map.get("toDescription", ""),
                        "detailedDescription": subject_map.get("detailedDescription", ""),
                        "persistentAttributes": subject_map.get("persistentAttributes", []),
                        "imageReference": subject_map.get("imageReference"),
                        "affectedShots": subject_map.get("affectedShots", ["all"]),
                        "isNewEntity": True
                    },
                    "boundAsset": subject_map.get("imageReference"),  # å¦‚æœæœ‰å‚è€ƒå›¾ï¼Œç›´æ¥ç»‘å®š
                    "bindingStatus": "REMIXED_NEW" if subject_map.get("imageReference") else "UNBOUND",
                    "bindingTimestamp": datetime.utcnow().isoformat() + "Z" if subject_map.get("imageReference") else None,
                    "isRemixed": True
                }
                print(f"   â• New character entity created: {entity_id}")
            elif entity_id in identity_mapping:
                # æ›´æ–°ç°æœ‰å®ä½“çš„ remixedEntityï¼ˆOverwrite æ¨¡å¼ï¼‰
                identity_mapping[entity_id]["remixedEntity"] = {
                    "toDescription": subject_map.get("toDescription", ""),
                    "detailedDescription": subject_map.get("detailedDescription", ""),
                    "persistentAttributes": subject_map.get("persistentAttributes", []),
                    "imageReference": subject_map.get("imageReference"),
                    "affectedShots": subject_map.get("affectedShots", ["all"]),
                    "isNewEntity": False
                }
                identity_mapping[entity_id]["isRemixed"] = True

                # å¦‚æœæœ‰å‚è€ƒå›¾ï¼Œæ›´æ–°ç»‘å®šçŠ¶æ€
                if subject_map.get("imageReference"):
                    identity_mapping[entity_id]["boundAsset"] = subject_map.get("imageReference")
                    identity_mapping[entity_id]["bindingStatus"] = "REMIXED_BOUND"
                    identity_mapping[entity_id]["bindingTimestamp"] = datetime.utcnow().isoformat() + "Z"

                print(f"   ğŸ”„ Character remixed: {entity_id} â†’ {subject_map.get('toDescription', '')[:30]}...")
            else:
                print(f"   âš ï¸ Warning: Entity {entity_id} not found in Identity Mapping")

        # å¤„ç†ç¯å¢ƒæ›¿æ¢ (environmentMapping)
        for env_map in parsed_intent.get("environmentMapping", []):
            entity_id = env_map.get("originalEntityId")

            if not entity_id:
                continue

            if entity_id.startswith("new_"):
                # ä¸ºæ–°ç¯å¢ƒåˆ›å»ºæ˜ å°„æ¡ç›®
                identity_mapping[entity_id] = {
                    "entityType": "ENVIRONMENT",
                    "originalEntity": None,
                    "remixedEntity": {
                        "entityId": entity_id,
                        "toDescription": env_map.get("toDescription", ""),
                        "detailedDescription": env_map.get("detailedDescription", ""),
                        "timeOfDay": env_map.get("timeOfDay", "unchanged"),
                        "weather": env_map.get("weather", "unchanged"),
                        "affectedShots": env_map.get("affectedShots", ["all"]),
                        "isNewEntity": True
                    },
                    "boundAsset": None,
                    "bindingStatus": "REMIXED_NEW",
                    "bindingTimestamp": datetime.utcnow().isoformat() + "Z",
                    "isRemixed": True
                }
                print(f"   â• New environment entity created: {entity_id}")
            elif entity_id in identity_mapping:
                identity_mapping[entity_id]["remixedEntity"] = {
                    "toDescription": env_map.get("toDescription", ""),
                    "detailedDescription": env_map.get("detailedDescription", ""),
                    "timeOfDay": env_map.get("timeOfDay", "unchanged"),
                    "weather": env_map.get("weather", "unchanged"),
                    "affectedShots": env_map.get("affectedShots", ["all"]),
                    "isNewEntity": False
                }
                identity_mapping[entity_id]["isRemixed"] = True
                identity_mapping[entity_id]["bindingStatus"] = "REMIXED"
                identity_mapping[entity_id]["bindingTimestamp"] = datetime.utcnow().isoformat() + "Z"

                print(f"   ğŸ”„ Environment remixed: {entity_id} â†’ {env_map.get('toDescription', '')[:30]}...")
            else:
                print(f"   âš ï¸ Warning: Environment {entity_id} not found in Identity Mapping")

        # ============================================================
        # å…¨å±€æ›¿æ¢æ£€æµ‹ï¼šå½“ç”¨æˆ·è¯´"æ‰€æœ‰è§’è‰²"æ—¶ï¼Œè‡ªåŠ¨åº”ç”¨åˆ°æœªè¢«æ˜ç¡® remix çš„è§’è‰²
        # ============================================================
        scope = parsed_intent.get("scope", "SINGLE_ELEMENT")
        style_instruction = parsed_intent.get("styleInstruction", {})
        subject_mappings = parsed_intent.get("subjectMapping", [])

        # æ£€æµ‹æ˜¯å¦æ˜¯å…¨å±€è§’è‰²æ›¿æ¢
        # æ¡ä»¶ï¼šscope æ˜¯ GLOBAL ä¸”æœ‰ artStyle æˆ–è‡³å°‘æœ‰ä¸€ä¸ª subject mapping
        is_global_character_remix = (
            scope == "GLOBAL" and
            (style_instruction.get("artStyle") or len(subject_mappings) > 0)
        )

        if is_global_character_remix and subject_mappings:
            # è·å–æ¨¡æ¿ï¼šä½¿ç”¨ç¬¬ä¸€ä¸ª subject mapping ä½œä¸ºæ¨¡æ¿
            template_mapping = subject_mappings[0]
            template_style = style_instruction.get("artStyle", "")
            template_description = template_mapping.get("detailedDescription", "")

            # ç»Ÿè®¡å·²è¢« remix çš„è§’è‰² ID
            remixed_char_ids = set(
                sm.get("originalEntityId") for sm in subject_mappings
                if sm.get("originalEntityId") and not sm.get("originalEntityId", "").startswith("new_")
            )

            # éå†æ‰€æœ‰è§’è‰²å®ä½“ï¼Œä¸ºæœªè¢« remix çš„åº”ç”¨æ¨¡æ¿
            applied_count = 0
            for entity_id, mapping in identity_mapping.items():
                if mapping.get("entityType") == "CHARACTER" and entity_id not in remixed_char_ids:
                    if not mapping.get("isRemixed"):
                        # è·å–åŸå§‹è§’è‰²ä¿¡æ¯
                        original_entity = mapping.get("originalEntity", {})
                        original_name = original_entity.get("displayName", "Unknown Character") if original_entity else "Unknown Character"

                        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæ–°æè¿°
                        # å°†æ¨¡æ¿ä¸­çš„æè¿°åº”ç”¨åˆ°è¿™ä¸ªè§’è‰²ï¼ˆä¿æŒè§’è‰²çš„åŸå§‹ç‰¹å¾ä½†åº”ç”¨æ–°é£æ ¼ï¼‰
                        adapted_description = f"{template_style} version of {original_name}. " + template_description if template_style else template_description

                        mapping["remixedEntity"] = {
                            "toDescription": f"{template_style} {original_name}" if template_style else original_name,
                            "detailedDescription": adapted_description,
                            "persistentAttributes": template_mapping.get("persistentAttributes", []),
                            "imageReference": None,
                            "affectedShots": ["all"],
                            "isNewEntity": False,
                            "autoApplied": True  # æ ‡è®°ä¸ºè‡ªåŠ¨åº”ç”¨
                        }
                        mapping["isRemixed"] = True
                        mapping["bindingStatus"] = "REMIXED_AUTO"
                        applied_count += 1

            if applied_count > 0:
                print(f"   ğŸ” Auto-applied global style to {applied_count} additional characters")

        # ä¿å­˜æ›´æ–°
        self.ir["pillars"]["IV_renderStrategy"]["identityMapping"] = identity_mapping

    def _run_abstraction(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 2: é€»è¾‘æŠ½è±¡
        å°† concrete æ•°æ®è„±æ•ï¼Œç”Ÿæˆ abstract éšå½¢æ¨¡æ¿

        TODO: æ¥å…¥ Meta Prompt (abstractionEngine)
        """
        print(f"ğŸ”® [Stage 2] Running abstraction for {self.job_id}...")

        meta_prompts = self.ir.get("metaPromptsRegistry", {})

        if not meta_prompts.get("abstractionEngine"):
            print("âš ï¸ Meta Prompt 'abstractionEngine' not configured, using placeholder")

        # è·å– concrete æ•°æ®
        story_theme_concrete = self.pillars["I_storyTheme"].get("concrete")
        narrative_concrete = self.pillars["II_narrativeTemplate"].get("concrete")
        shot_recipe_concrete = self.pillars["III_shotRecipe"].get("concrete")

        if not story_theme_concrete or not narrative_concrete or not shot_recipe_concrete:
            return {"status": "error", "reason": "Concrete data not available"}

        # TODO: è°ƒç”¨ AI è¿›è¡ŒæŠ½è±¡åŒ–
        # abstract_result = self._call_abstraction_engine(
        #     story_theme_concrete,
        #     narrative_concrete,
        #     shot_recipe_concrete,
        #     meta_prompts["abstractionEngine"]
        # )

        return {"status": "success", "message": "Abstraction completed (placeholder)"}

    def _run_intent_injection(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 3: æ„å›¾æ³¨å…¥ (M4 æ ¸å¿ƒ)
        å°†ç”¨æˆ·æ„å›¾æ³¨å…¥æŠ½è±¡æ¨¡æ¿ï¼Œç”Ÿæˆ remixed æ•°æ®

        ä¸¤æ­¥æµç¨‹:
        1. Intent Parser: è§£æç”¨æˆ·è‡ªç„¶è¯­è¨€ â†’ ParsedIntent
        2. Intent Fusion: Abstract + ParsedIntent â†’ RemixedLayer
        """
        print(f"ğŸ’‰ [Stage 3] Running intent injection for {self.job_id}...")

        user_prompt = self.user_intent.get("rawPrompt")
        if not user_prompt:
            return {"status": "error", "reason": "No user intent provided"}

        # è·å–å‚è€ƒå›¾ç‰‡è·¯å¾„
        reference_images = self.user_intent.get("referenceImages", [])

        # è·å–éšå½¢æ¨¡æ¿ (abstract å±‚)
        hidden_template = self.get_hidden_template()

        if not hidden_template.get("storyTheme") and not hidden_template.get("shotRecipe"):
            return {"status": "error", "reason": "Abstract template not available"}

        # è·å– concrete å±‚ä½œä¸ºå‚è€ƒ
        concrete_reference = {
            "storyTheme": self.pillars["I_storyTheme"].get("concrete"),
            "narrative": self.pillars["II_narrativeTemplate"].get("concrete"),
            "shotRecipe": self.pillars["III_shotRecipe"].get("concrete")
        }

        # è·å– Character Ledger å’Œ Environment Ledger (Phase 2: Entity-Aware Intent Parsing)
        narrative_pillar = self.pillars.get("II_narrativeTemplate", {})
        character_ledger = narrative_pillar.get("characterLedger", [])
        environment_ledger = narrative_pillar.get("environmentLedger", [])

        print(f"ğŸ“‹ [Ledger Context] Characters: {len(character_ledger)}, Environments: {len(environment_ledger)}")

        # ============================================================
        # Step 3.1: Intent Parsing (æ„å›¾è§£æ)
        # ============================================================
        print(f"ğŸ” [Stage 3.1] Parsing user intent...")

        try:
            parsed_intent = self._parse_user_intent(
                user_prompt,
                reference_images,
                hidden_template,
                character_ledger,
                environment_ledger
            )

            if not parsed_intent.get("parseSuccess"):
                return {"status": "error", "reason": "Intent parsing failed"}

            # åˆè§„æ£€æŸ¥
            is_compliant, compliance_issues = check_compliance(parsed_intent)
            if not is_compliant:
                print(f"âš ï¸ Compliance issues: {compliance_issues}")
                return {"status": "error", "reason": f"Compliance check failed: {compliance_issues}"}

            # å­˜å‚¨è§£æç»“æœ
            self.ir["userIntent"]["parsedIntent"] = parsed_intent

            # Phase 3: æ›´æ–° Identity Mapping (å°† remix æ„å›¾ç»‘å®šåˆ°å®ä½“)
            print(f"   [3.1.1] Updating Identity Mapping with remix data...")
            self._update_identity_mapping_with_remix(parsed_intent)

            self.save()

            print(f"âœ… [Stage 3.1] Intent parsed: {get_intent_summary(parsed_intent)}")

        except Exception as e:
            print(f"âŒ [Stage 3.1] Intent parsing failed: {e}")
            return {"status": "error", "reason": f"Intent parsing failed: {e}"}

        # ============================================================
        # Step 3.2: Intent Fusion (æ„å›¾èåˆ) - åˆ†æ‰¹å¤„ç†é¿å… token é™åˆ¶
        # ============================================================
        print(f"ğŸ”€ [Stage 3.2] Fusing intent with abstract template...")

        try:
            # 3.2.1: å…ˆç”Ÿæˆ Identity Anchors
            print(f"   [3.2.1] Generating identity anchors...")
            identity_anchors = self._generate_identity_anchors(
                parsed_intent,
                hidden_template,
                concrete_reference
            )
            print(f"   âœ… Generated {len(identity_anchors.get('characters', []))} character anchors, {len(identity_anchors.get('environments', []))} environment anchors")

            # 3.2.2: åˆ†æ‰¹ç”Ÿæˆ Shot Prompts (æ¯æ‰¹ 8 ä¸ªé•œå¤´)
            shot_recipe_concrete = concrete_reference.get("shotRecipe") or {}
            shot_recipe_abstract = hidden_template.get("shotRecipe") or {}
            concrete_shots = shot_recipe_concrete.get("shots", [])
            abstract_shots = shot_recipe_abstract.get("shotFunctions", [])

            # å¦‚æœ abstract ä¸ºç©ºï¼Œä½¿ç”¨ concrete çš„é•œå¤´åˆ—è¡¨
            if not abstract_shots and concrete_shots:
                abstract_shots = [{"shotId": s.get("shotId"), "beatTag": s.get("beatTag", "SETUP")} for s in concrete_shots]

            total_shots = len(abstract_shots) if abstract_shots else len(concrete_shots)
            batch_size = 8
            all_remixed_shots = []

            for i in range(0, total_shots, batch_size):
                batch_start = i
                batch_end = min(i + batch_size, total_shots)
                print(f"   [3.2.2] Processing shots {batch_start+1}-{batch_end} of {total_shots}...")

                batch_shots = self._generate_shot_prompts_batch(
                    parsed_intent,
                    identity_anchors,
                    concrete_shots[batch_start:batch_end] if concrete_shots else [],
                    abstract_shots[batch_start:batch_end] if abstract_shots else [],
                    batch_start
                )
                all_remixed_shots.extend(batch_shots)
                print(f"   âœ… Batch {i//batch_size + 1} completed: {len(batch_shots)} shots")

            # ç»„è£…å®Œæ•´çš„ fusion result
            fusion_result = {
                "fusionSuccess": True,
                "fusionTimestamp": datetime.utcnow().isoformat() + "Z",
                "remixedIdentityAnchors": identity_anchors,
                "remixedShots": all_remixed_shots,
                "globalRemixSummary": {
                    "totalShots": total_shots,
                    "shotsModified": len(all_remixed_shots),
                    "primaryChanges": [
                        m.get("toDescription", "")[:50] for m in parsed_intent.get("subjectMapping", [])[:2]
                    ],
                    "styleApplied": parsed_intent.get("styleInstruction", {}).get("artStyle", "None"),
                    "moodShift": parsed_intent.get("moodTone", {}).get("targetMood", "unchanged"),
                    "preservedElements": ["camera skeleton", "narrative rhythm", "beat structure"]
                }
            }

            # è½¬æ¢ä¸º remixed å±‚æ ¼å¼
            remixed_layer = convert_to_remixed_layer(fusion_result)

            # åå¤„ç†ï¼šæ¸…ç† Gemini æ®‹ç•™ã€è§£æå ä½ç¬¦ã€è§„èŒƒåŒ–ç›¸æœºå­—æ®µ
            remixed_layer = post_process_remixed_layer(remixed_layer)
            print(f"   âœ… Post-processed: cleaned artifacts, resolved placeholders, normalized camera fields")

            # å­˜å‚¨åˆ° userIntent.remixedLayer
            self.ir["userIntent"]["remixedLayer"] = remixed_layer

            # åŒæ—¶æ›´æ–°å„æ”¯æŸ±çš„ remixed å­—æ®µ
            self._distribute_remixed_to_pillars(remixed_layer)

            self.save()

            print(f"âœ… [Stage 3.2] Fusion completed:\n{generate_fusion_summary(fusion_result)}")

        except Exception as e:
            print(f"âŒ [Stage 3.2] Intent fusion failed: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "reason": f"Intent fusion failed: {e}"}

        return {
            "status": "success",
            "message": "Intent injection completed",
            "parsedIntent": get_intent_summary(parsed_intent),
            "remixedShots": len(remixed_layer.get("shots", []))
        }

    def _parse_user_intent(
        self,
        user_prompt: str,
        reference_images: List[str],
        source_abstract: Dict[str, Any],
        character_ledger: List[Dict[str, Any]] = None,
        environment_ledger: List[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ Gemini API è§£æç”¨æˆ·æ„å›¾

        Args:
            user_prompt: ç”¨æˆ·åŸå§‹è¾“å…¥
            reference_images: å‚è€ƒå›¾ç‰‡è·¯å¾„åˆ—è¡¨
            source_abstract: æºè§†é¢‘çš„ abstract æ¨¡æ¿
            character_ledger: è§’è‰²å®ä½“ç™»è®°è¡¨ï¼ˆç”¨äº Entity-Aware æ„å›¾è§£æï¼‰
            environment_ledger: ç¯å¢ƒå®ä½“ç™»è®°è¡¨ï¼ˆç”¨äº Entity-Aware æ„å›¾è§£æï¼‰

        Returns:
            ParsedIntent ç»“æ„ï¼ˆåŒ…å« originalEntityId å­—æ®µï¼‰
        """
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError("GEMINI_API_KEY not set")
        # Sanitize API key to remove non-ASCII characters (fixes encoding errors in HTTP headers)
        api_key = api_key.strip()
        api_key = ''.join(c for c in api_key if c.isascii() and c.isprintable())

        client = genai.Client(api_key=api_key)

        # æ ¼å¼åŒ– Character Ledger ä¸ºå¯è¯»æ–‡æœ¬
        character_ledger = character_ledger or []
        char_ledger_text = self._format_ledger_for_prompt(character_ledger, "character")

        # æ ¼å¼åŒ– Environment Ledger ä¸ºå¯è¯»æ–‡æœ¬
        environment_ledger = environment_ledger or []
        env_ledger_text = self._format_ledger_for_prompt(environment_ledger, "environment")

        # æ„å»º Prompt
        prompt = INTENT_PARSER_PROMPT.replace(
            "{user_instruction}",
            user_prompt
        ).replace(
            "{reference_images}",
            json.dumps(reference_images) if reference_images else "None"
        ).replace(
            "{source_abstract}",
            json.dumps(source_abstract, ensure_ascii=False, indent=2)
        ).replace(
            "{character_ledger}",
            char_ledger_text
        ).replace(
            "{environment_ledger}",
            env_ledger_text
        )

        # è°ƒç”¨ Gemini API
        print(f"ğŸ¤– Calling Gemini API for intent parsing...")
        response = client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=[prompt],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        # è§£æ JSON å“åº” (å¸¦å®¹é”™å¤„ç†)
        result = self._parse_json_response(response.text, "Intent parsing")
        print(f"âœ… Intent parsing received")

        # è§„èŒƒåŒ–ç»“æœ
        return parse_intent_result(result)

    def _format_ledger_for_prompt(
        self,
        ledger: List[Dict[str, Any]],
        ledger_type: str
    ) -> str:
        """
        æ ¼å¼åŒ– Ledger æ•°æ®ä¸ºå¯è¯»æ–‡æœ¬ï¼Œç”¨äº Intent Parser Prompt

        Args:
            ledger: Character æˆ– Environment Ledger åˆ—è¡¨
            ledger_type: "character" æˆ– "environment"

        Returns:
            æ ¼å¼åŒ–çš„æ–‡æœ¬å­—ç¬¦ä¸²
        """
        if not ledger:
            return f"No {ledger_type}s detected in the source video."

        lines = [f"=== {ledger_type.upper()} LEDGER ({len(ledger)} entities) ===\n"]

        for entity in ledger:
            entity_id = entity.get("entityId", "unknown")
            display_name = entity.get("displayName", "Unknown")
            visual_signature = entity.get("visualSignature", "")
            importance = entity.get("importance", "SECONDARY")

            lines.append(f"ã€{entity_id}ã€‘ {display_name}")
            lines.append(f"  - Importance: {importance}")
            lines.append(f"  - Visual Signature: {visual_signature}")

            # æ·»åŠ å‡ºç°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            appearances = entity.get("appearances", [])
            if appearances:
                shot_ids = [app.get("shotId", "") for app in appearances[:5]]  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                lines.append(f"  - Appears in: {', '.join(shot_ids)}")

                # æ·»åŠ ä¸€äº› visualCues ä½œä¸ºé¢å¤–åŒ¹é…çº¿ç´¢
                all_cues = []
                for app in appearances[:3]:
                    cues = app.get("visualCues", [])
                    all_cues.extend(cues[:2])  # æ¯ä¸ªå‡ºåœºå–2ä¸ªçº¿ç´¢
                if all_cues:
                    lines.append(f"  - Visual Cues: {', '.join(all_cues[:6])}")

            lines.append("")  # ç©ºè¡Œåˆ†éš”

        return "\n".join(lines)

    def _fuse_intent_with_template(
        self,
        parsed_intent: Dict[str, Any],
        abstract_template: Dict[str, Any],
        concrete_reference: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        è°ƒç”¨ Gemini API æ‰§è¡Œæ„å›¾èåˆ

        Args:
            parsed_intent: è§£æåçš„ç”¨æˆ·æ„å›¾
            abstract_template: æŠ½è±¡æ¨¡æ¿
            concrete_reference: å…·ä½“å±‚å‚è€ƒ

        Returns:
            Fusion ç»“æœï¼ŒåŒ…å« remixedIdentityAnchors å’Œ remixedShots
        """
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise RuntimeError("GEMINI_API_KEY not set")
        # Sanitize API key to remove non-ASCII characters (fixes encoding errors in HTTP headers)
        api_key = api_key.strip()
        api_key = ''.join(c for c in api_key if c.isascii() and c.isprintable())

        client = genai.Client(api_key=api_key)

        # æ„å»º Prompt
        prompt = INTENT_FUSION_PROMPT.replace(
            "{parsed_intent}",
            json.dumps(parsed_intent, ensure_ascii=False, indent=2)
        ).replace(
            "{abstract_template}",
            json.dumps(abstract_template, ensure_ascii=False, indent=2)
        ).replace(
            "{concrete_reference}",
            json.dumps(concrete_reference, ensure_ascii=False, indent=2)
        )

        # è°ƒç”¨ Gemini API
        print(f"ğŸ¤– Calling Gemini API for intent fusion...")
        response = client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=[prompt],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        # è§£æ JSON å“åº” (å¸¦å®¹é”™å¤„ç†)
        result = self._parse_json_response(response.text, "Intent fusion")
        print(f"âœ… Intent fusion received")

        return result

    def _extract_unique_subjects_and_scenes(
        self,
        concrete_reference: Dict[str, Any],
        max_subjects: int = 50,
        max_environments: int = 20
    ) -> Dict[str, List[Dict]]:
        """
        ä» concrete å±‚æå–ç‹¬ç‰¹çš„ä¸»ä½“å’Œåœºæ™¯

        Returns:
            {
                "subjects": [{"id": "subj_01", "description": "...", "shotIds": [...]}],
                "environments": [{"id": "env_01", "description": "...", "shotIds": [...]}]
            }
        """
        shot_recipe = concrete_reference.get("shotRecipe") or {}
        shots = shot_recipe.get("shots", [])

        # æå–ä¸»ä½“å’Œåœºæ™¯ï¼Œå¹¶è®°å½•å‡ºç°çš„é•œå¤´
        subject_map = {}  # description -> {"count": N, "shotIds": [...]}
        scene_map = {}

        for shot in shots:
            shot_id = shot.get("shotId", "")
            subject = shot.get("subject", "").strip()
            scene = shot.get("scene", "").strip()

            if subject:
                # ä½¿ç”¨ç®€åŒ–çš„ keyï¼ˆå‰50å­—ç¬¦ï¼‰æ¥å»é‡ç›¸ä¼¼æè¿°
                key = subject[:50].lower()
                if key not in subject_map:
                    subject_map[key] = {
                        "fullDescription": subject,
                        "count": 0,
                        "shotIds": []
                    }
                subject_map[key]["count"] += 1
                subject_map[key]["shotIds"].append(shot_id)

            if scene:
                key = scene[:50].lower()
                if key not in scene_map:
                    scene_map[key] = {
                        "fullDescription": scene,
                        "count": 0,
                        "shotIds": []
                    }
                scene_map[key]["count"] += 1
                scene_map[key]["shotIds"].append(shot_id)

        # æŒ‰å‡ºç°é¢‘ç‡æ’åºï¼Œå– top N
        sorted_subjects = sorted(
            subject_map.values(),
            key=lambda x: x["count"],
            reverse=True
        )[:max_subjects]

        sorted_scenes = sorted(
            scene_map.values(),
            key=lambda x: x["count"],
            reverse=True
        )[:max_environments]

        # æ„å»ºè¿”å›ç»“æ„
        subjects = [
            {
                "id": f"subj_{i+1:02d}",
                "description": item["fullDescription"],
                "shotIds": item["shotIds"],
                "frequency": item["count"]
            }
            for i, item in enumerate(sorted_subjects)
        ]

        environments = [
            {
                "id": f"scene_{i+1:02d}",
                "description": item["fullDescription"],
                "shotIds": item["shotIds"],
                "frequency": item["count"]
            }
            for i, item in enumerate(sorted_scenes)
        ]

        return {"subjects": subjects, "environments": environments}

    def _generate_identity_anchors(
        self,
        parsed_intent: Dict[str, Any],
        abstract_template: Dict[str, Any],
        concrete_reference: Dict[str, Any],
        max_character_anchors: int = 50,
        max_environment_anchors: int = 20
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆ Identity Anchors (è§’è‰²å’Œç¯å¢ƒçš„è¯¦ç»†æè¿°)

        Phase 4 Enhancement:
        - ä¼˜å…ˆä½¿ç”¨ parsed_intent ä¸­çš„ detailedDescriptionï¼ˆæ¥è‡ª Intent Parser çš„ 80-120 è¯æè¿°ï¼‰
        - å‚è€ƒ Identity Mapping ä¸­çš„ remixedEntity æ•°æ®
        - ä¸ºæœªè¢« remix çš„å®ä½“ä¿ç•™åŸå§‹æè¿°
        - æ”¯æŒå…¨å±€æ›¿æ¢ï¼šå½“ scope=GLOBAL æ—¶ï¼Œä¸ºæ‰€æœ‰è§’è‰²ç”Ÿæˆ anchors

        Args:
            max_character_anchors: æœ€å¤šç”Ÿæˆå‡ ä¸ªè§’è‰² anchorï¼ˆé»˜è®¤ 50ï¼Œè¶³å¤Ÿè¦†ç›–å¤§å¤šæ•°è§†é¢‘ï¼‰
            max_environment_anchors: æœ€å¤šç”Ÿæˆå‡ ä¸ªç¯å¢ƒ anchorï¼ˆé»˜è®¤ 20ï¼‰
        """
        api_key = os.getenv("GEMINI_API_KEY")
        # Sanitize API key to remove non-ASCII characters (fixes encoding errors in HTTP headers)
        if api_key:
            api_key = api_key.strip()
            api_key = ''.join(c for c in api_key if c.isascii() and c.isprintable())
        client = genai.Client(api_key=api_key)

        # æå–åŸå§‹è§†é¢‘ä¸­çš„ç‹¬ç‰¹ä¸»ä½“å’Œåœºæ™¯
        unique_elements = self._extract_unique_subjects_and_scenes(
            concrete_reference,
            max_subjects=max_character_anchors,
            max_environments=max_environment_anchors
        )

        print(f"   ğŸ“Š Found {len(unique_elements['subjects'])} unique subjects, {len(unique_elements['environments'])} unique environments")

        # Phase 4: è·å– Identity Mapping ä¸­çš„ remixedEntity æ•°æ®
        identity_mapping = self.ir["pillars"]["IV_renderStrategy"].get("identityMapping", {})
        remixed_entities = {
            "characters": [],
            "environments": []
        }

        # æ”¶é›†å·² remix çš„è§’è‰²å®ä½“
        for entity_id, mapping in identity_mapping.items():
            if mapping.get("isRemixed") and mapping.get("remixedEntity"):
                remixed = mapping["remixedEntity"]
                original = mapping.get("originalEntity", {})
                entity_type = mapping.get("entityType", "CHARACTER")

                if entity_type == "CHARACTER":
                    remixed_entities["characters"].append({
                        "originalEntityId": entity_id,
                        "originalDisplayName": original.get("displayName", "") if original else "New Character",
                        "remixedDescription": remixed.get("toDescription", ""),
                        "detailedDescription": remixed.get("detailedDescription", ""),
                        "persistentAttributes": remixed.get("persistentAttributes", []),
                        "imageReference": remixed.get("imageReference"),
                        "affectedShots": remixed.get("affectedShots", ["all"]),
                        "isNewEntity": remixed.get("isNewEntity", False)
                    })
                elif entity_type == "ENVIRONMENT":
                    remixed_entities["environments"].append({
                        "originalEntityId": entity_id,
                        "originalDisplayName": original.get("displayName", "") if original else "New Environment",
                        "remixedDescription": remixed.get("toDescription", ""),
                        "detailedDescription": remixed.get("detailedDescription", ""),
                        "timeOfDay": remixed.get("timeOfDay", "unchanged"),
                        "weather": remixed.get("weather", "unchanged"),
                        "affectedShots": remixed.get("affectedShots", ["all"]),
                        "isNewEntity": remixed.get("isNewEntity", False)
                    })

        print(f"   ğŸ“‹ Remixed entities from Identity Mapping: {len(remixed_entities['characters'])} characters, {len(remixed_entities['environments'])} environments")

        prompt = f"""
# Task: Generate Fine-Grained Identity Anchors for Video Remix

Based on the user's remix intent and the Identity Mapping data, generate detailed visual descriptions for EACH remixed character and environment.

## ğŸ¯ CRITICAL: Use Pre-computed Detailed Descriptions

The `detailedDescription` field in the remixed entities below has been carefully crafted with 80-120 words of VISUAL properties only (materials, textures, lighting behavior, proportions).

**YOU MUST:**
1. USE the provided `detailedDescription` AS-IS if it exists and is not empty
2. Only generate new descriptions if `detailedDescription` is empty or missing
3. NEVER replace a good detailed description with a shorter or different one

## Remixed Entities from Identity Mapping (PRE-COMPUTED):
{json.dumps(remixed_entities, ensure_ascii=False, indent=2)}

## Original Video's Unique Subjects (for reference):
{json.dumps(unique_elements['subjects'], ensure_ascii=False, indent=2)}

## Original Video's Unique Environments (for reference):
{json.dumps(unique_elements['environments'], ensure_ascii=False, indent=2)}

## Original Content Context:
- Story Theme: {json.dumps(concrete_reference.get('storyTheme', {}).get('coreTheme', {}), ensure_ascii=False)}

## Instructions:
1. For EACH remixed character, create an anchor using the provided detailedDescription
2. For EACH remixed environment, create an anchor using the provided detailedDescription
3. Map anchorId to the originalEntityId (e.g., orig_char_01 â†’ char_01, orig_env_01 â†’ env_01)
4. For new entities (new_char_XX, new_env_XX), use those IDs as anchorIds
5. Include which shotIds this anchor applies to (from affectedShots)

## âš ï¸ CRITICAL â€” Clothing/Props Inheritance:
When a character has `persistentAttributes` (e.g., clothing, accessories, held objects, vehicles), the `detailedDescription` MUST include ALL of these items on the NEW subject. The subject's identity (face, body, species) changes but their outfit, belongings, and interactive props remain the same. Do NOT invent new clothing or accessories â€” faithfully transfer what is listed in `persistentAttributes`. Also reference the ORIGINAL character's description from the Ledger to capture any clothing/props not explicitly listed in persistentAttributes.

## Output Format (Strict JSON):
{{
  "characters": [
    {{
      "anchorId": "char_01",
      "originalEntityId": "orig_char_01",
      "originalDescription": "Original subject description from Ledger...",
      "anchorName": "Remixed Character Name",
      "detailedDescription": "COPY the provided 80-120 word visual description EXACTLY - materials, textures, lighting, proportions...",
      "persistentAttributes": ["attribute1", "attribute2"],
      "imageReference": null,
      "styleAdaptation": "How this character looks in the target style",
      "appliedToShots": ["shot_01", "shot_05"]
    }}
  ],
  "environments": [
    {{
      "anchorId": "env_01",
      "originalEntityId": "orig_env_01",
      "originalDescription": "Original scene description from Ledger...",
      "anchorName": "Remixed Location Name",
      "detailedDescription": "COPY the provided 80-120 word visual description EXACTLY - architectural materials, lighting angles, atmospheric density...",
      "atmosphericConditions": "time of day, weather, mood lighting (remixed)",
      "styleAdaptation": "How this environment looks in the target style",
      "appliedToShots": ["shot_02", "shot_08"]
    }}
  ]
}}

Output ONLY valid JSON. No markdown, no explanation.
"""

        response = client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=[prompt],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        return self._parse_json_response(response.text, "Identity anchors")

    def _generate_shot_prompts_batch(
        self,
        parsed_intent: Dict[str, Any],
        identity_anchors: Dict[str, Any],
        concrete_shots: List[Dict],
        abstract_shots: List[Dict],
        batch_offset: int
    ) -> List[Dict[str, Any]]:
        """
        åˆ†æ‰¹ç”Ÿæˆ Shot Prompts (T2I + I2V)
        """
        api_key = os.getenv("GEMINI_API_KEY")
        # Sanitize API key to remove non-ASCII characters (fixes encoding errors in HTTP headers)
        if api_key:
            api_key = api_key.strip()
            api_key = ''.join(c for c in api_key if c.isascii() and c.isprintable())
        client = genai.Client(api_key=api_key)

        # æ„å»ºé•œå¤´ä¿¡æ¯
        shots_info = []
        for i, (concrete, abstract) in enumerate(zip(concrete_shots, abstract_shots or concrete_shots)):
            shots_info.append({
                "shotId": concrete.get("shotId", f"shot_{batch_offset + i + 1:02d}"),
                "beatTag": abstract.get("beatTag", concrete.get("beatTag", "SETUP")),
                "startTime": concrete.get("startTime", ""),
                "endTime": concrete.get("endTime", ""),
                "durationSeconds": concrete.get("durationSeconds", 3.0),
                "originalDescription": concrete.get("firstFrameDescription", concrete.get("subject", "")),
                "camera": concrete.get("camera", {}),
                "lighting": concrete.get("lighting", ""),
                "dynamics": concrete.get("dynamics", "")
            })

        prompt = f"""
# Task: Generate T2I and I2V Prompts for Video Shots

Apply the remix intent to generate Imagen 4.0 (T2I) and Veo 3.1 (I2V) prompts.

## ğŸ¯ ABSOLUTE CAMERA PRESERVATION (CRITICAL)

The camera parameters from the original video MUST be preserved EXACTLY. This is non-negotiable.
- **shotSize**: NEVER change (CLOSE_UP stays CLOSE_UP, WIDE stays WIDE)
- **cameraAngle**: NEVER change (Eye-level stays Eye-level, High angle stays High angle)
- **cameraMovement**: NEVER change (Static stays Static, Pan stays Pan)
- **focalLengthDepth**: NEVER change

The new remixed subject MUST FIT the original camera framing. If original is CLOSE_UP, the new subject appears in CLOSE_UP.

## Identity Anchors (use detailedDescription for prompts):
{json.dumps(identity_anchors, ensure_ascii=False, indent=2)}

## User Remix Intent:
- Subject Changes: {json.dumps(parsed_intent.get('subjectMapping', []), ensure_ascii=False)}
- Environment Changes: {json.dumps(parsed_intent.get('environmentMapping', []), ensure_ascii=False)}
- Style: {parsed_intent.get('styleInstruction', {}).get('artStyle', 'realistic')}
- Mood: {parsed_intent.get('moodTone', {}).get('targetMood', 'unchanged')}

## Shots to Process:
{json.dumps(shots_info, ensure_ascii=False, indent=2)}

## Output Format (Strict JSON array):
[
  {{
    "shotId": "shot_01",
    "beatTag": "HOOK",
    "startTime": "00:00:00.000",
    "endTime": "00:00:03.000",
    "durationSeconds": 3.0,
    "cameraPreserved": {{
      "shotSize": "EXACTLY from original - NEVER modify",
      "cameraAngle": "EXACTLY from original - NEVER modify",
      "cameraMovement": "EXACTLY from original - NEVER modify",
      "focalLengthDepth": "EXACTLY from original - NEVER modify"
    }},
    "T2I_FirstFrame": "[Subject from Identity Anchor detailedDescription], [pose matching original], [environment], [style], [lighting], [EXACT camera specs from cameraPreserved], high detail, cinematic --ar 16:9",
    "I2V_VideoGen": "[EXACT camera movement from cameraPreserved], [action], [physics details], maintaining exact composition and lighting from the first frame, cinematic, [duration]s",
    "remixNotes": "Brief change description",
    "appliedAnchors": {{"characters": ["char_01"], "environments": ["env_01"]}}
  }}
]

## CRITICAL RULES:
1. T2I prompt MUST end with --ar 16:9
2. I2V prompt MUST include "maintaining exact composition and lighting from the first frame"
3. **cameraPreserved MUST COPY EXACTLY from the original shot's camera field** - DO NOT INVENT NEW VALUES
4. T2I prompt MUST include the camera's shotSize (e.g., "medium shot", "close-up", "wide shot")
5. I2V prompt MUST start with the exact camera movement (e.g., "camera holds steady", "camera pans left")
6. Use the detailedDescription from Identity Anchors (80-120 words of visual properties)
7. Keep prompts concise but specific (50-80 words each)

Output ONLY valid JSON array. No markdown.
"""

        response = client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=[prompt],
            config=types.GenerateContentConfig(
                response_mime_type="application/json"
            )
        )

        result = self._parse_json_response(response.text, f"Shot prompts batch")

        # ç¡®ä¿è¿”å›åˆ—è¡¨
        if isinstance(result, dict) and "remixedShots" in result:
            return result["remixedShots"]
        elif isinstance(result, list):
            return result
        else:
            return []

    def _parse_json_response(self, text: str, context: str = "API") -> Dict[str, Any]:
        """
        è§£æ JSON å“åº”ï¼Œå¸¦å®¹é”™å¤„ç†

        Args:
            text: åŸå§‹å“åº”æ–‡æœ¬
            context: ä¸Šä¸‹æ–‡æè¿° (ç”¨äºé”™è¯¯æ¶ˆæ¯)

        Returns:
            è§£æåçš„ JSON å¯¹è±¡
        """
        import re

        if not text:
            raise ValueError(f"{context}: Empty response")

        s = text.strip()

        # ç§»é™¤ markdown code blocks
        if s.startswith("```"):
            lines = s.split('\n')
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            s = '\n'.join(lines).strip()

        # å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(s)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ {context}: Initial JSON parse failed, attempting fixes...")
            print(f"   Error: {e.msg} at line {e.lineno}")

        # ä¿®å¤å¸¸è§é—®é¢˜
        # 1. ç§»é™¤å°¾éƒ¨é€—å·
        s = re.sub(r',\s*]', ']', s)
        s = re.sub(r',\s*}', '}', s)

        # 2. ç§»é™¤æ³¨é‡Š
        s = re.sub(r'//.*?\n', '\n', s)
        s = re.sub(r'/\*.*?\*/', '', s, flags=re.DOTALL)

        # 3. ä¿®å¤æ— æ•ˆçš„è½¬ä¹‰åºåˆ—ï¼ˆå¦‚ \N, \n åœ¨ä¸è¯¥å‡ºç°çš„åœ°æ–¹ï¼‰
        # å…ˆä¿æŠ¤åˆæ³•çš„è½¬ä¹‰åºåˆ—
        s = s.replace('\\\\', '<<<DOUBLE_BACKSLASH>>>')
        s = s.replace('\\"', '<<<ESCAPED_QUOTE>>>')
        s = s.replace('\\n', '<<<NEWLINE>>>')
        s = s.replace('\\t', '<<<TAB>>>')
        s = s.replace('\\r', '<<<CR>>>')
        # ç§»é™¤å…¶ä»–æ— æ•ˆçš„åæ–œæ ï¼ˆåœ¨ JSON å­—ç¬¦ä¸²ä¸­ä¸åˆæ³•çš„è½¬ä¹‰ï¼‰
        s = re.sub(r'\\([^"\\nrtbfu/])', r'\1', s)
        # æ¢å¤åˆæ³•çš„è½¬ä¹‰åºåˆ—
        s = s.replace('<<<DOUBLE_BACKSLASH>>>', '\\\\')
        s = s.replace('<<<ESCAPED_QUOTE>>>', '\\"')
        s = s.replace('<<<NEWLINE>>>', '\\n')
        s = s.replace('<<<TAB>>>', '\\t')
        s = s.replace('<<<CR>>>', '\\r')

        # 3. ä¿®å¤å­—ç¬¦ä¸²å†…çš„æ¢è¡Œ
        def fix_string_newlines(text):
            result = []
            in_string = False
            escape_next = False
            for char in text:
                if escape_next:
                    result.append(char)
                    escape_next = False
                    continue
                if char == '\\':
                    result.append(char)
                    escape_next = True
                    continue
                if char == '"':
                    in_string = not in_string
                    result.append(char)
                    continue
                if char == '\n' and in_string:
                    result.append('\\n')
                    continue
                result.append(char)
            return ''.join(result)

        s = fix_string_newlines(s)

        # å†æ¬¡å°è¯•è§£æ
        try:
            return json.loads(s)
        except json.JSONDecodeError as e:
            print(f"âš ï¸ {context}: JSON parse failed, attempting truncation repair...")

            # å°è¯•ä¿®å¤æˆªæ–­çš„ JSON
            repaired = self._try_repair_truncated_json(s)
            if repaired:
                print(f"   ğŸ”§ JSON repair successful")
                return repaired

            # æ‰“å°é”™è¯¯ä¸Šä¸‹æ–‡
            lines = s.split('\n')
            error_line = e.lineno - 1
            start = max(0, error_line - 2)
            end = min(len(lines), error_line + 3)
            print(f"âŒ {context}: JSON parse failed after all fixes")
            print(f"   Error: {e.msg} at line {e.lineno}, col {e.colno}")
            print(f"   Error context (lines {start+1}-{end}):")
            for i in range(start, end):
                marker = ">>> " if i == error_line else "    "
                line_preview = lines[i][:80] + "..." if len(lines[i]) > 80 else lines[i]
                print(f"   {marker}{i+1}: {line_preview}")
            raise

    def _try_repair_truncated_json(self, text: str) -> Optional[Dict[str, Any]]:
        """
        å°è¯•ä¿®å¤æˆªæ–­çš„ JSON

        å¸¸è§é—®é¢˜ï¼š
        1. JSON åœ¨ä¸­é—´è¢«æˆªæ–­ï¼Œç¼ºå°‘é—­åˆæ‹¬å·
        2. æœ€åä¸€ä¸ªå…ƒç´ ä¸å®Œæ•´
        """
        s = text.strip()

        # å¦‚æœå·²ç»æ˜¯æœ‰æ•ˆ JSONï¼Œç›´æ¥è¿”å›
        try:
            return json.loads(s)
        except:
            pass

        # å°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ } æˆ– ]
        # ç„¶åè¡¥å…¨ç¼ºå¤±çš„æ‹¬å·
        open_braces = s.count('{') - s.count('}')
        open_brackets = s.count('[') - s.count(']')

        if open_braces > 0 or open_brackets > 0:
            # åˆ é™¤æœ€åä¸€ä¸ªä¸å®Œæ•´çš„å…ƒç´ ï¼ˆé€šå¸¸åœ¨é€—å·åé¢ï¼‰
            # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„ } æˆ– ]
            last_complete_idx = max(s.rfind('}'), s.rfind(']'))
            if last_complete_idx > 0:
                s = s[:last_complete_idx + 1]

            # é‡æ–°è®¡ç®—
            open_braces = s.count('{') - s.count('}')
            open_brackets = s.count('[') - s.count(']')

            # è¡¥å…¨æ‹¬å·
            s += ']' * open_brackets + '}' * open_braces

            try:
                return json.loads(s)
            except:
                pass

        # å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„é¡¶å±‚å¯¹è±¡
        brace_count = 0
        start_idx = s.find('{')
        if start_idx >= 0:
            for i in range(start_idx, len(s)):
                if s[i] == '{':
                    brace_count += 1
                elif s[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        try:
                            return json.loads(s[start_idx:i + 1])
                        except:
                            break

        return None

    def _distribute_remixed_to_pillars(self, remixed_layer: Dict[str, Any]) -> None:
        """
        å°† remixed ç»“æœåˆ†å‘åˆ°å„æ”¯æŸ±çš„ remixed å­—æ®µ

        Args:
            remixed_layer: èåˆåçš„ remixed å±‚æ•°æ®
        """
        # æå– Identity Anchors åˆ° Pillar IV
        identity_anchors = remixed_layer.get("identityAnchors", {})
        if identity_anchors:
            # è½¬æ¢ä¸º Pillar IV æ ¼å¼
            char_anchors = []
            for char in identity_anchors.get("characters", []):
                char_anchors.append({
                    "anchorId": char.get("anchorId"),
                    "role": "remixed",
                    "name": char.get("anchorName", ""),
                    "description": char.get("detailedDescription", ""),
                    "visualDNA": {
                        "hair": "",
                        "clothing": "",
                        "features": char.get("styleAdaptation", ""),
                        "bodyType": "",
                        "accessories": ", ".join(char.get("persistentAttributes", []))
                    },
                    "threeViews": {"front": None, "side": None, "back": None},
                    "status": "NOT_STARTED"
                })

            env_anchors = []
            for env in identity_anchors.get("environments", []):
                env_anchors.append({
                    "anchorId": env.get("anchorId"),
                    "type": "remixed",
                    "name": env.get("anchorName", ""),
                    "description": env.get("detailedDescription", ""),
                    "referenceImage": None,
                    "status": "NOT_STARTED"
                })

            self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["characters"] = char_anchors
            self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["environments"] = env_anchors

        # æå– T2I/I2V prompts åˆ° shotRenderRecipes
        shots = remixed_layer.get("shots", [])
        render_recipes = []
        for shot in shots:
            # å¤„ç† appliedAnchors å¯èƒ½æ˜¯ list æˆ– dict çš„æƒ…å†µ
            applied_anchors = shot.get("appliedAnchors", {})
            if isinstance(applied_anchors, dict):
                ref_chars = applied_anchors.get("characters", [])
                ref_envs = applied_anchors.get("environments", [])
            elif isinstance(applied_anchors, list):
                # å¦‚æœæ˜¯ listï¼Œå°è¯•æå–å…¶ä¸­çš„å¼•ç”¨
                ref_chars = []
                ref_envs = []
                for anchor in applied_anchors:
                    if isinstance(anchor, str):
                        # ç®€å•å­—ç¬¦ä¸²å½¢å¼çš„ anchor ID
                        if anchor.startswith("char_"):
                            ref_chars.append(anchor)
                        elif anchor.startswith("env_"):
                            ref_envs.append(anchor)
                        else:
                            ref_chars.append(anchor)  # é»˜è®¤å½“ä½œè§’è‰²
                    elif isinstance(anchor, dict):
                        # dict å½¢å¼ï¼Œå°è¯•è·å– id
                        anchor_id = anchor.get("id", anchor.get("anchorId", ""))
                        if "char" in anchor_id.lower() or anchor.get("type") == "character":
                            ref_chars.append(anchor_id)
                        else:
                            ref_envs.append(anchor_id)
            else:
                ref_chars = []
                ref_envs = []

            render_recipes.append({
                "shotId": shot.get("shotId"),
                "textToImagePrompt": shot.get("T2I_FirstFrame", ""),
                "imageToVideoPrompt": shot.get("I2V_VideoGen", ""),
                "referenceAnchors": ref_chars + ref_envs,
                "executionType": "I2V",
                "status": "NOT_STARTED"
            })

        self.ir["pillars"]["IV_renderStrategy"]["shotRenderRecipes"] = render_recipes

    def _run_asset_generation(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 4: èµ„äº§ç”Ÿæˆ
        ä½¿ç”¨ Gemini 3 Pro Image ç”Ÿæˆè§’è‰²ä¸‰è§†å›¾å’Œç¯å¢ƒå‚è€ƒå›¾

        æµç¨‹:
        1. ä» Pillar IV è·å– Identity Anchors
        2. ä¸ºæ¯ä¸ªè§’è‰²ç”Ÿæˆä¸‰è§†å›¾ (front/side/back)
        3. ä¸ºæ¯ä¸ªç¯å¢ƒç”Ÿæˆå‚è€ƒå›¾
        4. æ›´æ–° film_ir.json ä¸­çš„èµ„äº§è·¯å¾„
        """
        print(f"ğŸ¨ [Stage 4] Running asset generation for {self.job_id}...")

        try:
            from core.asset_generator import AssetGenerator, AssetStatus

            # åˆå§‹åŒ–èµ„äº§ç”Ÿæˆå™¨
            generator = AssetGenerator(self.job_id, str(self.project_dir))

            # è·å– Identity Anchors
            identity_anchors = self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]
            characters = identity_anchors.get("characters", [])
            environments = identity_anchors.get("environments", [])

            if not characters and not environments:
                print("âš ï¸ No identity anchors found. Run intent injection (M4) first.")
                return {"status": "skipped", "message": "No identity anchors to generate"}

            # è·å–ç”¨æˆ·å‚è€ƒå›¾ï¼ˆå¦‚æœæœ‰ï¼‰
            user_reference_images = self.ir.get("userIntent", {}).get("referenceImages", [])

            total_assets = len(characters) * 3 + len(environments)
            generated_count = 0
            failed_count = 0

            print(f"   ğŸ“Š Total assets to generate: {total_assets} ({len(characters)} characters Ã— 3 views + {len(environments)} environments)")

            # è¿›åº¦å›è°ƒ
            def on_progress(anchor_id, view, status, path=None, error=None):
                nonlocal generated_count, failed_count
                if status == "SUCCESS":
                    generated_count += 1
                elif status == "FAILED":
                    failed_count += 1

            # ç”Ÿæˆè§’è‰²ä¸‰è§†å›¾
            for i, char in enumerate(characters):
                anchor_id = char.get("anchorId", f"char_{i+1:02d}")
                anchor_name = char.get("name", "Unknown Character")
                description = char.get("description", "")

                print(f"\n   ğŸ‘¤ [{i+1}/{len(characters)}] Generating character: {anchor_name}")

                # æŸ¥æ‰¾è¯¥è§’è‰²çš„å‚è€ƒå›¾ï¼ˆå¦‚æœç”¨æˆ·æä¾›äº†ï¼‰
                user_ref_path = None
                if user_reference_images:
                    # ç®€å•ç­–ç•¥ï¼šç¬¬ä¸€ä¸ªå‚è€ƒå›¾ç»™ç¬¬ä¸€ä¸ªè§’è‰²
                    if i < len(user_reference_images):
                        user_ref_path = user_reference_images[i]

                # ä» visualDNA æå–æŒä¹…å±æ€§
                visual_dna = char.get("visualDNA", {})
                persistent_attrs = []
                if visual_dna.get("hair"):
                    persistent_attrs.append(f"hair: {visual_dna['hair']}")
                if visual_dna.get("clothing"):
                    persistent_attrs.append(f"clothing: {visual_dna['clothing']}")
                if visual_dna.get("accessories"):
                    persistent_attrs.append(f"accessories: {visual_dna['accessories']}")
                if visual_dna.get("features"):
                    persistent_attrs.append(f"features: {visual_dna['features']}")

                # ç”Ÿæˆä¸‰è§†å›¾
                results = generator.generate_character_assets(
                    anchor_id=anchor_id,
                    anchor_name=anchor_name,
                    detailed_description=description,
                    style_adaptation=visual_dna.get("features", ""),
                    persistent_attributes=persistent_attrs if persistent_attrs else None,
                    user_reference_path=user_ref_path,
                    on_progress=on_progress
                )

                # æ›´æ–° IR ä¸­çš„ä¸‰è§†å›¾è·¯å¾„
                self._update_character_asset_paths(anchor_id, results)

            # ç”Ÿæˆç¯å¢ƒå‚è€ƒå›¾
            for i, env in enumerate(environments):
                anchor_id = env.get("anchorId", f"env_{i+1:02d}")
                anchor_name = env.get("name", "Unknown Environment")
                description = env.get("description", "")

                print(f"\n   ğŸï¸ [{i+1}/{len(environments)}] Generating environment: {anchor_name}")

                # ç”Ÿæˆç¯å¢ƒå‚è€ƒå›¾
                result = generator.generate_environment_asset(
                    anchor_id=anchor_id,
                    anchor_name=anchor_name,
                    detailed_description=description,
                    atmospheric_conditions="",  # ä»æè¿°ä¸­å·²åŒ…å«
                    style_adaptation="",
                    on_progress=on_progress
                )

                # æ›´æ–° IR ä¸­çš„ç¯å¢ƒå‚è€ƒå›¾è·¯å¾„
                self._update_environment_asset_path(anchor_id, result)

            # ä¿å­˜æ›´æ–°åçš„ IR
            self.save()

            # ç”Ÿæˆæ‘˜è¦
            success_rate = (generated_count / total_assets * 100) if total_assets > 0 else 0
            print(f"\nâœ… [Stage 4] Asset generation completed:")
            print(f"   Generated: {generated_count}/{total_assets} ({success_rate:.1f}%)")
            if failed_count > 0:
                print(f"   Failed: {failed_count}")

            return {
                "status": "success" if failed_count == 0 else "partial",
                "message": f"Generated {generated_count}/{total_assets} assets",
                "generated": generated_count,
                "failed": failed_count,
                "total": total_assets,
                "assets_dir": str(generator.assets_dir)
            }

        except Exception as e:
            print(f"âŒ [Stage 4] Asset generation failed: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "failed", "message": str(e)}

    def _update_character_asset_paths(self, anchor_id: str, results: Dict) -> None:
        """
        æ›´æ–°è§’è‰²çš„ä¸‰è§†å›¾è·¯å¾„åˆ° IR

        Args:
            anchor_id: è§’è‰²é”šç‚¹ ID
            results: ç”Ÿæˆç»“æœ {view: GeneratedAsset}
        """
        characters = self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["characters"]

        for char in characters:
            if char.get("anchorId") == anchor_id:
                # æ›´æ–°ä¸‰è§†å›¾è·¯å¾„
                three_views = char.get("threeViews", {"front": None, "side": None, "back": None})

                for view_name, asset in results.items():
                    if asset.status.value == "SUCCESS" and asset.file_path:
                        three_views[view_name] = asset.file_path

                char["threeViews"] = three_views

                # æ›´æ–°çŠ¶æ€
                if all(three_views.get(v) for v in ["front", "side", "back"]):
                    char["status"] = "SUCCESS"
                elif any(three_views.get(v) for v in ["front", "side", "back"]):
                    char["status"] = "PARTIAL"
                else:
                    char["status"] = "FAILED"

                break

    def _update_environment_asset_path(self, anchor_id: str, result) -> None:
        """
        æ›´æ–°ç¯å¢ƒçš„å‚è€ƒå›¾è·¯å¾„åˆ° IR

        Args:
            anchor_id: ç¯å¢ƒé”šç‚¹ ID
            result: GeneratedAsset
        """
        environments = self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["environments"]

        for env in environments:
            if env.get("anchorId") == anchor_id:
                if result.status.value == "SUCCESS" and result.file_path:
                    env["referenceImage"] = result.file_path
                    env["status"] = "SUCCESS"
                else:
                    env["status"] = "FAILED"
                break

    def _run_shot_refinement(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 5: åˆ†é•œç²¾ä¿®
        ç”Ÿæˆæ¯ä¸€é•œçš„ T2I/I2V Prompt

        TODO: æ¥å…¥ Meta Prompts (t2iPromptComposer, i2vPromptComposer)
        """
        print(f"âœ¨ [Stage 5] Running shot refinement for {self.job_id}...")

        meta_prompts = self.ir.get("metaPromptsRegistry", {})

        if not meta_prompts.get("t2iPromptComposer"):
            print("âš ï¸ Meta Prompt 't2iPromptComposer' not configured")

        if not meta_prompts.get("i2vPromptComposer"):
            print("âš ï¸ Meta Prompt 'i2vPromptComposer' not configured")

        # TODO: ç”Ÿæˆæ¸²æŸ“é…æ–¹

        return {"status": "success", "message": "Shot refinement completed (placeholder)"}

    def _run_execution(self) -> Dict[str, Any]:
        """
        é˜¶æ®µ 6: æ‰§è¡Œè§†é¢‘ç”Ÿæˆ
        è°ƒç”¨ Imagen + Veo ç”Ÿæˆæœ€ç»ˆè§†é¢‘
        """
        print(f"ğŸ¬ [Stage 6] Running video execution for {self.job_id}...")

        # TODO: è°ƒç”¨è§†é¢‘ç”Ÿæˆç®¡çº¿

        return {"status": "success", "message": "Execution completed (placeholder)"}

    # ============================================================
    # æ„å›¾å¤„ç†
    # ============================================================

    def set_user_intent(
        self,
        raw_prompt: str,
        reference_images: Optional[List[str]] = None
    ) -> None:
        """
        è®¾ç½®ç”¨æˆ·æ„å›¾

        Args:
            raw_prompt: ç”¨æˆ·åŸå§‹è¾“å…¥
            reference_images: å‚è€ƒå›¾ç‰‡è·¯å¾„åˆ—è¡¨ (å¯é€‰)
        """
        # å¦‚æœä¹‹å‰æœ‰æ„å›¾ï¼Œå…ˆä¿å­˜åˆ°å†å²è®°å½•
        prev_prompt = self.ir["userIntent"].get("rawPrompt")
        prev_parsed = self.ir["userIntent"].get("parsedIntent")
        if prev_prompt and prev_parsed:
            # ç¡®ä¿ intentHistory å­˜åœ¨
            if "intentHistory" not in self.ir["userIntent"]:
                self.ir["userIntent"]["intentHistory"] = []

            # è¿½åŠ åˆ°å†å²è®°å½•
            self.ir["userIntent"]["intentHistory"].append({
                "rawPrompt": prev_prompt,
                "parsedIntent": prev_parsed,
                "referenceImages": self.ir["userIntent"].get("referenceImages", []),
                "injectedAt": self.ir["userIntent"].get("injectedAt"),
                "archivedAt": datetime.utcnow().isoformat() + "Z",
                "historyIndex": len(self.ir["userIntent"]["intentHistory"])
            })
            print(f"   ğŸ“œ Previous intent archived to history (index: {len(self.ir['userIntent']['intentHistory']) - 1})")

        # è®¾ç½®æ–°çš„æ„å›¾
        self.ir["userIntent"]["rawPrompt"] = raw_prompt
        self.ir["userIntent"]["referenceImages"] = reference_images or []
        self.ir["userIntent"]["injectedAt"] = datetime.utcnow().isoformat() + "Z"
        # æ¸…é™¤ä¹‹å‰çš„è§£æç»“æœï¼ˆä½†ä¿ç•™å†å²ï¼‰
        self.ir["userIntent"]["parsedIntent"] = None
        self.ir["userIntent"]["remixedLayer"] = None
        self.save()

    def get_remixed_layer(self) -> Optional[Dict[str, Any]]:
        """
        è·å– remixed å±‚æ•°æ®

        Returns:
            remixedLayer æˆ– None
        """
        return self.ir["userIntent"].get("remixedLayer")

    def get_intent_history(self) -> List[Dict[str, Any]]:
        """
        è·å–æ„å›¾ä¿®æ”¹å†å²è®°å½•

        Returns:
            æ„å›¾å†å²åˆ—è¡¨ï¼Œæ¯æ¡è®°å½•åŒ…å«:
            - rawPrompt: åŸå§‹ç”¨æˆ·è¾“å…¥
            - parsedIntent: è§£æåçš„æ„å›¾
            - referenceImages: å‚è€ƒå›¾ç‰‡
            - injectedAt: æ³¨å…¥æ—¶é—´
            - archivedAt: å½’æ¡£æ—¶é—´
            - historyIndex: å†å²ç´¢å¼•
        """
        return self.ir["userIntent"].get("intentHistory", [])

    def get_current_intent_with_history(self) -> Dict[str, Any]:
        """
        è·å–å½“å‰æ„å›¾åŠå…¶å†å²è®°å½•ï¼Œç”¨äºå‰ç«¯å±•ç¤º

        Returns:
            åŒ…å«å½“å‰æ„å›¾å’Œå†å²è®°å½•çš„å­—å…¸
        """
        return {
            "current": {
                "rawPrompt": self.ir["userIntent"].get("rawPrompt"),
                "parsedIntent": self.ir["userIntent"].get("parsedIntent"),
                "referenceImages": self.ir["userIntent"].get("referenceImages", []),
                "injectedAt": self.ir["userIntent"].get("injectedAt"),
                "isRemixed": self.ir["userIntent"].get("remixedLayer") is not None
            },
            "history": self.get_intent_history(),
            "totalModifications": len(self.get_intent_history()) + (1 if self.ir["userIntent"].get("rawPrompt") else 0)
        }

    def get_remix_diff_for_frontend(self) -> List[Dict[str, Any]]:
        """
        è·å– concrete vs remixed çš„å·®å¼‚ï¼Œç”¨äºå‰ç«¯ Diff View

        Returns:
            æ¯ä¸ªé•œå¤´çš„å·®å¼‚åˆ—è¡¨
        """
        from core.meta_prompts import get_remix_diff

        concrete = self.pillars["III_shotRecipe"].get("concrete", {})
        remixed_layer = self.get_remixed_layer()

        if not remixed_layer:
            return []

        return get_remix_diff(concrete, remixed_layer)

    def get_hidden_template(self) -> Dict[str, Any]:
        """
        è·å–éšå½¢æ¨¡æ¿ (æ‰€æœ‰æ”¯æŸ±çš„ abstract å±‚)
        """
        return {
            "storyTheme": self.pillars["I_storyTheme"].get("abstract"),
            "narrativeTemplate": self.pillars["II_narrativeTemplate"].get("abstract"),
            "shotRecipe": self.pillars["III_shotRecipe"].get("abstract")
        }

    # ============================================================
    # æ”¯æŸ±æ•°æ®æ“ä½œ
    # ============================================================

    def update_pillar(self, pillar: str, layer: str, data: Dict[str, Any]) -> None:
        """
        æ›´æ–°æ”¯æŸ±æ•°æ®

        Args:
            pillar: æ”¯æŸ±å (I_storyTheme/II_narrativeTemplate/III_shotRecipe/IV_renderStrategy)
            layer: å±‚çº§ (concrete/abstract/remixed)
            data: æ•°æ®
        """
        if pillar not in self.pillars:
            raise ValueError(f"Unknown pillar: {pillar}")

        if pillar == "IV_renderStrategy":
            self.ir["pillars"][pillar].update(data)
        else:
            if layer not in ["concrete", "abstract", "remixed"]:
                raise ValueError(f"Unknown layer: {layer}")
            self.ir["pillars"][pillar][layer] = data

        self.save()

    def get_active_layer(self, pillar: str) -> Optional[Dict[str, Any]]:
        """
        è·å–æ”¯æŸ±çš„æ´»è·ƒå±‚æ•°æ®
        ä¼˜å…ˆçº§: remixed > concrete > None
        """
        if pillar not in self.pillars:
            raise ValueError(f"Unknown pillar: {pillar}")

        pillar_data = self.pillars[pillar]

        if pillar == "IV_renderStrategy":
            return pillar_data

        if pillar_data.get("remixed"):
            return pillar_data["remixed"]
        return pillar_data.get("concrete")

    # ============================================================
    # å‰ç«¯æ•°æ®è¾“å‡º
    # ============================================================

    def get_story_theme_for_frontend(self) -> Optional[Dict[str, Any]]:
        """è·å–å‰ç«¯ StoryThemeAnalysis æ ¼å¼æ•°æ®"""
        return convert_to_frontend_story_theme(self.ir)

    def get_script_analysis_for_frontend(self) -> Optional[Dict[str, Any]]:
        """è·å–å‰ç«¯ ScriptAnalysis æ ¼å¼æ•°æ®"""
        return convert_to_frontend_script_analysis(self.ir)

    def get_storyboard_for_frontend(self, base_url: str = "") -> list:
        """è·å–å‰ç«¯ StoryboardShot[] æ ¼å¼æ•°æ®"""
        return convert_to_frontend_storyboard(self.ir, base_url)

    def get_full_analysis_for_frontend(self, base_url: str = "") -> Dict[str, Any]:
        """
        è·å–å®Œæ•´çš„å‰ç«¯åˆ†æç»“æœ

        Returns:
            å¯¹åº”å‰ç«¯ RemixAnalysisResult ç»“æ„
        """
        return {
            "storyTheme": self.get_story_theme_for_frontend(),
            "scriptAnalysis": self.get_script_analysis_for_frontend(),
            "storyboard": self.get_storyboard_for_frontend(base_url)
        }

    # ============================================================
    # èµ„äº§é”šç‚¹æ“ä½œ
    # ============================================================

    def add_character_anchor(self, character_data: Dict[str, Any]) -> str:
        """æ·»åŠ è§’è‰²é”šç‚¹"""
        anchors = self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["characters"]

        anchor_id = f"char_{len(anchors) + 1:02d}"
        character_data["anchorId"] = anchor_id
        character_data["status"] = character_data.get("status", "NOT_STARTED")

        anchors.append(character_data)
        self.save()

        return anchor_id

    def add_environment_anchor(self, env_data: Dict[str, Any]) -> str:
        """æ·»åŠ åœºæ™¯é”šç‚¹"""
        anchors = self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["environments"]

        anchor_id = f"env_{len(anchors) + 1:02d}"
        env_data["anchorId"] = anchor_id
        env_data["status"] = env_data.get("status", "NOT_STARTED")

        anchors.append(env_data)
        self.save()

        return anchor_id

    def update_anchor_status(self, anchor_id: str, status: str) -> None:
        """æ›´æ–°é”šç‚¹çŠ¶æ€"""
        for char in self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["characters"]:
            if char.get("anchorId") == anchor_id:
                char["status"] = status
                self.save()
                return

        for env in self.ir["pillars"]["IV_renderStrategy"]["identityAnchors"]["environments"]:
            if env.get("anchorId") == anchor_id:
                env["status"] = status
                self.save()
                return

    # ============================================================
    # Meta Prompts é…ç½®
    # ============================================================

    def set_meta_prompt(self, key: str, prompt: str) -> None:
        """
        è®¾ç½® Meta Prompt

        Args:
            key: Prompt é”®å
            prompt: Prompt å†…å®¹
        """
        valid_keys = [
            "storyThemeAnalysis", "narrativeExtraction", "shotDecomposition",
            "abstractionEngine", "intentFusion",
            "characterAnchorGen", "environmentAnchorGen",
            "t2iPromptComposer", "i2vPromptComposer"
        ]

        if key not in valid_keys:
            raise ValueError(f"Invalid meta prompt key: {key}. Valid keys: {valid_keys}")

        self.ir["metaPromptsRegistry"][key] = prompt
        self.save()

    def load_meta_prompts_from_config(self, config_path: Path) -> None:
        """
        ä»é…ç½®æ–‡ä»¶åŠ è½½æ‰€æœ‰ Meta Prompts

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ (JSON)
        """
        import json

        with open(config_path, "r", encoding="utf-8") as f:
            prompts = json.load(f)

        for key, prompt in prompts.items():
            if key in self.ir["metaPromptsRegistry"]:
                self.ir["metaPromptsRegistry"][key] = prompt

        self.save()
        print(f"âœ… Loaded {len(prompts)} meta prompts from {config_path}")
